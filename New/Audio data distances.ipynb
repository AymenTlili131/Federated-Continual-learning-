{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1a8fa2-b2dc-4acf-bb4b-a062266e43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd38b149-eca1-4481-947c-ba81d369e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_wave(batch_size=8, length=16000, sample_rate=16000):\n",
    "    t = torch.linspace(0, 1, steps=length)\n",
    "    waves = []\n",
    "    for _ in range(batch_size):\n",
    "        freq = torch.randint(100, 1000, (1,)).item()\n",
    "        wave = torch.sin(2 * np.pi * freq * t)\n",
    "        noise = 0.05 * torch.randn_like(wave)\n",
    "        waves.append((wave + noise).unsqueeze(0))  # shape: [1, length]\n",
    "    return torch.stack(waves)  # [batch_size, 1, length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf51d30a-d19e-4393-be9b-28aec4bbbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAudioAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 9, stride=2, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, 9, stride=2, padding=4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(32, 16, 9, stride=2, padding=4, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(16, 1, 9, stride=2, padding=4, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49b4bb7-7385-4b94-a3c3-5c8c84e4b946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32c038f-5f72-45bd-8dfd-82e133235feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbc3505-c7d7-4bc6-90b1-c5147fda0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, epochs=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        x = generate_synthetic_wave(batch_size=16).to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_fn(y, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67a94a96-37dc-4118-9cc1-ad0e12e59027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Training with Waveform L2\n",
      "Epoch 1: Loss = 0.5028\n",
      "Epoch 2: Loss = 0.4754\n",
      "Epoch 3: Loss = 0.4481\n",
      "Epoch 4: Loss = 0.4181\n",
      "Epoch 5: Loss = 0.3914\n",
      "\n",
      "ðŸ§ª Training with FFT Loss\n",
      "Epoch 1: Loss = 6.9610\n",
      "Epoch 2: Loss = 6.8325\n",
      "Epoch 3: Loss = 6.7758\n",
      "Epoch 4: Loss = 6.6426\n",
      "Epoch 5: Loss = 6.5873\n",
      "\n",
      "ðŸ§ª Training with Mel L2\n",
      "Epoch 1: Loss = 86000024.0000\n",
      "Epoch 2: Loss = 79670016.0000\n",
      "Epoch 3: Loss = 73875232.0000\n",
      "Epoch 4: Loss = 66363668.0000\n",
      "Epoch 5: Loss = 63252048.0000\n",
      "\n",
      "ðŸ§ª Training with Mel FID\n",
      "Epoch 1: Loss = 57867584.0000\n",
      "Epoch 2: Loss = 50311440.0000\n",
      "Epoch 3: Loss = 39476568.0000\n",
      "Epoch 4: Loss = 30372700.0000\n",
      "Epoch 5: Loss = 22131992.0000\n"
     ]
    }
   ],
   "source": [
    "model = TinyAudioAutoencoder()\n",
    "losses = {\n",
    "    \"Waveform L2\": WaveformL2Loss(),\n",
    "    \"FFT Loss\": FFTLoss(),\n",
    "    \"Mel L2\": MelSpecL2Loss(),\n",
    "    \"Mel FID\": MelFIDLoss(),\n",
    "}\n",
    "\n",
    "for name, loss_fn in losses.items():\n",
    "    print(f\"\\nðŸ§ª Training with {name}\")\n",
    "    train(model, loss_fn, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1bb28-35c0-49a8-a068-fcd22fb6b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
