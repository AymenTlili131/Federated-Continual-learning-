{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c777c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch Tensor Export and Benchmark Setup ===\n",
      "Project root: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New\n",
      "Data directory: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/data\n",
      "Tensor output directory: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches\n",
      "PyTorch version: 2.7.1+cu128\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"02_batch_tensors_and_benchmark.ipynb\n",
    "\n",
    "## Rationale and Approach\n",
    "\n",
    "This notebook optimizes data loading by materializing CustomDataset batches into persistent tensor files, then benchmarking the performance improvement.\n",
    "\n",
    "Key objectives:\n",
    "1. Export CustomDataset batches to .pt files with metadata preservation\n",
    "2. Create TensorDataset from saved tensors for faster loading\n",
    "3. Benchmark performance difference between on-the-fly vs pre-materialized loading\n",
    "4. Demonstrate training loop compatibility with the new dataset format\n",
    "\n",
    "Constraints:\n",
    "- Do not modify meta.ipynb or Double_input_transformer.py; import and reuse\n",
    "- Maintain full compatibility with existing data structures\n",
    "- Self-contained export and benchmark tool\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Set up paths\n",
    "ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "TENSOR_DIR = ROOT / \"notebooks_sandbox\" / \"tensor_batches\"\n",
    "TENSOR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"=== Batch Tensor Export and Benchmark Setup ===\")\n",
    "print(f\"Project root: {ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Tensor output directory: {TENSOR_DIR}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42c9fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Importing CustomDataset and Checking Data ===\n",
      "CustomDataset imported successfully\n",
      "‚úÖ Merged zoo.csv found at: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/data/Merged zoo.csv\n",
      "\n",
      "CustomDataset parameters:\n",
      "- L_exp: List of experiments (label1, label2, epoch_key, activ_key)\n",
      "- batch_size: Default 20\n",
      "- batch_limit: Default 5\n",
      "- df_path: Path to Merged zoo.csv (IMPORTANT: Must use absolute path)\n",
      "\n",
      "Batchify function:\n",
      "- Creates batches from L_exp with given batch_size and limit\n",
      "\n",
      "Sample L_exp format: (0, 1, 0, 0)\n",
      "\n",
      "üîß Fixing path issue - using absolute path: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/data/Merged zoo.csv\n",
      "‚úÖ CustomDataset created successfully!\n",
      "Epoch mapping: {'0': '11', '1': '16', '2': '21', '3': '26', '4': '31', '5': '36'}\n",
      "Activation mapping: {'0': 'gelu', '1': 'relu', '2': 'silu', '3': 'leakyrelu', '4': 'sigmoid', '5': 'tanh'}\n",
      "Dataset length: 2 batches\n",
      "\n",
      "üìä CSV Structure:\n",
      "   Shape: (5, 2483)\n",
      "   Available columns: ['label', '0', '1', '2', '3', '4', '5', '6', '7', '8']...\n",
      "   Activation columns found: ['gelu', 'relu', 'silu', 'tanh', 'sigmoid', 'leakyrelu']\n",
      "   Unique epochs: [36]\n",
      "   Unique labels: ['[0, 1]', '[0, 2]', '[0, 3]', '[0, 4]', '[0, 5]']\n",
      "‚úÖ Data structure appears valid for single initialization analysis\n",
      "\n",
      "üìù IMPORTANT NOTE:\n",
      "   Always use absolute paths when creating CustomDataset instances\n",
      "   The default relative path './data/Merged zoo.csv' only works from project root\n",
      "   From notebooks_sandbox, use: str(DATA_DIR / 'Merged zoo.csv')\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import CustomDataset and check data availability\n",
    "print(\"=== Importing CustomDataset and Checking Data ===\")\n",
    "\n",
    "# Import the CustomDataset from Double_input_transformer.py\n",
    "exec(open(ROOT / \"Double_input_transformer.py\").read())\n",
    "\n",
    "print(\"CustomDataset imported successfully\")\n",
    "\n",
    "# Check if the required CSV file exists\n",
    "merged_zoo_path = DATA_DIR / \"Merged zoo.csv\"\n",
    "if not merged_zoo_path.exists():\n",
    "    print(f\"‚ùå Merged zoo.csv not found at: {merged_zoo_path}\")\n",
    "    print(\"Please ensure the data file is available before proceeding.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Merged zoo.csv found at: {merged_zoo_path}\")\n",
    "\n",
    "# Examine the CustomDataset structure\n",
    "print(\"\\nCustomDataset parameters:\")\n",
    "print(\"- L_exp: List of experiments (label1, label2, epoch_key, activ_key)\")\n",
    "print(\"- batch_size: Default 20\")\n",
    "print(\"- batch_limit: Default 5\")\n",
    "print(\"- df_path: Path to Merged zoo.csv (IMPORTANT: Must use absolute path)\")\n",
    "\n",
    "# Let's examine the batchify function\n",
    "print(\"\\nBatchify function:\")\n",
    "print(\"- Creates batches from L_exp with given batch_size and limit\")\n",
    "\n",
    "# Create a sample L_exp to understand the format\n",
    "sample_L_exp = [\n",
    "    (0, 1, 0, 0),  # (label1, label2, epoch_key, activ_key)\n",
    "    (2, 3, 1, 1),\n",
    "    (4, 5, 2, 2),\n",
    "    (6, 7, 3, 3),\n",
    "    (8, 9, 4, 4),\n",
    "    (0, 2, 5, 5),\n",
    "    (1, 3, 0, 0),\n",
    "    (4, 6, 1, 1),\n",
    "    (5, 7, 2, 2),\n",
    "    (8, 0, 3, 3),\n",
    "]\n",
    "\n",
    "print(f\"\\nSample L_exp format: {sample_L_exp[0]}\")\n",
    "\n",
    "# IMPORTANT: Always use absolute path to avoid path resolution issues\n",
    "print(f\"\\nüîß Fixing path issue - using absolute path: {merged_zoo_path}\")\n",
    "\n",
    "try:\n",
    "    # Test CustomDataset with correct absolute path\n",
    "    sample_dataset = CustomDataset(\n",
    "        L_exp=sample_L_exp,\n",
    "        batch_size=4,\n",
    "        batch_limit=2,\n",
    "        df_path=str(merged_zoo_path)  # CRITICAL: Always use absolute path\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ CustomDataset created successfully!\")\n",
    "    print(f\"Epoch mapping: {sample_dataset.D_epoch}\")\n",
    "    print(f\"Activation mapping: {sample_dataset.D_activ}\")\n",
    "    print(f\"Dataset length: {len(sample_dataset)} batches\")\n",
    "    \n",
    "    # Check what data is actually available in the CSV\n",
    "    try:\n",
    "        df_sample = pd.read_csv(merged_zoo_path, nrows=5)\n",
    "        print(f\"\\nüìä CSV Structure:\")\n",
    "        print(f\"   Shape: {df_sample.shape}\")\n",
    "        print(f\"   Available columns: {list(df_sample.columns[:10])}...\")\n",
    "        \n",
    "        # Check for activation columns\n",
    "        activation_cols = [col for col in df_sample.columns if col in [\"silu\", \"gelu\", \"relu\", \"leakyrelu\", \"sigmoid\", \"tanh\"]]\n",
    "        print(f\"   Activation columns found: {activation_cols}\")\n",
    "        \n",
    "        # Check unique epochs\n",
    "        if 'epoch' in df_sample.columns:\n",
    "            unique_epochs = sorted(df_sample['epoch'].unique())\n",
    "            print(f\"   Unique epochs: {unique_epochs}\")\n",
    "        \n",
    "        # Check unique labels\n",
    "        if 'label' in df_sample.columns:\n",
    "            unique_labels = sorted(df_sample['label'].unique())\n",
    "            print(f\"   Unique labels: {unique_labels}\")\n",
    "        \n",
    "        print(\"‚úÖ Data structure appears valid for single initialization analysis\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error examining CSV: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating CustomDataset: {e}\")\n",
    "    print(f\"This might be due to:\")\n",
    "    print(f\"   - Missing data file\")\n",
    "    print(f\"   - Incompatible data format\")\n",
    "    print(f\"   - Path resolution issues\")\n",
    "    \n",
    "    # Still try to examine the CSV structure for debugging\n",
    "    try:\n",
    "        df_sample = pd.read_csv(merged_zoo_path, nrows=5)\n",
    "        print(f\"\\nüìä CSV Structure (for debugging):\")\n",
    "        print(f\"   Shape: {df_sample.shape}\")\n",
    "        print(f\"   Available columns: {list(df_sample.columns[:15])}...\")\n",
    "        print(f\"   First few rows:\")\n",
    "        print(df_sample.head(2))\n",
    "    except Exception as csv_error:\n",
    "        print(f\"‚ùå CSV also unreadable: {csv_error}\")\n",
    "\n",
    "print(f\"\\nüìù IMPORTANT NOTE:\")\n",
    "print(f\"   Always use absolute paths when creating CustomDataset instances\")\n",
    "print(f\"   The default relative path './data/Merged zoo.csv' only works from project root\")\n",
    "print(f\"   From notebooks_sandbox, use: str(DATA_DIR / 'Merged zoo.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7ed6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Single Initialization Data Preparation ===\n",
      "Created single initialization L_exp with 30 samples\n",
      "Single initialization dataset length: 5\n",
      "Number of batches: 5\n",
      "\n",
      "üìä Single Initialization Dataset Analysis:\n",
      "   Primary activation: Will be detected from data\n",
      "   Epoch range: Early-mid training phases\n",
      "   Label pairs: Balanced across 10 classes\n",
      "   Batch configuration: 6 samples per batch\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Single Initialization Data Preparation\n",
    "print(\"=== Single Initialization Data Preparation ===\")\n",
    "\n",
    "# Create a sample L_exp optimized for single initialization analysis\n",
    "def create_single_init_L_exp(num_samples=50):\n",
    "    \"\"\"Create L_exp focused on single initialization scenarios\"\"\"\n",
    "    L_exp = []\n",
    "    \n",
    "    # For single initialization, focus on primary activation and key epochs\n",
    "    labels = list(range(10))\n",
    "    epoch_keys = [0, 1, 2]  # Focus on early-mid training epochs\n",
    "    activ_key = 0  # Focus on primary activation (will be detected automatically)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Create balanced label pairs\n",
    "        label1 = labels[i % len(labels)]\n",
    "        label2 = labels[(i + 1) % len(labels)]\n",
    "        epoch_key = epoch_keys[i % len(epoch_keys)]\n",
    "        \n",
    "        L_exp.append((label1, label2, epoch_key, activ_key))\n",
    "    \n",
    "    return L_exp\n",
    "\n",
    "# Create single initialization dataset\n",
    "single_init_L_exp = create_single_init_L_exp(30)\n",
    "print(f\"Created single initialization L_exp with {len(single_init_L_exp)} samples\")\n",
    "\n",
    "# Create dataset with single initialization optimization\n",
    "single_init_dataset = CustomDataset(\n",
    "    L_exp=single_init_L_exp,\n",
    "    batch_size=6,\n",
    "    batch_limit=10,\n",
    "    df_path=str(merged_zoo_path)  # Use absolute path\n",
    ")\n",
    "\n",
    "print(f\"Single initialization dataset length: {len(single_init_dataset)}\")\n",
    "print(f\"Number of batches: {len(single_init_dataset.batchs)}\")\n",
    "\n",
    "# Analyze the dataset structure\n",
    "print(f\"\\nüìä Single Initialization Dataset Analysis:\")\n",
    "print(f\"   Primary activation: Will be detected from data\")\n",
    "print(f\"   Epoch range: Early-mid training phases\")\n",
    "print(f\"   Label pairs: Balanced across 10 classes\")\n",
    "print(f\"   Batch configuration: {single_init_dataset.batch_size} samples per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b00d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Single Initialization Data Preparation for Training ===\n",
      "Created training L_exp with 180 samples\n",
      "Training dataset length: 5\n",
      "Number of batches: 5\n",
      "\n",
      "üìä Training Dataset Analysis:\n",
      "   Primary activation: Will be detected from data\n",
      "   Epoch range: Early-mid training phases\n",
      "   Label pairs: Balanced across 10 classes\n",
      "   Batch configuration: 36 samples per batch (matches meta.ipynb)\n",
      "   Total samples: 180 ‚Üí 5 batches of 36 pairs each\n",
      "\n",
      "üîç Sample Batch Structure:\n",
      "   Batch type: <class 'list'>\n",
      "   Batch length: 36\n",
      "   Expected format: 36 pairs of (1D vectors + targets)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Single Initialization Data Preparation for Training\n",
    "print(\"=== Single Initialization Data Preparation for Training ===\")\n",
    "\n",
    "# Create a sample L_exp optimized for single initialization analysis\n",
    "def create_training_L_exp(num_samples=180):  # 180 samples = 5 batches of 36\n",
    "    \"\"\"Create L_exp for training with batch_size=36\"\"\"\n",
    "    L_exp = []\n",
    "    \n",
    "    # For single initialization, focus on primary activation and key epochs\n",
    "    labels = list(range(10))\n",
    "    epoch_keys = [0, 1, 2]  # Focus on early-mid training epochs\n",
    "    activ_key = 0  # Focus on primary activation (will be detected automatically)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Create balanced label pairs for training\n",
    "        label1 = labels[i % len(labels)]\n",
    "        label2 = labels[(i + 1) % len(labels)]\n",
    "        epoch_key = epoch_keys[i % len(epoch_keys)]\n",
    "        \n",
    "        L_exp.append((label1, label2, epoch_key, activ_key))\n",
    "    \n",
    "    return L_exp\n",
    "\n",
    "# Create training dataset with batch_size=36 to match meta.ipynb\n",
    "training_L_exp = create_training_L_exp(180)  # 180 samples for 5 batches of 36\n",
    "print(f\"Created training L_exp with {len(training_L_exp)} samples\")\n",
    "\n",
    "# Create dataset with training batch configuration (matching meta.ipynb)\n",
    "training_dataset = CustomDataset(\n",
    "    L_exp=training_L_exp,\n",
    "    batch_size=36,  # CRITICAL: Match batch size from meta.ipynb\n",
    "    batch_limit=5,   # Create 5 batches for demonstration\n",
    "    df_path=str(merged_zoo_path)  # Use absolute path\n",
    ")\n",
    "\n",
    "print(f\"Training dataset length: {len(training_dataset)}\")\n",
    "print(f\"Number of batches: {len(training_dataset.batchs)}\")\n",
    "\n",
    "# Analyze the training dataset structure\n",
    "print(f\"\\nüìä Training Dataset Analysis:\")\n",
    "print(f\"   Primary activation: Will be detected from data\")\n",
    "print(f\"   Epoch range: Early-mid training phases\")\n",
    "print(f\"   Label pairs: Balanced across 10 classes\")\n",
    "print(f\"   Batch configuration: {training_dataset.batch_size} samples per batch (matches meta.ipynb)\")\n",
    "print(f\"   Total samples: {len(training_L_exp)} ‚Üí {len(training_dataset)} batches of 36 pairs each\")\n",
    "\n",
    "# Verify batch structure for training\n",
    "if len(training_dataset.batchs) > 0:\n",
    "    sample_batch = training_dataset.batchs[0]\n",
    "    print(f\"\\nüîç Sample Batch Structure:\")\n",
    "    print(f\"   Batch type: {type(sample_batch)}\")\n",
    "    print(f\"   Batch length: {len(sample_batch) if sample_batch else 'N/A'}\")\n",
    "    print(f\"   Expected format: 36 pairs of (1D vectors + targets)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9428f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor batch directories organized by scenario:\n",
      "  train: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches/train_pair_scenario (21 files)\n",
      "  val: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches/val_pair_scenario (0 files)\n",
      "  test: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches/test_pair_scenario (0 files)\n",
      "Current scenario: train\n",
      "Using directory: /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches/train_pair_scenario\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Setup Tensor Batch Directory Structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory for tensor batches\n",
    "BASE_TENSOR_DIR = Path(\"/home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches\")\n",
    "\n",
    "# Scenario-specific directories\n",
    "SCENARIOS = {\n",
    "    'train': BASE_TENSOR_DIR / \"train_pair_scenario\",\n",
    "    'val': BASE_TENSOR_DIR / \"val_pair_scenario\", \n",
    "    'test': BASE_TENSOR_DIR / \"test_pair_scenario\"\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for scenario_name, scenario_dir in SCENARIOS.items():\n",
    "    scenario_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Current scenario for this notebook\n",
    "CURRENT_SCENARIO = 'train'\n",
    "TENSOR_DIR = SCENARIOS[CURRENT_SCENARIO]\n",
    "\n",
    "print(f\"Tensor batch directories organized by scenario:\")\n",
    "for scenario_name, scenario_dir in SCENARIOS.items():\n",
    "    file_count = len(list(scenario_dir.glob(\"*.pt\")))\n",
    "    print(f\"  {scenario_name}: {scenario_dir} ({file_count} files)\")\n",
    "\n",
    "print(f\"Current scenario: {CURRENT_SCENARIO}\")\n",
    "print(f\"Using directory: {TENSOR_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f592e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Create Training Dataset with Proper MNIST Subset Labels ===\n",
      "\n",
      "=== Creating MNIST Training Dataset ===\n",
      "Found 1013 unique MNIST subset labels:\n",
      "  0: '[0, 1]'\n",
      "  1: '[0, 2]'\n",
      "  2: '[0, 3]'\n",
      "  3: '[0, 4]'\n",
      "  4: '[0, 5]'\n",
      "  5: '[0, 6]'\n",
      "  6: '[0, 7]'\n",
      "  7: '[0, 8]'\n",
      "  8: '[0, 9]'\n",
      "  9: '[1, 2]'\n",
      "  10: '[1, 3]'\n",
      "  11: '[1, 4]'\n",
      "  12: '[1, 5]'\n",
      "  13: '[1, 6]'\n",
      "  14: '[1, 7]'\n",
      "  15: '[1, 8]'\n",
      "  16: '[1, 9]'\n",
      "  17: '[2, 3]'\n",
      "  18: '[2, 4]'\n",
      "  19: '[2, 5]'\n",
      "  20: '[2, 6]'\n",
      "  21: '[2, 7]'\n",
      "  22: '[2, 8]'\n",
      "  23: '[2, 9]'\n",
      "  24: '[3, 4]'\n",
      "  25: '[3, 5]'\n",
      "  26: '[3, 6]'\n",
      "  27: '[3, 7]'\n",
      "  28: '[3, 8]'\n",
      "  29: '[3, 9]'\n",
      "  30: '[4, 5]'\n",
      "  31: '[4, 6]'\n",
      "  32: '[4, 7]'\n",
      "  33: '[4, 8]'\n",
      "  34: '[4, 9]'\n",
      "  35: '[5, 6]'\n",
      "  36: '[5, 7]'\n",
      "  37: '[5, 8]'\n",
      "  38: '[5, 9]'\n",
      "  39: '[6, 7]'\n",
      "  40: '[6, 8]'\n",
      "  41: '[6, 9]'\n",
      "  42: '[7, 8]'\n",
      "  43: '[7, 9]'\n",
      "  44: '[8, 9]'\n",
      "  45: '[0, 1, 2]'\n",
      "  46: '[0, 1, 3]'\n",
      "  47: '[0, 1, 4]'\n",
      "  48: '[0, 1, 5]'\n",
      "  49: '[0, 1, 6]'\n",
      "  50: '[0, 1, 7]'\n",
      "  51: '[0, 1, 8]'\n",
      "  52: '[0, 1, 9]'\n",
      "  53: '[0, 2, 3]'\n",
      "  54: '[0, 2, 4]'\n",
      "  55: '[0, 2, 5]'\n",
      "  56: '[0, 2, 6]'\n",
      "  57: '[0, 2, 7]'\n",
      "  58: '[0, 2, 8]'\n",
      "  59: '[0, 2, 9]'\n",
      "  60: '[0, 3, 4]'\n",
      "  61: '[0, 3, 5]'\n",
      "  62: '[0, 3, 6]'\n",
      "  63: '[0, 3, 7]'\n",
      "  64: '[0, 3, 8]'\n",
      "  65: '[0, 3, 9]'\n",
      "  66: '[0, 4, 5]'\n",
      "  67: '[0, 4, 6]'\n",
      "  68: '[0, 4, 7]'\n",
      "  69: '[0, 4, 8]'\n",
      "  70: '[0, 4, 9]'\n",
      "  71: '[0, 5, 6]'\n",
      "  72: '[0, 5, 7]'\n",
      "  73: '[0, 5, 8]'\n",
      "  74: '[0, 5, 9]'\n",
      "  75: '[0, 6, 7]'\n",
      "  76: '[0, 6, 8]'\n",
      "  77: '[0, 6, 9]'\n",
      "  78: '[0, 7, 8]'\n",
      "  79: '[0, 7, 9]'\n",
      "  80: '[0, 8, 9]'\n",
      "  81: '[1, 2, 3]'\n",
      "  82: '[1, 2, 4]'\n",
      "  83: '[1, 2, 5]'\n",
      "  84: '[1, 2, 6]'\n",
      "  85: '[1, 2, 7]'\n",
      "  86: '[1, 2, 8]'\n",
      "  87: '[1, 2, 9]'\n",
      "  88: '[1, 3, 4]'\n",
      "  89: '[1, 3, 5]'\n",
      "  90: '[1, 3, 6]'\n",
      "  91: '[1, 3, 7]'\n",
      "  92: '[1, 3, 8]'\n",
      "  93: '[1, 3, 9]'\n",
      "  94: '[1, 4, 5]'\n",
      "  95: '[1, 4, 6]'\n",
      "  96: '[1, 4, 7]'\n",
      "  97: '[1, 4, 8]'\n",
      "  98: '[1, 4, 9]'\n",
      "  99: '[1, 5, 6]'\n",
      "  100: '[1, 5, 7]'\n",
      "  101: '[1, 5, 8]'\n",
      "  102: '[1, 5, 9]'\n",
      "  103: '[1, 6, 7]'\n",
      "  104: '[1, 6, 8]'\n",
      "  105: '[1, 6, 9]'\n",
      "  106: '[1, 7, 8]'\n",
      "  107: '[1, 7, 9]'\n",
      "  108: '[1, 8, 9]'\n",
      "  109: '[2, 3, 4]'\n",
      "  110: '[2, 3, 5]'\n",
      "  111: '[2, 3, 6]'\n",
      "  112: '[2, 3, 7]'\n",
      "  113: '[2, 3, 8]'\n",
      "  114: '[2, 3, 9]'\n",
      "  115: '[2, 4, 5]'\n",
      "  116: '[2, 4, 6]'\n",
      "  117: '[2, 4, 7]'\n",
      "  118: '[2, 4, 8]'\n",
      "  119: '[2, 4, 9]'\n",
      "  120: '[2, 5, 6]'\n",
      "  121: '[2, 5, 7]'\n",
      "  122: '[2, 5, 8]'\n",
      "  123: '[2, 5, 9]'\n",
      "  124: '[2, 6, 7]'\n",
      "  125: '[2, 6, 8]'\n",
      "  126: '[2, 6, 9]'\n",
      "  127: '[2, 7, 8]'\n",
      "  128: '[2, 7, 9]'\n",
      "  129: '[2, 8, 9]'\n",
      "  130: '[3, 4, 5]'\n",
      "  131: '[3, 4, 6]'\n",
      "  132: '[3, 4, 7]'\n",
      "  133: '[3, 4, 8]'\n",
      "  134: '[3, 4, 9]'\n",
      "  135: '[3, 5, 6]'\n",
      "  136: '[3, 5, 7]'\n",
      "  137: '[3, 5, 8]'\n",
      "  138: '[3, 5, 9]'\n",
      "  139: '[3, 6, 7]'\n",
      "  140: '[3, 6, 8]'\n",
      "  141: '[3, 6, 9]'\n",
      "  142: '[3, 7, 8]'\n",
      "  143: '[3, 7, 9]'\n",
      "  144: '[3, 8, 9]'\n",
      "  145: '[4, 5, 6]'\n",
      "  146: '[4, 5, 7]'\n",
      "  147: '[4, 5, 8]'\n",
      "  148: '[4, 5, 9]'\n",
      "  149: '[4, 6, 7]'\n",
      "  150: '[4, 6, 8]'\n",
      "  151: '[4, 6, 9]'\n",
      "  152: '[4, 7, 8]'\n",
      "  153: '[4, 7, 9]'\n",
      "  154: '[4, 8, 9]'\n",
      "  155: '[5, 6, 7]'\n",
      "  156: '[5, 6, 8]'\n",
      "  157: '[5, 6, 9]'\n",
      "  158: '[5, 7, 8]'\n",
      "  159: '[5, 7, 9]'\n",
      "  160: '[5, 8, 9]'\n",
      "  161: '[6, 7, 8]'\n",
      "  162: '[6, 7, 9]'\n",
      "  163: '[6, 8, 9]'\n",
      "  164: '[7, 8, 9]'\n",
      "  165: '[0, 1, 2, 3]'\n",
      "  166: '[0, 1, 2, 4]'\n",
      "  167: '[0, 1, 2, 5]'\n",
      "  168: '[0, 1, 2, 6]'\n",
      "  169: '[0, 1, 2, 7]'\n",
      "  170: '[0, 1, 2, 8]'\n",
      "  171: '[0, 1, 2, 9]'\n",
      "  172: '[0, 1, 3, 4]'\n",
      "  173: '[0, 1, 3, 5]'\n",
      "  174: '[0, 1, 3, 6]'\n",
      "  175: '[0, 1, 3, 7]'\n",
      "  176: '[0, 1, 3, 8]'\n",
      "  177: '[0, 1, 3, 9]'\n",
      "  178: '[0, 1, 4, 5]'\n",
      "  179: '[0, 1, 4, 6]'\n",
      "  180: '[0, 1, 4, 7]'\n",
      "  181: '[0, 1, 4, 8]'\n",
      "  182: '[0, 1, 4, 9]'\n",
      "  183: '[0, 1, 5, 6]'\n",
      "  184: '[0, 1, 5, 7]'\n",
      "  185: '[0, 1, 5, 8]'\n",
      "  186: '[0, 1, 5, 9]'\n",
      "  187: '[0, 1, 6, 7]'\n",
      "  188: '[0, 1, 6, 8]'\n",
      "  189: '[0, 1, 6, 9]'\n",
      "  190: '[0, 1, 7, 8]'\n",
      "  191: '[0, 1, 7, 9]'\n",
      "  192: '[0, 1, 8, 9]'\n",
      "  193: '[0, 2, 3, 4]'\n",
      "  194: '[0, 2, 3, 5]'\n",
      "  195: '[0, 2, 3, 6]'\n",
      "  196: '[0, 2, 3, 7]'\n",
      "  197: '[0, 2, 3, 8]'\n",
      "  198: '[0, 2, 3, 9]'\n",
      "  199: '[0, 2, 4, 5]'\n",
      "  200: '[0, 2, 4, 6]'\n",
      "  201: '[0, 2, 4, 7]'\n",
      "  202: '[0, 2, 4, 8]'\n",
      "  203: '[0, 2, 4, 9]'\n",
      "  204: '[0, 2, 5, 6]'\n",
      "  205: '[0, 2, 5, 7]'\n",
      "  206: '[0, 2, 5, 8]'\n",
      "  207: '[0, 2, 5, 9]'\n",
      "  208: '[0, 2, 6, 7]'\n",
      "  209: '[0, 2, 6, 8]'\n",
      "  210: '[0, 2, 6, 9]'\n",
      "  211: '[0, 2, 7, 8]'\n",
      "  212: '[0, 2, 7, 9]'\n",
      "  213: '[0, 2, 8, 9]'\n",
      "  214: '[0, 3, 4, 5]'\n",
      "  215: '[0, 3, 4, 6]'\n",
      "  216: '[0, 3, 4, 7]'\n",
      "  217: '[0, 3, 4, 8]'\n",
      "  218: '[0, 3, 4, 9]'\n",
      "  219: '[0, 3, 5, 6]'\n",
      "  220: '[0, 3, 5, 7]'\n",
      "  221: '[0, 3, 5, 8]'\n",
      "  222: '[0, 3, 5, 9]'\n",
      "  223: '[0, 3, 6, 7]'\n",
      "  224: '[0, 3, 6, 8]'\n",
      "  225: '[0, 3, 6, 9]'\n",
      "  226: '[0, 3, 7, 8]'\n",
      "  227: '[0, 3, 7, 9]'\n",
      "  228: '[0, 3, 8, 9]'\n",
      "  229: '[0, 4, 5, 6]'\n",
      "  230: '[0, 4, 5, 7]'\n",
      "  231: '[0, 4, 5, 8]'\n",
      "  232: '[0, 4, 5, 9]'\n",
      "  233: '[0, 4, 6, 7]'\n",
      "  234: '[0, 4, 6, 8]'\n",
      "  235: '[0, 4, 6, 9]'\n",
      "  236: '[0, 4, 7, 8]'\n",
      "  237: '[0, 4, 7, 9]'\n",
      "  238: '[0, 4, 8, 9]'\n",
      "  239: '[0, 5, 6, 7]'\n",
      "  240: '[0, 5, 6, 8]'\n",
      "  241: '[0, 5, 6, 9]'\n",
      "  242: '[0, 5, 7, 8]'\n",
      "  243: '[0, 5, 7, 9]'\n",
      "  244: '[0, 5, 8, 9]'\n",
      "  245: '[0, 6, 7, 8]'\n",
      "  246: '[0, 6, 7, 9]'\n",
      "  247: '[0, 6, 8, 9]'\n",
      "  248: '[0, 7, 8, 9]'\n",
      "  249: '[1, 2, 3, 4]'\n",
      "  250: '[1, 2, 3, 5]'\n",
      "  251: '[1, 2, 3, 6]'\n",
      "  252: '[1, 2, 3, 7]'\n",
      "  253: '[1, 2, 3, 8]'\n",
      "  254: '[1, 2, 3, 9]'\n",
      "  255: '[1, 2, 4, 5]'\n",
      "  256: '[1, 2, 4, 6]'\n",
      "  257: '[1, 2, 4, 7]'\n",
      "  258: '[1, 2, 4, 8]'\n",
      "  259: '[1, 2, 4, 9]'\n",
      "  260: '[1, 2, 5, 6]'\n",
      "  261: '[1, 2, 5, 7]'\n",
      "  262: '[1, 2, 5, 8]'\n",
      "  263: '[1, 2, 5, 9]'\n",
      "  264: '[1, 2, 6, 7]'\n",
      "  265: '[1, 2, 6, 8]'\n",
      "  266: '[1, 2, 6, 9]'\n",
      "  267: '[1, 2, 7, 8]'\n",
      "  268: '[1, 2, 7, 9]'\n",
      "  269: '[1, 2, 8, 9]'\n",
      "  270: '[1, 3, 4, 5]'\n",
      "  271: '[1, 3, 4, 6]'\n",
      "  272: '[1, 3, 4, 7]'\n",
      "  273: '[1, 3, 4, 8]'\n",
      "  274: '[1, 3, 4, 9]'\n",
      "  275: '[1, 3, 5, 6]'\n",
      "  276: '[1, 3, 5, 7]'\n",
      "  277: '[1, 3, 5, 8]'\n",
      "  278: '[1, 3, 5, 9]'\n",
      "  279: '[1, 3, 6, 7]'\n",
      "  280: '[1, 3, 6, 8]'\n",
      "  281: '[1, 3, 6, 9]'\n",
      "  282: '[1, 3, 7, 8]'\n",
      "  283: '[1, 3, 7, 9]'\n",
      "  284: '[1, 3, 8, 9]'\n",
      "  285: '[1, 4, 5, 6]'\n",
      "  286: '[1, 4, 5, 7]'\n",
      "  287: '[1, 4, 5, 8]'\n",
      "  288: '[1, 4, 5, 9]'\n",
      "  289: '[1, 4, 6, 7]'\n",
      "  290: '[1, 4, 6, 8]'\n",
      "  291: '[1, 4, 6, 9]'\n",
      "  292: '[1, 4, 7, 8]'\n",
      "  293: '[1, 4, 7, 9]'\n",
      "  294: '[1, 4, 8, 9]'\n",
      "  295: '[1, 5, 6, 7]'\n",
      "  296: '[1, 5, 6, 8]'\n",
      "  297: '[1, 5, 6, 9]'\n",
      "  298: '[1, 5, 7, 8]'\n",
      "  299: '[1, 5, 7, 9]'\n",
      "  300: '[1, 5, 8, 9]'\n",
      "  301: '[1, 6, 7, 8]'\n",
      "  302: '[1, 6, 7, 9]'\n",
      "  303: '[1, 6, 8, 9]'\n",
      "  304: '[1, 7, 8, 9]'\n",
      "  305: '[2, 3, 4, 5]'\n",
      "  306: '[2, 3, 4, 6]'\n",
      "  307: '[2, 3, 4, 7]'\n",
      "  308: '[2, 3, 4, 8]'\n",
      "  309: '[2, 3, 4, 9]'\n",
      "  310: '[2, 3, 5, 6]'\n",
      "  311: '[2, 3, 5, 7]'\n",
      "  312: '[2, 3, 5, 8]'\n",
      "  313: '[2, 3, 5, 9]'\n",
      "  314: '[2, 3, 6, 7]'\n",
      "  315: '[2, 3, 6, 8]'\n",
      "  316: '[2, 3, 6, 9]'\n",
      "  317: '[2, 3, 7, 8]'\n",
      "  318: '[2, 3, 7, 9]'\n",
      "  319: '[2, 3, 8, 9]'\n",
      "  320: '[2, 4, 5, 6]'\n",
      "  321: '[2, 4, 5, 7]'\n",
      "  322: '[2, 4, 5, 8]'\n",
      "  323: '[2, 4, 5, 9]'\n",
      "  324: '[2, 4, 6, 7]'\n",
      "  325: '[2, 4, 6, 8]'\n",
      "  326: '[2, 4, 6, 9]'\n",
      "  327: '[2, 4, 7, 8]'\n",
      "  328: '[2, 4, 7, 9]'\n",
      "  329: '[2, 4, 8, 9]'\n",
      "  330: '[2, 5, 6, 7]'\n",
      "  331: '[2, 5, 6, 8]'\n",
      "  332: '[2, 5, 6, 9]'\n",
      "  333: '[2, 5, 7, 8]'\n",
      "  334: '[2, 5, 7, 9]'\n",
      "  335: '[2, 5, 8, 9]'\n",
      "  336: '[2, 6, 7, 8]'\n",
      "  337: '[2, 6, 7, 9]'\n",
      "  338: '[2, 6, 8, 9]'\n",
      "  339: '[2, 7, 8, 9]'\n",
      "  340: '[3, 4, 5, 6]'\n",
      "  341: '[3, 4, 5, 7]'\n",
      "  342: '[3, 4, 5, 8]'\n",
      "  343: '[3, 4, 5, 9]'\n",
      "  344: '[3, 4, 6, 7]'\n",
      "  345: '[3, 4, 6, 8]'\n",
      "  346: '[3, 4, 6, 9]'\n",
      "  347: '[3, 4, 7, 8]'\n",
      "  348: '[3, 4, 7, 9]'\n",
      "  349: '[3, 4, 8, 9]'\n",
      "  350: '[3, 5, 6, 7]'\n",
      "  351: '[3, 5, 6, 8]'\n",
      "  352: '[3, 5, 6, 9]'\n",
      "  353: '[3, 5, 7, 8]'\n",
      "  354: '[3, 5, 7, 9]'\n",
      "  355: '[3, 5, 8, 9]'\n",
      "  356: '[3, 6, 7, 8]'\n",
      "  357: '[3, 6, 7, 9]'\n",
      "  358: '[3, 6, 8, 9]'\n",
      "  359: '[3, 7, 8, 9]'\n",
      "  360: '[4, 5, 6, 7]'\n",
      "  361: '[4, 5, 6, 8]'\n",
      "  362: '[4, 5, 6, 9]'\n",
      "  363: '[4, 5, 7, 8]'\n",
      "  364: '[4, 5, 7, 9]'\n",
      "  365: '[4, 5, 8, 9]'\n",
      "  366: '[4, 6, 7, 8]'\n",
      "  367: '[4, 6, 7, 9]'\n",
      "  368: '[4, 6, 8, 9]'\n",
      "  369: '[4, 7, 8, 9]'\n",
      "  370: '[5, 6, 7, 8]'\n",
      "  371: '[5, 6, 7, 9]'\n",
      "  372: '[5, 6, 8, 9]'\n",
      "  373: '[5, 7, 8, 9]'\n",
      "  374: '[6, 7, 8, 9]'\n",
      "  375: '[0, 1, 2, 3, 4]'\n",
      "  376: '[0, 1, 2, 3, 5]'\n",
      "  377: '[0, 1, 2, 3, 6]'\n",
      "  378: '[0, 1, 2, 3, 7]'\n",
      "  379: '[0, 1, 2, 3, 8]'\n",
      "  380: '[0, 1, 2, 3, 9]'\n",
      "  381: '[0, 1, 2, 4, 5]'\n",
      "  382: '[0, 1, 2, 4, 6]'\n",
      "  383: '[0, 1, 2, 4, 7]'\n",
      "  384: '[0, 1, 2, 4, 8]'\n",
      "  385: '[0, 1, 2, 4, 9]'\n",
      "  386: '[0, 1, 2, 5, 6]'\n",
      "  387: '[0, 1, 2, 5, 7]'\n",
      "  388: '[0, 1, 2, 5, 8]'\n",
      "  389: '[0, 1, 2, 5, 9]'\n",
      "  390: '[0, 1, 2, 6, 7]'\n",
      "  391: '[0, 1, 2, 6, 8]'\n",
      "  392: '[0, 1, 2, 6, 9]'\n",
      "  393: '[0, 1, 2, 7, 8]'\n",
      "  394: '[0, 1, 2, 7, 9]'\n",
      "  395: '[0, 1, 2, 8, 9]'\n",
      "  396: '[0, 1, 3, 4, 5]'\n",
      "  397: '[0, 1, 3, 4, 6]'\n",
      "  398: '[0, 1, 3, 4, 7]'\n",
      "  399: '[0, 1, 3, 4, 8]'\n",
      "  400: '[0, 1, 3, 4, 9]'\n",
      "  401: '[0, 1, 3, 5, 6]'\n",
      "  402: '[0, 1, 3, 5, 7]'\n",
      "  403: '[0, 1, 3, 5, 8]'\n",
      "  404: '[0, 1, 3, 5, 9]'\n",
      "  405: '[0, 1, 3, 6, 7]'\n",
      "  406: '[0, 1, 3, 6, 8]'\n",
      "  407: '[0, 1, 3, 6, 9]'\n",
      "  408: '[0, 1, 3, 7, 8]'\n",
      "  409: '[0, 1, 3, 7, 9]'\n",
      "  410: '[0, 1, 3, 8, 9]'\n",
      "  411: '[0, 1, 4, 5, 6]'\n",
      "  412: '[0, 1, 4, 5, 7]'\n",
      "  413: '[0, 1, 4, 5, 8]'\n",
      "  414: '[0, 1, 4, 5, 9]'\n",
      "  415: '[0, 1, 4, 6, 7]'\n",
      "  416: '[0, 1, 4, 6, 8]'\n",
      "  417: '[0, 1, 4, 6, 9]'\n",
      "  418: '[0, 1, 4, 7, 8]'\n",
      "  419: '[0, 1, 4, 7, 9]'\n",
      "  420: '[0, 1, 4, 8, 9]'\n",
      "  421: '[0, 1, 5, 6, 7]'\n",
      "  422: '[0, 1, 5, 6, 8]'\n",
      "  423: '[0, 1, 5, 6, 9]'\n",
      "  424: '[0, 1, 5, 7, 8]'\n",
      "  425: '[0, 1, 5, 7, 9]'\n",
      "  426: '[0, 1, 5, 8, 9]'\n",
      "  427: '[0, 1, 6, 7, 8]'\n",
      "  428: '[0, 1, 6, 7, 9]'\n",
      "  429: '[0, 1, 6, 8, 9]'\n",
      "  430: '[0, 1, 7, 8, 9]'\n",
      "  431: '[0, 2, 3, 4, 5]'\n",
      "  432: '[0, 2, 3, 4, 6]'\n",
      "  433: '[0, 2, 3, 4, 7]'\n",
      "  434: '[0, 2, 3, 4, 8]'\n",
      "  435: '[0, 2, 3, 4, 9]'\n",
      "  436: '[0, 2, 3, 5, 6]'\n",
      "  437: '[0, 2, 3, 5, 7]'\n",
      "  438: '[0, 2, 3, 5, 8]'\n",
      "  439: '[0, 2, 3, 5, 9]'\n",
      "  440: '[0, 2, 3, 6, 7]'\n",
      "  441: '[0, 2, 3, 6, 8]'\n",
      "  442: '[0, 2, 3, 6, 9]'\n",
      "  443: '[0, 2, 3, 7, 8]'\n",
      "  444: '[0, 2, 3, 7, 9]'\n",
      "  445: '[0, 2, 3, 8, 9]'\n",
      "  446: '[0, 2, 4, 5, 6]'\n",
      "  447: '[0, 2, 4, 5, 7]'\n",
      "  448: '[0, 2, 4, 5, 8]'\n",
      "  449: '[0, 2, 4, 5, 9]'\n",
      "  450: '[0, 2, 4, 6, 7]'\n",
      "  451: '[0, 2, 4, 6, 8]'\n",
      "  452: '[0, 2, 4, 6, 9]'\n",
      "  453: '[0, 2, 4, 7, 8]'\n",
      "  454: '[0, 2, 4, 7, 9]'\n",
      "  455: '[0, 2, 4, 8, 9]'\n",
      "  456: '[0, 2, 5, 6, 7]'\n",
      "  457: '[0, 2, 5, 6, 8]'\n",
      "  458: '[0, 2, 5, 6, 9]'\n",
      "  459: '[0, 2, 5, 7, 8]'\n",
      "  460: '[0, 2, 5, 7, 9]'\n",
      "  461: '[0, 2, 5, 8, 9]'\n",
      "  462: '[0, 2, 6, 7, 8]'\n",
      "  463: '[0, 2, 6, 7, 9]'\n",
      "  464: '[0, 2, 6, 8, 9]'\n",
      "  465: '[0, 2, 7, 8, 9]'\n",
      "  466: '[0, 3, 4, 5, 6]'\n",
      "  467: '[0, 3, 4, 5, 7]'\n",
      "  468: '[0, 3, 4, 5, 8]'\n",
      "  469: '[0, 3, 4, 5, 9]'\n",
      "  470: '[0, 3, 4, 6, 7]'\n",
      "  471: '[0, 3, 4, 6, 8]'\n",
      "  472: '[0, 3, 4, 6, 9]'\n",
      "  473: '[0, 3, 4, 7, 8]'\n",
      "  474: '[0, 3, 4, 7, 9]'\n",
      "  475: '[0, 3, 4, 8, 9]'\n",
      "  476: '[0, 3, 5, 6, 7]'\n",
      "  477: '[0, 3, 5, 6, 8]'\n",
      "  478: '[0, 3, 5, 6, 9]'\n",
      "  479: '[0, 3, 5, 7, 8]'\n",
      "  480: '[0, 3, 5, 7, 9]'\n",
      "  481: '[0, 3, 5, 8, 9]'\n",
      "  482: '[0, 3, 6, 7, 8]'\n",
      "  483: '[0, 3, 6, 7, 9]'\n",
      "  484: '[0, 3, 6, 8, 9]'\n",
      "  485: '[0, 3, 7, 8, 9]'\n",
      "  486: '[0, 4, 5, 6, 7]'\n",
      "  487: '[0, 4, 5, 6, 8]'\n",
      "  488: '[0, 4, 5, 6, 9]'\n",
      "  489: '[0, 4, 5, 7, 8]'\n",
      "  490: '[0, 4, 5, 7, 9]'\n",
      "  491: '[0, 4, 5, 8, 9]'\n",
      "  492: '[0, 4, 6, 7, 8]'\n",
      "  493: '[0, 4, 6, 7, 9]'\n",
      "  494: '[0, 4, 6, 8, 9]'\n",
      "  495: '[0, 4, 7, 8, 9]'\n",
      "  496: '[0, 5, 6, 7, 8]'\n",
      "  497: '[0, 5, 6, 7, 9]'\n",
      "  498: '[0, 5, 6, 8, 9]'\n",
      "  499: '[0, 5, 7, 8, 9]'\n",
      "  500: '[0, 6, 7, 8, 9]'\n",
      "  501: '[1, 2, 3, 4, 5]'\n",
      "  502: '[1, 2, 3, 4, 6]'\n",
      "  503: '[1, 2, 3, 4, 7]'\n",
      "  504: '[1, 2, 3, 4, 8]'\n",
      "  505: '[1, 2, 3, 4, 9]'\n",
      "  506: '[1, 2, 3, 5, 6]'\n",
      "  507: '[1, 2, 3, 5, 7]'\n",
      "  508: '[1, 2, 3, 5, 8]'\n",
      "  509: '[1, 2, 3, 5, 9]'\n",
      "  510: '[1, 2, 3, 6, 7]'\n",
      "  511: '[1, 2, 3, 6, 8]'\n",
      "  512: '[1, 2, 3, 6, 9]'\n",
      "  513: '[1, 2, 3, 7, 8]'\n",
      "  514: '[1, 2, 3, 7, 9]'\n",
      "  515: '[1, 2, 3, 8, 9]'\n",
      "  516: '[1, 2, 4, 5, 6]'\n",
      "  517: '[1, 2, 4, 5, 7]'\n",
      "  518: '[1, 2, 4, 5, 8]'\n",
      "  519: '[1, 2, 4, 5, 9]'\n",
      "  520: '[1, 2, 4, 6, 7]'\n",
      "  521: '[1, 2, 4, 6, 8]'\n",
      "  522: '[1, 2, 4, 6, 9]'\n",
      "  523: '[1, 2, 4, 7, 8]'\n",
      "  524: '[1, 2, 4, 7, 9]'\n",
      "  525: '[1, 2, 4, 8, 9]'\n",
      "  526: '[1, 2, 5, 6, 7]'\n",
      "  527: '[1, 2, 5, 6, 8]'\n",
      "  528: '[1, 2, 5, 6, 9]'\n",
      "  529: '[1, 2, 5, 7, 8]'\n",
      "  530: '[1, 2, 5, 7, 9]'\n",
      "  531: '[1, 2, 5, 8, 9]'\n",
      "  532: '[1, 2, 6, 7, 8]'\n",
      "  533: '[1, 2, 6, 7, 9]'\n",
      "  534: '[1, 2, 6, 8, 9]'\n",
      "  535: '[1, 2, 7, 8, 9]'\n",
      "  536: '[1, 3, 4, 5, 6]'\n",
      "  537: '[1, 3, 4, 5, 7]'\n",
      "  538: '[1, 3, 4, 5, 8]'\n",
      "  539: '[1, 3, 4, 5, 9]'\n",
      "  540: '[1, 3, 4, 6, 7]'\n",
      "  541: '[1, 3, 4, 6, 8]'\n",
      "  542: '[1, 3, 4, 6, 9]'\n",
      "  543: '[1, 3, 4, 7, 8]'\n",
      "  544: '[1, 3, 4, 7, 9]'\n",
      "  545: '[1, 3, 4, 8, 9]'\n",
      "  546: '[1, 3, 5, 6, 7]'\n",
      "  547: '[1, 3, 5, 6, 8]'\n",
      "  548: '[1, 3, 5, 6, 9]'\n",
      "  549: '[1, 3, 5, 7, 8]'\n",
      "  550: '[1, 3, 5, 7, 9]'\n",
      "  551: '[1, 3, 5, 8, 9]'\n",
      "  552: '[1, 3, 6, 7, 8]'\n",
      "  553: '[1, 3, 6, 7, 9]'\n",
      "  554: '[1, 3, 6, 8, 9]'\n",
      "  555: '[1, 3, 7, 8, 9]'\n",
      "  556: '[1, 4, 5, 6, 7]'\n",
      "  557: '[1, 4, 5, 6, 8]'\n",
      "  558: '[1, 4, 5, 6, 9]'\n",
      "  559: '[1, 4, 5, 7, 8]'\n",
      "  560: '[1, 4, 5, 7, 9]'\n",
      "  561: '[1, 4, 5, 8, 9]'\n",
      "  562: '[1, 4, 6, 7, 8]'\n",
      "  563: '[1, 4, 6, 7, 9]'\n",
      "  564: '[1, 4, 6, 8, 9]'\n",
      "  565: '[1, 4, 7, 8, 9]'\n",
      "  566: '[1, 5, 6, 7, 8]'\n",
      "  567: '[1, 5, 6, 7, 9]'\n",
      "  568: '[1, 5, 6, 8, 9]'\n",
      "  569: '[1, 5, 7, 8, 9]'\n",
      "  570: '[1, 6, 7, 8, 9]'\n",
      "  571: '[2, 3, 4, 5, 6]'\n",
      "  572: '[2, 3, 4, 5, 7]'\n",
      "  573: '[2, 3, 4, 5, 8]'\n",
      "  574: '[2, 3, 4, 5, 9]'\n",
      "  575: '[2, 3, 4, 6, 7]'\n",
      "  576: '[2, 3, 4, 6, 8]'\n",
      "  577: '[2, 3, 4, 6, 9]'\n",
      "  578: '[2, 3, 4, 7, 8]'\n",
      "  579: '[2, 3, 4, 7, 9]'\n",
      "  580: '[2, 3, 4, 8, 9]'\n",
      "  581: '[2, 3, 5, 6, 7]'\n",
      "  582: '[2, 3, 5, 6, 8]'\n",
      "  583: '[2, 3, 5, 6, 9]'\n",
      "  584: '[2, 3, 5, 7, 8]'\n",
      "  585: '[2, 3, 5, 7, 9]'\n",
      "  586: '[2, 3, 5, 8, 9]'\n",
      "  587: '[2, 3, 6, 7, 8]'\n",
      "  588: '[2, 3, 6, 7, 9]'\n",
      "  589: '[2, 3, 6, 8, 9]'\n",
      "  590: '[2, 3, 7, 8, 9]'\n",
      "  591: '[2, 4, 5, 6, 7]'\n",
      "  592: '[2, 4, 5, 6, 8]'\n",
      "  593: '[2, 4, 5, 6, 9]'\n",
      "  594: '[2, 4, 5, 7, 8]'\n",
      "  595: '[2, 4, 5, 7, 9]'\n",
      "  596: '[2, 4, 5, 8, 9]'\n",
      "  597: '[2, 4, 6, 7, 8]'\n",
      "  598: '[2, 4, 6, 7, 9]'\n",
      "  599: '[2, 4, 6, 8, 9]'\n",
      "  600: '[2, 4, 7, 8, 9]'\n",
      "  601: '[2, 5, 6, 7, 8]'\n",
      "  602: '[2, 5, 6, 7, 9]'\n",
      "  603: '[2, 5, 6, 8, 9]'\n",
      "  604: '[2, 5, 7, 8, 9]'\n",
      "  605: '[2, 6, 7, 8, 9]'\n",
      "  606: '[3, 4, 5, 6, 7]'\n",
      "  607: '[3, 4, 5, 6, 8]'\n",
      "  608: '[3, 4, 5, 6, 9]'\n",
      "  609: '[3, 4, 5, 7, 8]'\n",
      "  610: '[3, 4, 5, 7, 9]'\n",
      "  611: '[3, 4, 5, 8, 9]'\n",
      "  612: '[3, 4, 6, 7, 8]'\n",
      "  613: '[3, 4, 6, 7, 9]'\n",
      "  614: '[3, 4, 6, 8, 9]'\n",
      "  615: '[3, 4, 7, 8, 9]'\n",
      "  616: '[3, 5, 6, 7, 8]'\n",
      "  617: '[3, 5, 6, 7, 9]'\n",
      "  618: '[3, 5, 6, 8, 9]'\n",
      "  619: '[3, 5, 7, 8, 9]'\n",
      "  620: '[3, 6, 7, 8, 9]'\n",
      "  621: '[4, 5, 6, 7, 8]'\n",
      "  622: '[4, 5, 6, 7, 9]'\n",
      "  623: '[4, 5, 6, 8, 9]'\n",
      "  624: '[4, 5, 7, 8, 9]'\n",
      "  625: '[4, 6, 7, 8, 9]'\n",
      "  626: '[5, 6, 7, 8, 9]'\n",
      "  627: '[0, 1, 2, 3, 4, 5]'\n",
      "  628: '[0, 1, 2, 3, 4, 6]'\n",
      "  629: '[0, 1, 2, 3, 4, 7]'\n",
      "  630: '[0, 1, 2, 3, 4, 8]'\n",
      "  631: '[0, 1, 2, 3, 4, 9]'\n",
      "  632: '[0, 1, 2, 3, 5, 6]'\n",
      "  633: '[0, 1, 2, 3, 5, 7]'\n",
      "  634: '[0, 1, 2, 3, 5, 8]'\n",
      "  635: '[0, 1, 2, 3, 5, 9]'\n",
      "  636: '[0, 1, 2, 3, 6, 7]'\n",
      "  637: '[0, 1, 2, 3, 6, 8]'\n",
      "  638: '[0, 1, 2, 3, 6, 9]'\n",
      "  639: '[0, 1, 2, 3, 7, 8]'\n",
      "  640: '[0, 1, 2, 3, 7, 9]'\n",
      "  641: '[0, 1, 2, 3, 8, 9]'\n",
      "  642: '[0, 1, 2, 4, 5, 6]'\n",
      "  643: '[0, 1, 2, 4, 5, 7]'\n",
      "  644: '[0, 1, 2, 4, 5, 8]'\n",
      "  645: '[0, 1, 2, 4, 5, 9]'\n",
      "  646: '[0, 1, 2, 4, 6, 7]'\n",
      "  647: '[0, 1, 2, 4, 6, 8]'\n",
      "  648: '[0, 1, 2, 4, 6, 9]'\n",
      "  649: '[0, 1, 2, 4, 7, 8]'\n",
      "  650: '[0, 1, 2, 4, 7, 9]'\n",
      "  651: '[0, 1, 2, 4, 8, 9]'\n",
      "  652: '[0, 1, 2, 5, 6, 7]'\n",
      "  653: '[0, 1, 2, 5, 6, 8]'\n",
      "  654: '[0, 1, 2, 5, 6, 9]'\n",
      "  655: '[0, 1, 2, 5, 7, 8]'\n",
      "  656: '[0, 1, 2, 5, 7, 9]'\n",
      "  657: '[0, 1, 2, 5, 8, 9]'\n",
      "  658: '[0, 1, 2, 6, 7, 8]'\n",
      "  659: '[0, 1, 2, 6, 7, 9]'\n",
      "  660: '[0, 1, 2, 6, 8, 9]'\n",
      "  661: '[0, 1, 2, 7, 8, 9]'\n",
      "  662: '[0, 1, 3, 4, 5, 6]'\n",
      "  663: '[0, 1, 3, 4, 5, 7]'\n",
      "  664: '[0, 1, 3, 4, 5, 8]'\n",
      "  665: '[0, 1, 3, 4, 5, 9]'\n",
      "  666: '[0, 1, 3, 4, 6, 7]'\n",
      "  667: '[0, 1, 3, 4, 6, 8]'\n",
      "  668: '[0, 1, 3, 4, 6, 9]'\n",
      "  669: '[0, 1, 3, 4, 7, 8]'\n",
      "  670: '[0, 1, 3, 4, 7, 9]'\n",
      "  671: '[0, 1, 3, 4, 8, 9]'\n",
      "  672: '[0, 1, 3, 5, 6, 7]'\n",
      "  673: '[0, 1, 3, 5, 6, 8]'\n",
      "  674: '[0, 1, 3, 5, 6, 9]'\n",
      "  675: '[0, 1, 3, 5, 7, 8]'\n",
      "  676: '[0, 1, 3, 5, 7, 9]'\n",
      "  677: '[0, 1, 3, 5, 8, 9]'\n",
      "  678: '[0, 1, 3, 6, 7, 8]'\n",
      "  679: '[0, 1, 3, 6, 7, 9]'\n",
      "  680: '[0, 1, 3, 6, 8, 9]'\n",
      "  681: '[0, 1, 3, 7, 8, 9]'\n",
      "  682: '[0, 1, 4, 5, 6, 7]'\n",
      "  683: '[0, 1, 4, 5, 6, 8]'\n",
      "  684: '[0, 1, 4, 5, 6, 9]'\n",
      "  685: '[0, 1, 4, 5, 7, 8]'\n",
      "  686: '[0, 1, 4, 5, 7, 9]'\n",
      "  687: '[0, 1, 4, 5, 8, 9]'\n",
      "  688: '[0, 1, 4, 6, 7, 8]'\n",
      "  689: '[0, 1, 4, 6, 7, 9]'\n",
      "  690: '[0, 1, 4, 6, 8, 9]'\n",
      "  691: '[0, 1, 4, 7, 8, 9]'\n",
      "  692: '[0, 1, 5, 6, 7, 8]'\n",
      "  693: '[0, 1, 5, 6, 7, 9]'\n",
      "  694: '[0, 1, 5, 6, 8, 9]'\n",
      "  695: '[0, 1, 5, 7, 8, 9]'\n",
      "  696: '[0, 1, 6, 7, 8, 9]'\n",
      "  697: '[0, 2, 3, 4, 5, 6]'\n",
      "  698: '[0, 2, 3, 4, 5, 7]'\n",
      "  699: '[0, 2, 3, 4, 5, 8]'\n",
      "  700: '[0, 2, 3, 4, 5, 9]'\n",
      "  701: '[0, 2, 3, 4, 6, 7]'\n",
      "  702: '[0, 2, 3, 4, 6, 8]'\n",
      "  703: '[0, 2, 3, 4, 6, 9]'\n",
      "  704: '[0, 2, 3, 4, 7, 8]'\n",
      "  705: '[0, 2, 3, 4, 7, 9]'\n",
      "  706: '[0, 2, 3, 4, 8, 9]'\n",
      "  707: '[0, 2, 3, 5, 6, 7]'\n",
      "  708: '[0, 2, 3, 5, 6, 8]'\n",
      "  709: '[0, 2, 3, 5, 6, 9]'\n",
      "  710: '[0, 2, 3, 5, 7, 8]'\n",
      "  711: '[0, 2, 3, 5, 7, 9]'\n",
      "  712: '[0, 2, 3, 5, 8, 9]'\n",
      "  713: '[0, 2, 3, 6, 7, 8]'\n",
      "  714: '[0, 2, 3, 6, 7, 9]'\n",
      "  715: '[0, 2, 3, 6, 8, 9]'\n",
      "  716: '[0, 2, 3, 7, 8, 9]'\n",
      "  717: '[0, 2, 4, 5, 6, 7]'\n",
      "  718: '[0, 2, 4, 5, 6, 8]'\n",
      "  719: '[0, 2, 4, 5, 6, 9]'\n",
      "  720: '[0, 2, 4, 5, 7, 8]'\n",
      "  721: '[0, 2, 4, 5, 7, 9]'\n",
      "  722: '[0, 2, 4, 5, 8, 9]'\n",
      "  723: '[0, 2, 4, 6, 7, 8]'\n",
      "  724: '[0, 2, 4, 6, 7, 9]'\n",
      "  725: '[0, 2, 4, 6, 8, 9]'\n",
      "  726: '[0, 2, 4, 7, 8, 9]'\n",
      "  727: '[0, 2, 5, 6, 7, 8]'\n",
      "  728: '[0, 2, 5, 6, 7, 9]'\n",
      "  729: '[0, 2, 5, 6, 8, 9]'\n",
      "  730: '[0, 2, 5, 7, 8, 9]'\n",
      "  731: '[0, 2, 6, 7, 8, 9]'\n",
      "  732: '[0, 3, 4, 5, 6, 7]'\n",
      "  733: '[0, 3, 4, 5, 6, 8]'\n",
      "  734: '[0, 3, 4, 5, 6, 9]'\n",
      "  735: '[0, 3, 4, 5, 7, 8]'\n",
      "  736: '[0, 3, 4, 5, 7, 9]'\n",
      "  737: '[0, 3, 4, 5, 8, 9]'\n",
      "  738: '[0, 3, 4, 6, 7, 8]'\n",
      "  739: '[0, 3, 4, 6, 7, 9]'\n",
      "  740: '[0, 3, 4, 6, 8, 9]'\n",
      "  741: '[0, 3, 4, 7, 8, 9]'\n",
      "  742: '[0, 3, 5, 6, 7, 8]'\n",
      "  743: '[0, 3, 5, 6, 7, 9]'\n",
      "  744: '[0, 3, 5, 6, 8, 9]'\n",
      "  745: '[0, 3, 5, 7, 8, 9]'\n",
      "  746: '[0, 3, 6, 7, 8, 9]'\n",
      "  747: '[0, 4, 5, 6, 7, 8]'\n",
      "  748: '[0, 4, 5, 6, 7, 9]'\n",
      "  749: '[0, 4, 5, 6, 8, 9]'\n",
      "  750: '[0, 4, 5, 7, 8, 9]'\n",
      "  751: '[0, 4, 6, 7, 8, 9]'\n",
      "  752: '[0, 5, 6, 7, 8, 9]'\n",
      "  753: '[1, 2, 3, 4, 5, 6]'\n",
      "  754: '[1, 2, 3, 4, 5, 7]'\n",
      "  755: '[1, 2, 3, 4, 5, 8]'\n",
      "  756: '[1, 2, 3, 4, 5, 9]'\n",
      "  757: '[1, 2, 3, 4, 6, 7]'\n",
      "  758: '[1, 2, 3, 4, 6, 8]'\n",
      "  759: '[1, 2, 3, 4, 6, 9]'\n",
      "  760: '[1, 2, 3, 4, 7, 8]'\n",
      "  761: '[1, 2, 3, 4, 7, 9]'\n",
      "  762: '[1, 2, 3, 4, 8, 9]'\n",
      "  763: '[1, 2, 3, 5, 6, 7]'\n",
      "  764: '[1, 2, 3, 5, 6, 8]'\n",
      "  765: '[1, 2, 3, 5, 6, 9]'\n",
      "  766: '[1, 2, 3, 5, 7, 8]'\n",
      "  767: '[1, 2, 3, 5, 7, 9]'\n",
      "  768: '[1, 2, 3, 5, 8, 9]'\n",
      "  769: '[1, 2, 3, 6, 7, 8]'\n",
      "  770: '[1, 2, 3, 6, 7, 9]'\n",
      "  771: '[1, 2, 3, 6, 8, 9]'\n",
      "  772: '[1, 2, 3, 7, 8, 9]'\n",
      "  773: '[1, 2, 4, 5, 6, 7]'\n",
      "  774: '[1, 2, 4, 5, 6, 8]'\n",
      "  775: '[1, 2, 4, 5, 6, 9]'\n",
      "  776: '[1, 2, 4, 5, 7, 8]'\n",
      "  777: '[1, 2, 4, 5, 7, 9]'\n",
      "  778: '[1, 2, 4, 5, 8, 9]'\n",
      "  779: '[1, 2, 4, 6, 7, 8]'\n",
      "  780: '[1, 2, 4, 6, 7, 9]'\n",
      "  781: '[1, 2, 4, 6, 8, 9]'\n",
      "  782: '[1, 2, 4, 7, 8, 9]'\n",
      "  783: '[1, 2, 5, 6, 7, 8]'\n",
      "  784: '[1, 2, 5, 6, 7, 9]'\n",
      "  785: '[1, 2, 5, 6, 8, 9]'\n",
      "  786: '[1, 2, 5, 7, 8, 9]'\n",
      "  787: '[1, 2, 6, 7, 8, 9]'\n",
      "  788: '[1, 3, 4, 5, 6, 7]'\n",
      "  789: '[1, 3, 4, 5, 6, 8]'\n",
      "  790: '[1, 3, 4, 5, 6, 9]'\n",
      "  791: '[1, 3, 4, 5, 7, 8]'\n",
      "  792: '[1, 3, 4, 5, 7, 9]'\n",
      "  793: '[1, 3, 4, 5, 8, 9]'\n",
      "  794: '[1, 3, 4, 6, 7, 8]'\n",
      "  795: '[1, 3, 4, 6, 7, 9]'\n",
      "  796: '[1, 3, 4, 6, 8, 9]'\n",
      "  797: '[1, 3, 4, 7, 8, 9]'\n",
      "  798: '[1, 3, 5, 6, 7, 8]'\n",
      "  799: '[1, 3, 5, 6, 7, 9]'\n",
      "  800: '[1, 3, 5, 6, 8, 9]'\n",
      "  801: '[1, 3, 5, 7, 8, 9]'\n",
      "  802: '[1, 3, 6, 7, 8, 9]'\n",
      "  803: '[1, 4, 5, 6, 7, 8]'\n",
      "  804: '[1, 4, 5, 6, 7, 9]'\n",
      "  805: '[1, 4, 5, 6, 8, 9]'\n",
      "  806: '[1, 4, 5, 7, 8, 9]'\n",
      "  807: '[1, 4, 6, 7, 8, 9]'\n",
      "  808: '[1, 5, 6, 7, 8, 9]'\n",
      "  809: '[2, 3, 4, 5, 6, 7]'\n",
      "  810: '[2, 3, 4, 5, 6, 8]'\n",
      "  811: '[2, 3, 4, 5, 6, 9]'\n",
      "  812: '[2, 3, 4, 5, 7, 8]'\n",
      "  813: '[2, 3, 4, 5, 7, 9]'\n",
      "  814: '[2, 3, 4, 5, 8, 9]'\n",
      "  815: '[2, 3, 4, 6, 7, 8]'\n",
      "  816: '[2, 3, 4, 6, 7, 9]'\n",
      "  817: '[2, 3, 4, 6, 8, 9]'\n",
      "  818: '[2, 3, 4, 7, 8, 9]'\n",
      "  819: '[2, 3, 5, 6, 7, 8]'\n",
      "  820: '[2, 3, 5, 6, 7, 9]'\n",
      "  821: '[2, 3, 5, 6, 8, 9]'\n",
      "  822: '[2, 3, 5, 7, 8, 9]'\n",
      "  823: '[2, 3, 6, 7, 8, 9]'\n",
      "  824: '[2, 4, 5, 6, 7, 8]'\n",
      "  825: '[2, 4, 5, 6, 7, 9]'\n",
      "  826: '[2, 4, 5, 6, 8, 9]'\n",
      "  827: '[2, 4, 5, 7, 8, 9]'\n",
      "  828: '[2, 4, 6, 7, 8, 9]'\n",
      "  829: '[2, 5, 6, 7, 8, 9]'\n",
      "  830: '[3, 4, 5, 6, 7, 8]'\n",
      "  831: '[3, 4, 5, 6, 7, 9]'\n",
      "  832: '[3, 4, 5, 6, 8, 9]'\n",
      "  833: '[3, 4, 5, 7, 8, 9]'\n",
      "  834: '[3, 4, 6, 7, 8, 9]'\n",
      "  835: '[3, 5, 6, 7, 8, 9]'\n",
      "  836: '[4, 5, 6, 7, 8, 9]'\n",
      "  837: '[0, 1, 2, 3, 4, 5, 6]'\n",
      "  838: '[0, 1, 2, 3, 4, 5, 7]'\n",
      "  839: '[0, 1, 2, 3, 4, 5, 8]'\n",
      "  840: '[0, 1, 2, 3, 4, 5, 9]'\n",
      "  841: '[0, 1, 2, 3, 4, 6, 7]'\n",
      "  842: '[0, 1, 2, 3, 4, 6, 8]'\n",
      "  843: '[0, 1, 2, 3, 4, 6, 9]'\n",
      "  844: '[0, 1, 2, 3, 4, 7, 8]'\n",
      "  845: '[0, 1, 2, 3, 4, 7, 9]'\n",
      "  846: '[0, 1, 2, 3, 4, 8, 9]'\n",
      "  847: '[0, 1, 2, 3, 5, 6, 7]'\n",
      "  848: '[0, 1, 2, 3, 5, 6, 8]'\n",
      "  849: '[0, 1, 2, 3, 5, 6, 9]'\n",
      "  850: '[0, 1, 2, 3, 5, 7, 8]'\n",
      "  851: '[0, 1, 2, 3, 5, 7, 9]'\n",
      "  852: '[0, 1, 2, 3, 5, 8, 9]'\n",
      "  853: '[0, 1, 2, 3, 6, 7, 8]'\n",
      "  854: '[0, 1, 2, 3, 6, 7, 9]'\n",
      "  855: '[0, 1, 2, 3, 6, 8, 9]'\n",
      "  856: '[0, 1, 2, 3, 7, 8, 9]'\n",
      "  857: '[0, 1, 2, 4, 5, 6, 7]'\n",
      "  858: '[0, 1, 2, 4, 5, 6, 8]'\n",
      "  859: '[0, 1, 2, 4, 5, 6, 9]'\n",
      "  860: '[0, 1, 2, 4, 5, 7, 8]'\n",
      "  861: '[0, 1, 2, 4, 5, 7, 9]'\n",
      "  862: '[0, 1, 2, 4, 5, 8, 9]'\n",
      "  863: '[0, 1, 2, 4, 6, 7, 8]'\n",
      "  864: '[0, 1, 2, 4, 6, 7, 9]'\n",
      "  865: '[0, 1, 2, 4, 6, 8, 9]'\n",
      "  866: '[0, 1, 2, 4, 7, 8, 9]'\n",
      "  867: '[0, 1, 2, 5, 6, 7, 8]'\n",
      "  868: '[0, 1, 2, 5, 6, 7, 9]'\n",
      "  869: '[0, 1, 2, 5, 6, 8, 9]'\n",
      "  870: '[0, 1, 2, 5, 7, 8, 9]'\n",
      "  871: '[0, 1, 2, 6, 7, 8, 9]'\n",
      "  872: '[0, 1, 3, 4, 5, 6, 7]'\n",
      "  873: '[0, 1, 3, 4, 5, 6, 8]'\n",
      "  874: '[0, 1, 3, 4, 5, 6, 9]'\n",
      "  875: '[0, 1, 3, 4, 5, 7, 8]'\n",
      "  876: '[0, 1, 3, 4, 5, 7, 9]'\n",
      "  877: '[0, 1, 3, 4, 5, 8, 9]'\n",
      "  878: '[0, 1, 3, 4, 6, 7, 8]'\n",
      "  879: '[0, 1, 3, 4, 6, 7, 9]'\n",
      "  880: '[0, 1, 3, 4, 6, 8, 9]'\n",
      "  881: '[0, 1, 3, 4, 7, 8, 9]'\n",
      "  882: '[0, 1, 3, 5, 6, 7, 8]'\n",
      "  883: '[0, 1, 3, 5, 6, 7, 9]'\n",
      "  884: '[0, 1, 3, 5, 6, 8, 9]'\n",
      "  885: '[0, 1, 3, 5, 7, 8, 9]'\n",
      "  886: '[0, 1, 3, 6, 7, 8, 9]'\n",
      "  887: '[0, 1, 4, 5, 6, 7, 8]'\n",
      "  888: '[0, 1, 4, 5, 6, 7, 9]'\n",
      "  889: '[0, 1, 4, 5, 6, 8, 9]'\n",
      "  890: '[0, 1, 4, 5, 7, 8, 9]'\n",
      "  891: '[0, 1, 4, 6, 7, 8, 9]'\n",
      "  892: '[0, 1, 5, 6, 7, 8, 9]'\n",
      "  893: '[0, 2, 3, 4, 5, 6, 7]'\n",
      "  894: '[0, 2, 3, 4, 5, 6, 8]'\n",
      "  895: '[0, 2, 3, 4, 5, 6, 9]'\n",
      "  896: '[0, 2, 3, 4, 5, 7, 8]'\n",
      "  897: '[0, 2, 3, 4, 5, 7, 9]'\n",
      "  898: '[0, 2, 3, 4, 5, 8, 9]'\n",
      "  899: '[0, 2, 3, 4, 6, 7, 8]'\n",
      "  900: '[0, 2, 3, 4, 6, 7, 9]'\n",
      "  901: '[0, 2, 3, 4, 6, 8, 9]'\n",
      "  902: '[0, 2, 3, 4, 7, 8, 9]'\n",
      "  903: '[0, 2, 3, 5, 6, 7, 8]'\n",
      "  904: '[0, 2, 3, 5, 6, 7, 9]'\n",
      "  905: '[0, 2, 3, 5, 6, 8, 9]'\n",
      "  906: '[0, 2, 3, 5, 7, 8, 9]'\n",
      "  907: '[0, 2, 3, 6, 7, 8, 9]'\n",
      "  908: '[0, 2, 4, 5, 6, 7, 8]'\n",
      "  909: '[0, 2, 4, 5, 6, 7, 9]'\n",
      "  910: '[0, 2, 4, 5, 6, 8, 9]'\n",
      "  911: '[0, 2, 4, 5, 7, 8, 9]'\n",
      "  912: '[0, 2, 4, 6, 7, 8, 9]'\n",
      "  913: '[0, 2, 5, 6, 7, 8, 9]'\n",
      "  914: '[0, 3, 4, 5, 6, 7, 8]'\n",
      "  915: '[0, 3, 4, 5, 6, 7, 9]'\n",
      "  916: '[0, 3, 4, 5, 6, 8, 9]'\n",
      "  917: '[0, 3, 4, 5, 7, 8, 9]'\n",
      "  918: '[0, 3, 4, 6, 7, 8, 9]'\n",
      "  919: '[0, 3, 5, 6, 7, 8, 9]'\n",
      "  920: '[0, 4, 5, 6, 7, 8, 9]'\n",
      "  921: '[1, 2, 3, 4, 5, 6, 7]'\n",
      "  922: '[1, 2, 3, 4, 5, 6, 8]'\n",
      "  923: '[1, 2, 3, 4, 5, 6, 9]'\n",
      "  924: '[1, 2, 3, 4, 5, 7, 8]'\n",
      "  925: '[1, 2, 3, 4, 5, 7, 9]'\n",
      "  926: '[1, 2, 3, 4, 5, 8, 9]'\n",
      "  927: '[1, 2, 3, 4, 6, 7, 8]'\n",
      "  928: '[1, 2, 3, 4, 6, 7, 9]'\n",
      "  929: '[1, 2, 3, 4, 6, 8, 9]'\n",
      "  930: '[1, 2, 3, 4, 7, 8, 9]'\n",
      "  931: '[1, 2, 3, 5, 6, 7, 8]'\n",
      "  932: '[1, 2, 3, 5, 6, 7, 9]'\n",
      "  933: '[1, 2, 3, 5, 6, 8, 9]'\n",
      "  934: '[1, 2, 3, 5, 7, 8, 9]'\n",
      "  935: '[1, 2, 3, 6, 7, 8, 9]'\n",
      "  936: '[1, 2, 4, 5, 6, 7, 8]'\n",
      "  937: '[1, 2, 4, 5, 6, 7, 9]'\n",
      "  938: '[1, 2, 4, 5, 6, 8, 9]'\n",
      "  939: '[1, 2, 4, 5, 7, 8, 9]'\n",
      "  940: '[1, 2, 4, 6, 7, 8, 9]'\n",
      "  941: '[1, 2, 5, 6, 7, 8, 9]'\n",
      "  942: '[1, 3, 4, 5, 6, 7, 8]'\n",
      "  943: '[1, 3, 4, 5, 6, 7, 9]'\n",
      "  944: '[1, 3, 4, 5, 6, 8, 9]'\n",
      "  945: '[1, 3, 4, 5, 7, 8, 9]'\n",
      "  946: '[1, 3, 4, 6, 7, 8, 9]'\n",
      "  947: '[1, 3, 5, 6, 7, 8, 9]'\n",
      "  948: '[1, 4, 5, 6, 7, 8, 9]'\n",
      "  949: '[2, 3, 4, 5, 6, 7, 8]'\n",
      "  950: '[2, 3, 4, 5, 6, 7, 9]'\n",
      "  951: '[2, 3, 4, 5, 6, 8, 9]'\n",
      "  952: '[2, 3, 4, 5, 7, 8, 9]'\n",
      "  953: '[2, 3, 4, 6, 7, 8, 9]'\n",
      "  954: '[2, 3, 5, 6, 7, 8, 9]'\n",
      "  955: '[2, 4, 5, 6, 7, 8, 9]'\n",
      "  956: '[3, 4, 5, 6, 7, 8, 9]'\n",
      "  957: '[0, 1, 2, 3, 4, 5, 6, 7]'\n",
      "  958: '[0, 1, 2, 3, 4, 5, 6, 8]'\n",
      "  959: '[0, 1, 2, 3, 4, 5, 6, 9]'\n",
      "  960: '[0, 1, 2, 3, 4, 5, 7, 8]'\n",
      "  961: '[0, 1, 2, 3, 4, 5, 7, 9]'\n",
      "  962: '[0, 1, 2, 3, 4, 5, 8, 9]'\n",
      "  963: '[0, 1, 2, 3, 4, 6, 7, 8]'\n",
      "  964: '[0, 1, 2, 3, 4, 6, 7, 9]'\n",
      "  965: '[0, 1, 2, 3, 4, 6, 8, 9]'\n",
      "  966: '[0, 1, 2, 3, 4, 7, 8, 9]'\n",
      "  967: '[0, 1, 2, 3, 5, 6, 7, 8]'\n",
      "  968: '[0, 1, 2, 3, 5, 6, 7, 9]'\n",
      "  969: '[0, 1, 2, 3, 5, 6, 8, 9]'\n",
      "  970: '[0, 1, 2, 3, 5, 7, 8, 9]'\n",
      "  971: '[0, 1, 2, 3, 6, 7, 8, 9]'\n",
      "  972: '[0, 1, 2, 4, 5, 6, 7, 8]'\n",
      "  973: '[0, 1, 2, 4, 5, 6, 7, 9]'\n",
      "  974: '[0, 1, 2, 4, 5, 6, 8, 9]'\n",
      "  975: '[0, 1, 2, 4, 5, 7, 8, 9]'\n",
      "  976: '[0, 1, 2, 4, 6, 7, 8, 9]'\n",
      "  977: '[0, 1, 2, 5, 6, 7, 8, 9]'\n",
      "  978: '[0, 1, 3, 4, 5, 6, 7, 8]'\n",
      "  979: '[0, 1, 3, 4, 5, 6, 7, 9]'\n",
      "  980: '[0, 1, 3, 4, 5, 6, 8, 9]'\n",
      "  981: '[0, 1, 3, 4, 5, 7, 8, 9]'\n",
      "  982: '[0, 1, 3, 4, 6, 7, 8, 9]'\n",
      "  983: '[0, 1, 3, 5, 6, 7, 8, 9]'\n",
      "  984: '[0, 1, 4, 5, 6, 7, 8, 9]'\n",
      "  985: '[0, 2, 3, 4, 5, 6, 7, 8]'\n",
      "  986: '[0, 2, 3, 4, 5, 6, 7, 9]'\n",
      "  987: '[0, 2, 3, 4, 5, 6, 8, 9]'\n",
      "  988: '[0, 2, 3, 4, 5, 7, 8, 9]'\n",
      "  989: '[0, 2, 3, 4, 6, 7, 8, 9]'\n",
      "  990: '[0, 2, 3, 5, 6, 7, 8, 9]'\n",
      "  991: '[0, 2, 4, 5, 6, 7, 8, 9]'\n",
      "  992: '[0, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  993: '[1, 2, 3, 4, 5, 6, 7, 8]'\n",
      "  994: '[1, 2, 3, 4, 5, 6, 7, 9]'\n",
      "  995: '[1, 2, 3, 4, 5, 6, 8, 9]'\n",
      "  996: '[1, 2, 3, 4, 5, 7, 8, 9]'\n",
      "  997: '[1, 2, 3, 4, 6, 7, 8, 9]'\n",
      "  998: '[1, 2, 3, 5, 6, 7, 8, 9]'\n",
      "  999: '[1, 2, 4, 5, 6, 7, 8, 9]'\n",
      "  1000: '[1, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  1001: '[2, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  1002: '[0, 1, 2, 3, 4, 5, 6, 7, 8]'\n",
      "  1003: '[0, 1, 2, 3, 4, 5, 6, 7, 9]'\n",
      "  1004: '[0, 1, 2, 3, 4, 5, 6, 8, 9]'\n",
      "  1005: '[0, 1, 2, 3, 4, 5, 7, 8, 9]'\n",
      "  1006: '[0, 1, 2, 3, 4, 6, 7, 8, 9]'\n",
      "  1007: '[0, 1, 2, 3, 5, 6, 7, 8, 9]'\n",
      "  1008: '[0, 1, 2, 4, 5, 6, 7, 8, 9]'\n",
      "  1009: '[0, 1, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  1010: '[0, 2, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  1011: '[1, 2, 3, 4, 5, 6, 7, 8, 9]'\n",
      "  1012: '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]'\n",
      "\n",
      "Creating training L_exp with 360 samples using actual MNIST labels...\n",
      "Created L_exp with 360 samples\n",
      "Sample entry: ('[0, 1]', '[0, 2]', 0, 0)\n",
      "Label types: <class 'str'>, <class 'str'>\n",
      "‚úÖ MNIST training dataset created successfully!\n",
      "   Dataset length: 10 batches\n",
      "   Expected samples per batch: 36\n",
      "   Total samples in L_exp: 360\n",
      "\n",
      "=== Testing Batch Access ===\n",
      "‚úÖ Batch 0: loaded.shape=torch.Size([36, 3, 2464]), batch_len=36\n",
      "   Sample batch item type: <class 'tuple'>\n",
      "   Sample item length: 4\n",
      "‚úÖ Batch 1: loaded.shape=torch.Size([36, 3, 2464]), batch_len=36\n",
      "‚úÖ Batch 2: loaded.shape=torch.Size([36, 3, 2464]), batch_len=36\n",
      "\n",
      "‚úÖ Success! Ready for batch saving in next cell\n",
      "   Dataset has 10 batches of 36 pairs each\n",
      "   Using actual MNIST subset labels from the trained CNN\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Training Dataset with Proper MNIST Subset Labels\n",
    "print(\"=== Create Training Dataset with Proper MNIST Subset Labels ===\")\n",
    "\n",
    "def get_actual_mnist_labels():\n",
    "    \"\"\"Get the actual MNIST subset labels from the CSV\"\"\"\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(merged_zoo_path)\n",
    "        unique_labels = df['label'].unique()\n",
    "        \n",
    "        print(f\"Found {len(unique_labels)} unique MNIST subset labels:\")\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            print(f\"  {i}: {repr(label)}\")\n",
    "        \n",
    "        return list(unique_labels)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading labels: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_mnist_training_L_exp(num_samples=360):\n",
    "    \"\"\"Create L_exp using actual MNIST subset labels from the CSV\"\"\"\n",
    "    \n",
    "    # Get actual labels\n",
    "    mnist_labels = get_actual_mnist_labels()\n",
    "    \n",
    "    if not mnist_labels:\n",
    "        print(\"No labels found - cannot create dataset\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nCreating training L_exp with {num_samples} samples using actual MNIST labels...\")\n",
    "    \n",
    "    L_exp = []\n",
    "    epoch_keys = list(range(6))  # 0-5 for different epochs\n",
    "    activ_keys = list(range(6))  # 0-5 for different activations\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Use actual MNIST subset labels from CSV\n",
    "        label1 = mnist_labels[i % len(mnist_labels)]\n",
    "        label2 = mnist_labels[(i + 1) % len(mnist_labels)]\n",
    "        epoch_key = epoch_keys[i % len(epoch_keys)]\n",
    "        activ_key = activ_keys[i % len(activ_keys)]\n",
    "        \n",
    "        L_exp.append((label1, label2, epoch_key, activ_key))\n",
    "    \n",
    "    print(f\"Created L_exp with {len(L_exp)} samples\")\n",
    "    print(f\"Sample entry: {L_exp[0]}\")\n",
    "    print(f\"Label types: {type(L_exp[0][0])}, {type(L_exp[0][1])}\")\n",
    "    \n",
    "    return L_exp\n",
    "\n",
    "def create_mnist_training_dataset():\n",
    "    \"\"\"Create the training dataset with proper MNIST labels\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Creating MNIST Training Dataset ===\")\n",
    "    \n",
    "    # Create L_exp with actual MNIST subset labels\n",
    "    mnist_training_L_exp = create_mnist_training_L_exp(360)  # 10 batches of 36\n",
    "    \n",
    "    if not mnist_training_L_exp:\n",
    "        print(\"‚ùå Failed to create L_exp\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Create dataset with MNIST labels\n",
    "        mnist_training_dataset = CustomDataset(\n",
    "            L_exp=mnist_training_L_exp,\n",
    "            batch_size=36,  # Match meta.ipynb\n",
    "            batch_limit=10,  # 10 batches\n",
    "            df_path=str(merged_zoo_path)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ MNIST training dataset created successfully!\")\n",
    "        print(f\"   Dataset length: {len(mnist_training_dataset)} batches\")\n",
    "        print(f\"   Expected samples per batch: 36\")\n",
    "        print(f\"   Total samples in L_exp: {len(mnist_training_L_exp)}\")\n",
    "        \n",
    "        # Test accessing first few batches\n",
    "        print(f\"\\n=== Testing Batch Access ===\")\n",
    "        for i in range(min(3, len(mnist_training_dataset))):\n",
    "            try:\n",
    "                loaded, batch, L_ACC, L_indexes = mnist_training_dataset[i]\n",
    "                print(f\"‚úÖ Batch {i}: loaded.shape={loaded.shape}, batch_len={len(batch)}\")\n",
    "                \n",
    "                # Show sample of actual labels being used\n",
    "                if i == 0 and len(batch) > 0:\n",
    "                    sample_item = batch[0]\n",
    "                    print(f\"   Sample batch item type: {type(sample_item)}\")\n",
    "                    if hasattr(sample_item, '__len__') and len(sample_item) > 0:\n",
    "                        print(f\"   Sample item length: {len(sample_item)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error accessing batch {i}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        return mnist_training_dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating MNIST training dataset: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Create the proper MNIST training dataset\n",
    "full_training_dataset = create_mnist_training_dataset()\n",
    "\n",
    "if full_training_dataset:\n",
    "    print(f\"\\n‚úÖ Success! Ready for batch saving in next cell\")\n",
    "    print(f\"   Dataset has {len(full_training_dataset)} batches of 36 pairs each\")\n",
    "    print(f\"   Using actual MNIST subset labels from the trained CNN\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Failed to create training dataset\")\n",
    "    print(f\"   Check the error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18576da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test MNIST Label Parsing and Save Batches ===\n",
      "=== Testing MNIST Label Parsing ===\n",
      "  [0, 1] ‚Üí [0, 1]\n",
      "  [2, 3, 4] ‚Üí [2, 3, 4]\n",
      "  [5, 6, 7, 8] ‚Üí [5, 6, 7, 8]\n",
      "‚úÖ Label parsing function works correctly\n",
      "\n",
      "=== Saving Training Batches ===\n",
      "Processing 10 training batches (each with 36 pairs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving training batches:  10%|‚ñà         | 1/10 [00:00<00:02,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Successfully saved batch 0: 36 pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving training batches:  20%|‚ñà‚ñà        | 2/10 [00:00<00:01,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Successfully saved batch 1: 36 pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving training batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 training batches to /home/aymen/Documents/GitHub/Federated-Continual-learning-/New/notebooks_sandbox/tensor_batches/train_pair_scenario\n",
      "‚úÖ Successfully saved training batches!\n",
      "   Total batches: 10\n",
      "   Pairs per batch: 36 (matches meta.ipynb)\n",
      "   Total pairs: 360\n",
      "   Ready for meta training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test MNIST Label Parsing and Save Batches\n",
    "print(\"=== Test MNIST Label Parsing and Save Batches ===\")\n",
    "\n",
    "# Reload the updated CustomDataset\n",
    "exec(open(ROOT / \"Double_input_transformer.py\").read())\n",
    "\n",
    "def test_mnist_label_parsing():\n",
    "    \"\"\"Test that MNIST label parsing works correctly\"\"\"\n",
    "    \n",
    "    print(\"=== Testing MNIST Label Parsing ===\")\n",
    "    \n",
    "    # Test the parsing function directly\n",
    "    def parse_mnist_label(label_str):\n",
    "        \"\"\"Parse MNIST subset label string like '[0, 1]' into list [0, 1]\"\"\"\n",
    "        try:\n",
    "            import ast\n",
    "            parsed = ast.literal_eval(label_str)\n",
    "            return list(parsed) if isinstance(parsed, (list, tuple)) else [parsed]\n",
    "        except:\n",
    "            # Fallback: try to extract numbers manually\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', str(label_str))\n",
    "            return [int(n) for n in numbers] if numbers else [0]\n",
    "    \n",
    "    # Test with sample labels\n",
    "    test_labels = [\"[0, 1]\", \"[2, 3, 4]\", \"[5, 6, 7, 8]\"]\n",
    "    for label in test_labels:\n",
    "        parsed = parse_mnist_label(label)\n",
    "        print(f\"  {label} ‚Üí {parsed}\")\n",
    "    \n",
    "    print(\"‚úÖ Label parsing function works correctly\")\n",
    "\n",
    "def save_training_batches_working(dataset, output_dir, prefix=\"training\"):\n",
    "    \"\"\"Save training batches with the fixed label parsing\"\"\"\n",
    "    \n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    saved_files = {\n",
    "        'loaded_tensors': [],\n",
    "        'metadata': [],\n",
    "        'batch_info': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing {len(dataset)} training batches (each with 36 pairs)...\")\n",
    "    \n",
    "    for i in tqdm(range(len(dataset)), desc=\"Saving training batches\"):\n",
    "        try:\n",
    "            # Get batch data - this should work now with fixed label parsing\n",
    "            loaded, batch, L_ACC, L_indexes = dataset[i]\n",
    "            \n",
    "            # Verify batch size for training\n",
    "            expected_batch_size = 36\n",
    "            actual_batch_size = len(batch) if hasattr(batch, '__len__') else 0\n",
    "            \n",
    "            if actual_batch_size != expected_batch_size:\n",
    "                print(f\"‚ö†Ô∏è Warning: Batch {i} has {actual_batch_size} samples, expected {expected_batch_size}\")\n",
    "            \n",
    "            # Save main tensor\n",
    "            tensor_filename = f\"{prefix}_batch_{i:03d}_loaded.pt\"\n",
    "            tensor_path = output_path / tensor_filename\n",
    "            torch.save(loaded, tensor_path)\n",
    "            saved_files['loaded_tensors'].append(str(tensor_path))\n",
    "            \n",
    "            # Save metadata with proper serialization\n",
    "            metadata = {\n",
    "                'batch_idx': int(i),\n",
    "                'batch_info': str(batch) if not isinstance(batch, (list, tuple)) else list(batch),\n",
    "                'L_ACC': float(L_ACC) if isinstance(L_ACC, (int, float)) else str(L_ACC),\n",
    "                'L_indexes': list(L_indexes) if hasattr(L_indexes, '__iter__') else [int(L_indexes)],\n",
    "                'tensor_shape': tuple(loaded.shape) if hasattr(loaded, 'shape') else str(loaded.shape),\n",
    "                'tensor_filename': str(tensor_filename),\n",
    "                'batch_size': int(actual_batch_size),\n",
    "                'expected_batch_size': int(expected_batch_size),\n",
    "                'is_training_batch': True\n",
    "            }\n",
    "            \n",
    "            metadata_filename = f\"{prefix}_batch_{i:03d}_metadata.pt\"\n",
    "            metadata_path = output_path / metadata_filename\n",
    "            torch.save(metadata, metadata_path)\n",
    "            saved_files['metadata'].append(str(metadata_path))\n",
    "            \n",
    "            # Store batch info\n",
    "            saved_files['batch_info'].append({\n",
    "                'batch_idx': int(i),\n",
    "                'batch_size': int(actual_batch_size),\n",
    "                'tensor_shape': tuple(loaded.shape) if hasattr(loaded, 'shape') else str(loaded.shape),\n",
    "                'is_training_ready': actual_batch_size == expected_batch_size\n",
    "            })\n",
    "            \n",
    "            if i < 2:\n",
    "                print(f\"  ‚úì Successfully saved batch {i}: {actual_batch_size} pairs\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving training batch {i}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'total_batches': len(saved_files['loaded_tensors']),\n",
    "        'batch_files': saved_files['loaded_tensors'],\n",
    "        'metadata_files': saved_files['metadata'],\n",
    "        'batch_info': saved_files['batch_info'],\n",
    "        'dataset_config': {\n",
    "            'L_exp_length': len(dataset.L_exp),\n",
    "            'batch_size': int(dataset.batch_size),\n",
    "            'batch_limit': int(dataset.batch_limit),\n",
    "            'df_path': str(dataset.df_path),\n",
    "            'target_batch_size': 36,\n",
    "            'is_training_dataset': True\n",
    "        },\n",
    "        'training_info': {\n",
    "            'pairs_per_batch': 36,\n",
    "            'total_pairs': len(saved_files['loaded_tensors']) * 36,\n",
    "            'ready_for_meta_training': len(saved_files['loaded_tensors']) > 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    summary_path = output_path / f\"{prefix}_summary.pt\"\n",
    "    torch.save(summary, summary_path)\n",
    "    \n",
    "    print(f\"Saved {len(saved_files['loaded_tensors'])} training batches to {output_path}\")\n",
    "    return summary\n",
    "\n",
    "# Test label parsing\n",
    "test_mnist_label_parsing()\n",
    "\n",
    "# Save the training batches\n",
    "if full_training_dataset:\n",
    "    print(f\"\\n=== Saving Training Batches ===\")\n",
    "    try:\n",
    "        training_summary = save_training_batches_working(full_training_dataset, TENSOR_DIR, \"training\")\n",
    "        \n",
    "        if training_summary['total_batches'] > 0:\n",
    "            print(f\"‚úÖ Successfully saved training batches!\")\n",
    "            print(f\"   Total batches: {training_summary['total_batches']}\")\n",
    "            print(f\"   Pairs per batch: 36 (matches meta.ipynb)\")\n",
    "            print(f\"   Total pairs: {training_summary['training_info']['total_pairs']}\")\n",
    "            print(f\"   Ready for meta training: {training_summary['training_info']['ready_for_meta_training']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå No batches were saved successfully\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving training batches: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f\"‚ùå No training dataset available - run cell 5 first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8198e72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10 training batches...\n",
      "Stacked tensors shape: torch.Size([10, 36, 3, 2464])\n",
      "Feature dimension: 2464\n",
      "Stream 1 shape: torch.Size([360, 2464])\n",
      "Stream 2 shape: torch.Size([360, 2464])\n",
      "Target vectors shape: torch.Size([360, 2464])\n",
      "Target range: [-5.607, 4.186]\n",
      "TensorDataset created successfully: 360 samples\n",
      "Scenario: train\n",
      "Sample shapes: stream1=torch.Size([2464]), stream2=torch.Size([2464]), target=torch.Size([2464])\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Create Training TensorDataset for Double Input Transformer\n",
    "def create_training_tensor_dataset(summary_path):\n",
    "    \"\"\"Create TensorDataset from saved training batches for double input transformer\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Add safe globals for PyTorch 2.6 compatibility\n",
    "        import numpy.core.multiarray\n",
    "        torch.serialization.add_safe_globals([numpy.core.multiarray.scalar])\n",
    "        \n",
    "        summary = torch.load(summary_path, map_location='cpu', weights_only=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading summary: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    if summary['total_batches'] == 0:\n",
    "        print(\"No batches were saved\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"Loading {summary['total_batches']} training batches...\")\n",
    "    \n",
    "    # Load all batch tensors\n",
    "    all_loaded_tensors = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    for i, (tensor_file, metadata_file) in enumerate(zip(\n",
    "        summary['batch_files'], \n",
    "        summary['metadata_files']\n",
    "    )):\n",
    "        try:\n",
    "            loaded = torch.load(tensor_file, map_location='cpu', weights_only=False)\n",
    "            metadata = torch.load(metadata_file, map_location='cpu', weights_only=False)\n",
    "            \n",
    "            expected_size = 36\n",
    "            actual_size = metadata.get('batch_size', 0)\n",
    "            if actual_size != expected_size:\n",
    "                print(f\"Batch {i}: size {actual_size} != expected {expected_size}\")\n",
    "            \n",
    "            all_loaded_tensors.append(loaded)\n",
    "            all_metadata.append(metadata)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading batch {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_loaded_tensors:\n",
    "        print(\"No tensors loaded successfully\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Stack all tensors for TensorDataset\n",
    "    stacked_tensors = torch.stack(all_loaded_tensors)  # [10, 36, 3, 2464]\n",
    "    feature_dim = stacked_tensors.shape[-1]  # 2464\n",
    "    \n",
    "    print(f\"Stacked tensors shape: {stacked_tensors.shape}\")\n",
    "    print(f\"Feature dimension: {feature_dim}\")\n",
    "    \n",
    "    # Reshape for easier processing: [10*36, 3, 2464]\n",
    "    all_samples = stacked_tensors.view(-1, 3, feature_dim)  # [360, 3, 2464]\n",
    "    \n",
    "    # Extract inputs and targets for double input transformer\n",
    "    stream1_features = all_samples[:, 0, :]  # [360, 2464] - parent1 weight vectors\n",
    "    stream2_features = all_samples[:, 1, :]  # [360, 2464] - parent2 weight vectors  \n",
    "    target_vectors = all_samples[:, 2, :]    # [360, 2464] - target weight vectors\n",
    "    \n",
    "    print(f\"Stream 1 shape: {stream1_features.shape}\")\n",
    "    print(f\"Stream 2 shape: {stream2_features.shape}\")\n",
    "    print(f\"Target vectors shape: {target_vectors.shape}\")\n",
    "    print(f\"Target range: [{target_vectors.min():.3f}, {target_vectors.max():.3f}]\")\n",
    "    \n",
    "    # Create TensorDataset for double input transformer\n",
    "    training_tensor_dataset = torch.utils.data.TensorDataset(\n",
    "        stream1_features, \n",
    "        stream2_features, \n",
    "        target_vectors\n",
    "    )\n",
    "    \n",
    "    dataset_info = {\n",
    "        'total_samples': len(training_tensor_dataset),\n",
    "        'stream1_dim': stream1_features.shape[1],\n",
    "        'stream2_dim': stream2_features.shape[1],\n",
    "        'target_dim': target_vectors.shape[1],\n",
    "        'original_batches': len(all_loaded_tensors),\n",
    "        'samples_per_batch': 36,\n",
    "        'feature_dim': feature_dim,\n",
    "        'dataset_type': 'double_input_transformer_full_vectors',\n",
    "        'scenario': CURRENT_SCENARIO,\n",
    "        'target_vector_stats': {\n",
    "            'min': float(target_vectors.min()),\n",
    "            'max': float(target_vectors.max()),\n",
    "            'mean': float(target_vectors.mean()),\n",
    "            'std': float(target_vectors.std())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return training_tensor_dataset, dataset_info, summary\n",
    "\n",
    "def create_tensor_dataset_from_custom(custom_dataset):\n",
    "    \"\"\"Create TensorDataset directly from CustomDataset if file loading fails\"\"\"\n",
    "    \n",
    "    if custom_dataset is None:\n",
    "        print(\"CustomDataset not available\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        all_stream1_features = []\n",
    "        all_stream2_features = []\n",
    "        all_target_vectors = []\n",
    "        \n",
    "        print(\"Creating TensorDataset from CustomDataset...\")\n",
    "        \n",
    "        for i in range(len(custom_dataset)):\n",
    "            try:\n",
    "                loaded, batch, L_ACC, L_indexes = custom_dataset[i]\n",
    "                \n",
    "                if loaded.dim() == 3 and loaded.shape[1] == 3:\n",
    "                    feature_dim = loaded.shape[-1]  # 2464\n",
    "                    \n",
    "                    for j in range(loaded.shape[0]):  # 36 samples\n",
    "                        stream1_feat = loaded[j, 0, :]  # Full 2464-dim parent1 vector\n",
    "                        stream2_feat = loaded[j, 1, :]  # Full 2464-dim parent2 vector\n",
    "                        target_vector = loaded[j, 2, :]  # Full 2464-dim target vector\n",
    "                        \n",
    "                        all_stream1_features.append(stream1_feat)\n",
    "                        all_stream2_features.append(stream2_feat)\n",
    "                        all_target_vectors.append(target_vector)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not all_stream1_features:\n",
    "            print(\"No samples collected from CustomDataset\")\n",
    "            return None, None\n",
    "        \n",
    "        # Convert to tensors\n",
    "        stream1_features = torch.stack(all_stream1_features)\n",
    "        stream2_features = torch.stack(all_stream2_features)\n",
    "        target_vectors = torch.stack(all_target_vectors)\n",
    "        \n",
    "        print(f\"Collected {len(all_stream1_features)} samples\")\n",
    "        print(f\"Target range: [{target_vectors.min():.3f}, {target_vectors.max():.3f}]\")\n",
    "        \n",
    "        # Create TensorDataset\n",
    "        training_tensor_dataset = torch.utils.data.TensorDataset(\n",
    "            stream1_features, \n",
    "            stream2_features, \n",
    "            target_vectors\n",
    "        )\n",
    "        \n",
    "        dataset_info = {\n",
    "            'total_samples': len(training_tensor_dataset),\n",
    "            'stream1_dim': stream1_features.shape[1],\n",
    "            'stream2_dim': stream2_features.shape[1],\n",
    "            'target_dim': target_vectors.shape[1],\n",
    "            'original_batches': len(custom_dataset),\n",
    "            'samples_per_batch': 36,\n",
    "            'feature_dim': stream1_features.shape[1],\n",
    "            'dataset_type': 'double_input_transformer_full_vectors_from_custom',\n",
    "            'scenario': CURRENT_SCENARIO,\n",
    "            'target_vector_stats': {\n",
    "                'min': float(target_vectors.min()),\n",
    "                'max': float(target_vectors.max()),\n",
    "                'mean': float(target_vectors.mean()),\n",
    "                'std': float(target_vectors.std())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return training_tensor_dataset, dataset_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating TensorDataset from CustomDataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Create the TensorDataset\n",
    "try:\n",
    "    training_summary_path = TENSOR_DIR / \"training_summary.pt\"\n",
    "    \n",
    "    if not training_summary_path.exists():\n",
    "        print(f\"Summary file not found: {training_summary_path}\")\n",
    "        print(\"Run cell 6 first to create the summary file\")\n",
    "        training_tensor_dataset = None\n",
    "    else:\n",
    "        # Try to load from saved files first\n",
    "        training_tensor_dataset, dataset_info, training_summary = create_training_tensor_dataset(training_summary_path)\n",
    "        \n",
    "        # If that fails, try creating directly from CustomDataset\n",
    "        if training_tensor_dataset is None:\n",
    "            print(\"Loading from saved files failed, trying direct approach...\")\n",
    "            training_tensor_dataset, dataset_info = create_tensor_dataset_from_custom(full_training_dataset)\n",
    "        \n",
    "        if training_tensor_dataset:\n",
    "            print(f\"TensorDataset created successfully: {len(training_tensor_dataset)} samples\")\n",
    "            print(f\"Scenario: {dataset_info['scenario']}\")\n",
    "            \n",
    "            # Test accessing a sample\n",
    "            sample_stream1, sample_stream2, sample_target = training_tensor_dataset[0]\n",
    "            print(f\"Sample shapes: stream1={sample_stream1.shape}, stream2={sample_stream2.shape}, target={sample_target.shape}\")\n",
    "        else:\n",
    "            print(\"Failed to create TensorDataset\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error creating TensorDataset: {e}\")\n",
    "    training_tensor_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb482d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDataset avg time: 0.2308s\n",
      "TensorDataset avg time: 0.0001s\n",
      "TensorDataset speedup: 3371.02x\n",
      "Dataset dimensions: stream1=2464, stream2=2464, target=2464\n",
      "Model created on device: cuda\n",
      "Model parameters: 25,227,984\n",
      "Batch 0:\n",
      "  Input shapes: stream1=torch.Size([4, 2464]), stream2=torch.Size([4, 2464])\n",
      "  Target shape: torch.Size([4, 2464])\n",
      "  Output shape: torch.Size([4, 2464])\n",
      "  Target range: [-1.402, 1.086]\n",
      "  Output range: [-0.343, 0.380]\n",
      "  MSE: 0.071182\n",
      "Batch 1:\n",
      "  Input shapes: stream1=torch.Size([4, 2464]), stream2=torch.Size([4, 2464])\n",
      "  Target shape: torch.Size([4, 2464])\n",
      "  Output shape: torch.Size([4, 2464])\n",
      "  Target range: [-4.644, 3.030]\n",
      "  Output range: [-0.384, 0.360]\n",
      "  MSE: 0.244562\n",
      "All tests completed successfully\n",
      "TensorDataset ready for training with 2464-dim vectors\n",
      "Toy double input transformer matching TransformerAE architecture\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Benchmark and Create Toy Double Input Transformer Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class ToyDoubleInputTransformer(nn.Module):\n",
    "    \"\"\"Toy Double Input Transformer matching TransformerAE architecture for testing\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=2464, d_model=100, max_seq_len=50, neck=20, N=1, heads=1, d_ff=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.neck = neck\n",
    "        self.N = N\n",
    "        self.heads = heads\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        # Simplified embedding layer (mimics EmbedderNeuronGroup)\n",
    "        self.embed_stream1 = nn.Linear(input_dim, max_seq_len * d_model)\n",
    "        self.embed_stream2 = nn.Linear(input_dim, max_seq_len * d_model)\n",
    "        \n",
    "        # Simplified positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, max_seq_len, d_model) * 0.1)\n",
    "        \n",
    "        # Simplified encoder layers (one for each stream)\n",
    "        self.encoder_stream1 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dim_feedforward=d_ff, dropout=0.1),\n",
    "            num_layers=N\n",
    "        )\n",
    "        self.encoder_stream2 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dim_feedforward=d_ff, dropout=0.1),\n",
    "            num_layers=N\n",
    "        )\n",
    "        \n",
    "        # Fusion layer (mimics vec2neck in TransformerAE)\n",
    "        self.fusion = nn.Linear(2 * d_model * max_seq_len, neck)\n",
    "        \n",
    "        # Simplified decoder (mimics DecoderNeuronGroup + Seq2Vec)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(neck, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(d_ff, input_dim)  # Output 2464-dimensional vector\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        \n",
    "    def forward(self, stream1, stream2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            stream1: [batch_size, 2464] - parent model weights\n",
    "            stream2: [batch_size, 2464] - parent model weights\n",
    "        Returns:\n",
    "            output: [batch_size, 2464] - predicted target model weights\n",
    "        \"\"\"\n",
    "        batch_size = stream1.size(0)\n",
    "        \n",
    "        # Embed streams to sequences\n",
    "        stream1_seq = self.embed_stream1(stream1).view(batch_size, self.max_seq_len, self.d_model)\n",
    "        stream2_seq = self.embed_stream2(stream2).view(batch_size, self.max_seq_len, self.d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        stream1_seq = stream1_seq + self.pos_encoder\n",
    "        stream2_seq = stream2_seq + self.pos_encoder\n",
    "        \n",
    "        # Encode each stream independently\n",
    "        stream1_encoded = self.encoder_stream1(stream1_seq.transpose(0, 1)).transpose(0, 1)\n",
    "        stream2_encoded = self.encoder_stream2(stream2_seq.transpose(0, 1)).transpose(0, 1)\n",
    "        \n",
    "        # Concatenate encoded streams\n",
    "        concatenated = torch.cat([stream1_encoded, stream2_encoded], dim=2)\n",
    "        \n",
    "        # Flatten and fuse\n",
    "        flattened = concatenated.view(batch_size, -1)\n",
    "        neck_rep = torch.tanh(self.fusion(flattened))\n",
    "        \n",
    "        # Decode to final output\n",
    "        output = self.decoder(neck_rep)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def benchmark_datasets(training_dataset, training_tensor_dataset):\n",
    "    \"\"\"Benchmark CustomDataset vs TensorDataset\"\"\"\n",
    "    \n",
    "    if training_dataset is None or training_tensor_dataset is None:\n",
    "        print(\"One or both datasets not available\")\n",
    "        return None\n",
    "    \n",
    "    # Test CustomDataset\n",
    "    custom_times = []\n",
    "    custom_loader = torch.utils.data.DataLoader(training_dataset, batch_size=1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, batch in enumerate(custom_loader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        loaded, batch_data, L_ACC, L_indexes = batch\n",
    "        custom_times.append(time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "    \n",
    "    custom_avg_time = sum(custom_times) / len(custom_times) if custom_times else 0\n",
    "    \n",
    "    # Test TensorDataset  \n",
    "    tensor_times = []\n",
    "    tensor_loader = torch.utils.data.DataLoader(training_tensor_dataset, batch_size=1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, (stream1, stream2, target_vector) in enumerate(tensor_loader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        tensor_times.append(time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "    \n",
    "    tensor_avg_time = sum(tensor_times) / len(tensor_times) if tensor_times else 0\n",
    "    \n",
    "    print(f\"CustomDataset avg time: {custom_avg_time:.4f}s\")\n",
    "    print(f\"TensorDataset avg time: {tensor_avg_time:.4f}s\")\n",
    "    \n",
    "    if tensor_avg_time > 0:\n",
    "        speedup = custom_avg_time / tensor_avg_time\n",
    "        print(f\"TensorDataset speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    return {\n",
    "        'custom_avg_time': custom_avg_time,\n",
    "        'tensor_avg_time': tensor_avg_time,\n",
    "        'speedup': custom_avg_time / tensor_avg_time if tensor_avg_time > 0 else 0\n",
    "    }\n",
    "\n",
    "def test_toy_model(training_tensor_dataset):\n",
    "    \"\"\"Test the toy double input transformer model with 2464-dim vectors\"\"\"\n",
    "    \n",
    "    if training_tensor_dataset is None:\n",
    "        print(\"TensorDataset not available\")\n",
    "        return None\n",
    "    \n",
    "    # Get dataset info\n",
    "    sample_stream1, sample_stream2, sample_target = training_tensor_dataset[0]\n",
    "    stream1_dim = sample_stream1.shape[0]\n",
    "    stream2_dim = sample_stream2.shape[0]\n",
    "    target_dim = sample_target.shape[0]  # Should be 2464\n",
    "    \n",
    "    print(f\"Dataset dimensions: stream1={stream1_dim}, stream2={stream2_dim}, target={target_dim}\")\n",
    "    \n",
    "    if target_dim != 2464:\n",
    "        print(f\"Warning: Expected target_dim=2464, got {target_dim}\")\n",
    "    \n",
    "    # Create model matching TransformerAE architecture\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ToyDoubleInputTransformer(\n",
    "        input_dim=stream1_dim,  # 2464\n",
    "        d_model=100,            # Match TransformerAE default\n",
    "        max_seq_len=50,         # Match EmbedderNeuronGroup output (26+24=50)\n",
    "        neck=20,                # Match TransformerAE default\n",
    "        N=1,                    # Match TransformerAE default\n",
    "        heads=1,                # Match TransformerAE default\n",
    "        d_ff=100                # Match TransformerAE default\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model created on device: {device}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create DataLoader\n",
    "        test_loader = torch.utils.data.DataLoader(training_tensor_dataset, batch_size=4, shuffle=True)\n",
    "        \n",
    "        for i, (stream1_batch, stream2_batch, target_batch) in enumerate(test_loader):\n",
    "            if i >= 2:\n",
    "                break\n",
    "                \n",
    "            # Move to device\n",
    "            stream1_batch = stream1_batch.to(device)\n",
    "            stream2_batch = stream2_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(stream1_batch, stream2_batch)\n",
    "            \n",
    "            print(f\"Batch {i}:\")\n",
    "            print(f\"  Input shapes: stream1={stream1_batch.shape}, stream2={stream2_batch.shape}\")\n",
    "            print(f\"  Target shape: {target_batch.shape}\")\n",
    "            print(f\"  Output shape: {output.shape}\")\n",
    "            print(f\"  Target range: [{target_batch.min():.3f}, {target_batch.max():.3f}]\")\n",
    "            print(f\"  Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "            \n",
    "            # Calculate MSE for this batch\n",
    "            mse = F.mse_loss(output, target_batch)\n",
    "            print(f\"  MSE: {mse.item():.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run benchmarks and tests\n",
    "try:\n",
    "    # Benchmark datasets\n",
    "    benchmark_results = benchmark_datasets(full_training_dataset, training_tensor_dataset)\n",
    "    \n",
    "    # Test toy model\n",
    "    toy_model = test_toy_model(training_tensor_dataset)\n",
    "    \n",
    "    if toy_model:\n",
    "        print(\"All tests completed successfully\")\n",
    "        print(\"TensorDataset ready for training with 2464-dim vectors\")\n",
    "        print(\"Toy double input transformer matching TransformerAE architecture\")\n",
    "    else:\n",
    "        print(\"Model test failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in benchmarking/testing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74a7736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n",
      "Training samples: 360\n",
      "Batch size: 32\n",
      "Batches per epoch: 11\n",
      "Starting training...\n",
      "  Epoch 1/5, Batch 0/11, Loss: 0.202068\n",
      "  Epoch 1/5, Batch 2/11, Loss: 0.186866\n",
      "  Epoch 1/5, Batch 4/11, Loss: 0.165638\n",
      "  Epoch 1/5, Batch 6/11, Loss: 0.133759\n",
      "  Epoch 1/5, Batch 8/11, Loss: 0.176621\n",
      "  Epoch 1/5, Batch 10/11, Loss: 0.170474\n",
      "Epoch 1/5 completed:\n",
      "  Average Loss: 0.185348\n",
      "  Learning Rate: 0.000100\n",
      "  Batches Processed: 11\n",
      "--------------------------------------------------\n",
      "  Epoch 2/5, Batch 0/11, Loss: 0.240868\n",
      "  Epoch 2/5, Batch 2/11, Loss: 0.141679\n",
      "  Epoch 2/5, Batch 4/11, Loss: 0.155945\n",
      "  Epoch 2/5, Batch 6/11, Loss: 0.230693\n",
      "  Epoch 2/5, Batch 8/11, Loss: 0.181479\n",
      "  Epoch 2/5, Batch 10/11, Loss: 0.180808\n",
      "Epoch 2/5 completed:\n",
      "  Average Loss: 0.184185\n",
      "  Learning Rate: 0.000100\n",
      "  Batches Processed: 11\n",
      "--------------------------------------------------\n",
      "  Epoch 3/5, Batch 0/11, Loss: 0.170619\n",
      "  Epoch 3/5, Batch 2/11, Loss: 0.189560\n",
      "  Epoch 3/5, Batch 4/11, Loss: 0.200699\n",
      "  Epoch 3/5, Batch 6/11, Loss: 0.103626\n",
      "  Epoch 3/5, Batch 8/11, Loss: 0.181167\n",
      "  Epoch 3/5, Batch 10/11, Loss: 0.212703\n",
      "Epoch 3/5 completed:\n",
      "  Average Loss: 0.182323\n",
      "  Learning Rate: 0.000100\n",
      "  Batches Processed: 11\n",
      "--------------------------------------------------\n",
      "  Epoch 4/5, Batch 0/11, Loss: 0.138359\n",
      "  Epoch 4/5, Batch 2/11, Loss: 0.159367\n",
      "  Epoch 4/5, Batch 4/11, Loss: 0.176183\n",
      "  Epoch 4/5, Batch 6/11, Loss: 0.189813\n",
      "  Epoch 4/5, Batch 8/11, Loss: 0.134768\n",
      "  Epoch 4/5, Batch 10/11, Loss: 0.227583\n",
      "Epoch 4/5 completed:\n",
      "  Average Loss: 0.179433\n",
      "  Learning Rate: 0.000100\n",
      "  Batches Processed: 11\n",
      "--------------------------------------------------\n",
      "  Epoch 5/5, Batch 0/11, Loss: 0.141990\n",
      "  Epoch 5/5, Batch 2/11, Loss: 0.190524\n",
      "  Epoch 5/5, Batch 4/11, Loss: 0.129627\n",
      "  Epoch 5/5, Batch 6/11, Loss: 0.186286\n",
      "  Epoch 5/5, Batch 8/11, Loss: 0.179935\n",
      "  Epoch 5/5, Batch 10/11, Loss: 0.192131\n",
      "Epoch 5/5 completed:\n",
      "  Average Loss: 0.177049\n",
      "  Learning Rate: 0.000100\n",
      "  Batches Processed: 11\n",
      "--------------------------------------------------\n",
      "Training completed\n",
      "Model evaluation...\n",
      "Batch 0:\n",
      "  Target range: [-4.778, 3.515]\n",
      "  Prediction range: [-0.390, 0.288]\n",
      "  Loss: 0.170066\n",
      "Batch 1:\n",
      "  Target range: [-4.694, 3.694]\n",
      "  Prediction range: [-0.318, 0.324]\n",
      "  Loss: 0.177688\n",
      "Evaluation results:\n",
      "  Total samples: 360\n",
      "  Average Loss (MSE): 0.178607\n",
      "  Root Mean Square Error: 0.422620\n",
      "  Mean Absolute Error: 0.265229\n",
      "  Correlation: 0.611422\n",
      "Final summary:\n",
      "  Created training batches with 36 pairs each (matches meta.ipynb)\n",
      "  Exported training tensors to scenario: train\n",
      "  Built and trained toy double input transformer model\n",
      "  Demonstrated end-to-end training pipeline\n",
      "  Ready for integration with meta.ipynb training pipeline\n",
      "  Model evaluation completed with correlation: 0.6114\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training Loop Demo with Double Input Transformer\n",
    "def train_double_input_transformer(model, dataset, epochs=5, batch_size=32, learning_rate=1e-4):\n",
    "    \"\"\"Training loop for double input transformer\"\"\"\n",
    "    \n",
    "    if model is None or dataset is None:\n",
    "        print(\"Model or dataset not available\")\n",
    "        return None, None\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Training on device: {device}\")\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(dataset)}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "    \n",
    "    # Setup training\n",
    "    criterion = nn.MSELoss()  # Regression loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (stream1_batch, stream2_batch, target_batch) in enumerate(train_loader):\n",
    "            # Move to device\n",
    "            stream1_batch = stream1_batch.to(device)\n",
    "            stream2_batch = stream2_batch.to(device)\n",
    "            target_batch = target_batch.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(stream1_batch, stream2_batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(output.squeeze(), target_batch.squeeze())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if batch_idx % 2 == 0:\n",
    "                print(f\"  Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_epoch_loss = epoch_loss / num_batches if num_batches > 0 else 0\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_epoch_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed:\")\n",
    "        print(f\"  Average Loss: {avg_epoch_loss:.6f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "        print(f\"  Batches Processed: {num_batches}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Training completed\")\n",
    "    return train_losses, model\n",
    "\n",
    "def evaluate_model(model, dataset, batch_size=32):\n",
    "    \"\"\"Evaluate the trained model\"\"\"\n",
    "    \n",
    "    if model is None or dataset is None:\n",
    "        print(\"Model or dataset not available\")\n",
    "        return None\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    # Create DataLoader\n",
    "    eval_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    print(\"Model evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (stream1_batch, stream2_batch, target_batch) in enumerate(eval_loader):\n",
    "            # Move to device\n",
    "            stream1_batch = stream1_batch.to(device)\n",
    "            stream2_batch = stream2_batch.to(device)\n",
    "            target_batch = target_batch.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(stream1_batch, stream2_batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(output.squeeze(), target_batch.squeeze())\n",
    "            total_loss += loss.item() * target_batch.size(0)\n",
    "            num_samples += target_batch.size(0)\n",
    "            \n",
    "            # Store predictions and actuals\n",
    "            predictions.extend(output.squeeze().cpu().numpy())\n",
    "            actuals.extend(target_batch.squeeze().cpu().numpy())\n",
    "            \n",
    "            if batch_idx < 2:\n",
    "                print(f\"Batch {batch_idx}:\")\n",
    "                print(f\"  Target range: [{target_batch.min():.3f}, {target_batch.max():.3f}]\")\n",
    "                print(f\"  Prediction range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "                print(f\"  Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / num_samples if num_samples > 0 else 0\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    if len(predictions) > 1 and len(actuals) > 1:\n",
    "        correlation = np.corrcoef(predictions, actuals)[0, 1]\n",
    "        mae = np.mean(np.abs(predictions - actuals))\n",
    "        mse = np.mean((predictions - actuals) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "    else:\n",
    "        correlation = 0.0\n",
    "        mae = 0.0\n",
    "        mse = 0.0\n",
    "        rmse = 0.0\n",
    "    \n",
    "    print(\"Evaluation results:\")\n",
    "    print(f\"  Total samples: {num_samples}\")\n",
    "    print(f\"  Average Loss (MSE): {avg_loss:.6f}\")\n",
    "    print(f\"  Root Mean Square Error: {rmse:.6f}\")\n",
    "    print(f\"  Mean Absolute Error: {mae:.6f}\")\n",
    "    print(f\"  Correlation: {correlation:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_loss': avg_loss,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'correlation': correlation,\n",
    "        'num_samples': num_samples\n",
    "    }\n",
    "\n",
    "# Run training and evaluation\n",
    "try:\n",
    "    if training_tensor_dataset and toy_model:\n",
    "        # Train the model\n",
    "        train_losses, trained_model = train_double_input_transformer(\n",
    "            toy_model, \n",
    "            training_tensor_dataset, \n",
    "            epochs=5, \n",
    "            batch_size=32, \n",
    "            learning_rate=1e-4\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        eval_results = evaluate_model(trained_model, training_tensor_dataset, batch_size=32)\n",
    "        \n",
    "        print(\"Final summary:\")\n",
    "        print(f\"  Created training batches with 36 pairs each (matches meta.ipynb)\")\n",
    "        print(f\"  Exported training tensors to scenario: {CURRENT_SCENARIO}\")\n",
    "        print(f\"  Built and trained toy double input transformer model\")\n",
    "        print(f\"  Demonstrated end-to-end training pipeline\")\n",
    "        print(f\"  Ready for integration with meta.ipynb training pipeline\")\n",
    "        \n",
    "        if eval_results:\n",
    "            print(f\"  Model evaluation completed with correlation: {eval_results['correlation']:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Cannot run training - missing TensorDataset or model\")\n",
    "        print(f\"  training_tensor_dataset available: {training_tensor_dataset is not None}\")\n",
    "        print(f\"  toy_model available: {toy_model is not None}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during training/evaluation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966dd16-4d3e-4c33-9aa5-c1241c8d4551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
