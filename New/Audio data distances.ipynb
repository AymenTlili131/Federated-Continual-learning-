{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a8fa2-b2dc-4acf-bb4b-a062266e43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38b149-eca1-4481-947c-ba81d369e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_wave(batch_size=8, length=16000, sample_rate=16000):\n",
    "    t = torch.linspace(0, 1, steps=length)\n",
    "    waves = []\n",
    "    for _ in range(batch_size):\n",
    "        freq = torch.randint(100, 1000, (1,)).item()\n",
    "        wave = torch.sin(2 * np.pi * freq * t)\n",
    "        noise = 0.05 * torch.randn_like(wave)\n",
    "        waves.append((wave + noise).unsqueeze(0))  # shape: [1, length]\n",
    "    return torch.stack(waves)  # [batch_size, 1, length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51d30a-d19e-4393-be9b-28aec4bbbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyAudioAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 9, stride=2, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, 9, stride=2, padding=4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(32, 16, 9, stride=2, padding=4, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(16, 1, 9, stride=2, padding=4, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b4bb7-7385-4b94-a3c3-5c8c84e4b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformL2Loss(nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "class FFTLoss(nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        x_fft = torch.fft.fft(x)\n",
    "        y_fft = torch.fft.fft(y)\n",
    "        return torch.mean(torch.abs(x_fft - y_fft))\n",
    "class MelSpecL2Loss(nn.Module):\n",
    "    def __init__(self, sample_rate=16000, n_fft=1024, hop_length=256, n_mels=64):\n",
    "        super().__init__()\n",
    "        self.mel = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            n_mels=n_mels,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        m1 = self.mel(x.squeeze(1))\n",
    "        m2 = self.mel(y.squeeze(1))\n",
    "        return F.mse_loss(m1, m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c038f-5f72-45bd-8dfd-82e133235feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrtm_newton_schulz(A, num_iter=10):\n",
    "    B, N, _ = A.shape\n",
    "    normA = A.norm(dim=(1, 2), keepdim=True)\n",
    "    Y = A / normA\n",
    "    I = torch.eye(N, device=A.device).unsqueeze(0).expand(B, -1, -1)\n",
    "    Z = I.clone()\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        T = 0.5 * (3.0 * I - Z @ Y)\n",
    "        Y = Y @ T\n",
    "        Z = T @ Z\n",
    "    return Y * torch.sqrt(normA)\n",
    "\n",
    "class MelFIDLoss(nn.Module):\n",
    "    def __init__(self, sample_rate=16000):\n",
    "        super().__init__()\n",
    "        self.mel = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=64)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        m1 = self.mel(x.squeeze(1))  # [B, mel, T]\n",
    "        m2 = self.mel(y.squeeze(1))\n",
    "        f1 = m1.transpose(1, 2)  # [B, T, mel]\n",
    "        f2 = m2.transpose(1, 2)\n",
    "        mu1 = f1.mean(dim=1)\n",
    "        mu2 = f2.mean(dim=1)\n",
    "        c1 = (f1 - mu1.unsqueeze(1)).transpose(1, 2) @ (f1 - mu1.unsqueeze(1)) / (f1.shape[1] - 1)\n",
    "        c2 = (f2 - mu2.unsqueeze(1)).transpose(1, 2) @ (f2 - mu2.unsqueeze(1)) / (f2.shape[1] - 1)\n",
    "        sqrt_cov = sqrtm_newton_schulz(c1 @ c2)\n",
    "        trace_term = torch.diagonal(c1 + c2 - 2 * sqrt_cov, dim1=1, dim2=2).sum(dim=1)\n",
    "        mean_term = (mu1 - mu2).pow(2).sum(dim=1)\n",
    "        return (mean_term + trace_term).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc3505-c7d7-4bc6-90b1-c5147fda0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, epochs=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        x = generate_synthetic_wave(batch_size=16).to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_fn(y, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a94a96-37dc-4118-9cc1-ad0e12e59027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyAudioAutoencoder()\n",
    "losses = {\n",
    "    \"Waveform L2\": WaveformL2Loss(),\n",
    "    \"FFT Loss\": FFTLoss(),\n",
    "    \"Mel L2\": MelSpecL2Loss(),\n",
    "    \"Mel FID\": MelFIDLoss(),\n",
    "}\n",
    "\n",
    "for name, loss_fn in losses.items():\n",
    "    print(f\"\\nðŸ§ª Training with {name}\")\n",
    "    train(model, loss_fn, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
