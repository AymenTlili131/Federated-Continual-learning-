{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4d2cab-fe90-44e2-81f5-d7bc1d4a8d81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_796924/4207577347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load pre-trained BERT tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    " \n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    " \n",
    "# Input text\n",
    "text = 'ChatGPT is a language model developed by OpenAI, based on the GPT (Generative Pre-trained Transformer) architecture. '\n",
    " \n",
    "# Tokenize and encode the text\n",
    "encoding = tokenizer.encode(text)\n",
    " \n",
    "# Print the token IDs\n",
    "print(\"Token IDs:\", encoding)\n",
    " \n",
    "# Convert token IDs back to tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding)\n",
    " \n",
    "# Print the corresponding tokens\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c",
   "metadata": {
    "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "import random\n",
    "import ast\n",
    "        \n",
    "\n",
    "import torch.nn.functional as F\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation ,FFMpegWriter ,PillowWriter\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os \n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c973ef-a1c2-4c67-88f5-5c2cdc634f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceed1bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maymentlili\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/crns/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"ab631efc36e2c87f5f54d82b5cdbd6c501d5221f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecd06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c395ca-191a-49f4-b45c-e87ecd231e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
    "outputId": "9229fdc7-630d-4e87-d54b-3771391ef44c"
   },
   "outputs": [],
   "source": [
    "random.seed(881)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a1e1f6-dcf6-4c01-b2c3-ab25ee771a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Double_input_transformer import CustomDataset,TransformerAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655000ba-32ed-41d3-93a3-522336521239",
   "metadata": {
    "id": "655000ba-32ed-41d3-93a3-522336521239"
   },
   "source": [
    "# Trainloader code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2e5630-1312-47db-b6b1-1646cb9eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the list\n",
    "train_pair = np.load('train_pair_seed881.npy', allow_pickle=True)\n",
    "test_pair = np.load('test_pair_seed881.npy', allow_pickle=True)\n",
    "val_pair = np.load('val_pair_seed881.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96f0b1d-6532-48da-9cfb-44a1fe16465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10]]\n"
     ]
    }
   ],
   "source": [
    "def batchify(lst, batch_size):\n",
    "    return [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]\n",
    "\n",
    "# Example usage:\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "batch_size = 4\n",
    "batches = batchify(my_list, batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs_tr=CustomDataset(train_pair,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c1f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset,EXP,ACC,U = cs_tr[0]\n",
    "#x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4e714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0930913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2",
   "metadata": {
    "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387b2953-3794-42d9-a327-5e7cca27939d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387b2953-3794-42d9-a327-5e7cca27939d",
    "outputId": "29fef800-a2d7-43d4-dafb-9fa69bda52ca"
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b",
   "metadata": {
    "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30",
   "metadata": {
    "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72",
   "metadata": {
    "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a",
   "metadata": {
    "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a"
   },
   "outputs": [],
   "source": [
    "class EmbedderNeuronGroup(nn.Module):\n",
    "    def __init__(self, d_model, seed=22):\n",
    "        super().__init__()\n",
    "        #print(\"EmbedderNeuroneGroup\")\n",
    "        self.neuron_l1 = nn.Linear(200, d_model) #8\n",
    "        self.neuron_l2 = nn.Linear(72, d_model) #12\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.multiLinear(x)\n",
    "\n",
    "    def multiLinear(self, v):\n",
    "        #print(\"multi-linear method\",v.shape)\n",
    "\n",
    "        l = []\n",
    "\n",
    "        for ndx in range(8):\n",
    "            idx_start = ndx * 200\n",
    "            idx_end = idx_start + 200\n",
    "            l.append(self.neuron_l1(v[:,idx_start:idx_end]))\n",
    "\n",
    "        # l2\n",
    "        for ndx in range(12):\n",
    "            idx_start = 200*8 + ndx * 72\n",
    "            idx_end = idx_start + 72\n",
    "            l.append(self.neuron_l2(v[:,idx_start:idx_end]))\n",
    "        #print(len(l))\n",
    "        #print(len(l[0]))\n",
    "        final = torch.stack(l, dim=1)\n",
    "\n",
    "        # print(final.shape)\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2",
   "metadata": {
    "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f",
   "metadata": {
    "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f"
   },
   "outputs": [],
   "source": [
    "# max_seq_len=176,\n",
    "# N=4\n",
    "# heads=3\n",
    "# d_model=900\n",
    "# d_ff=900\n",
    "# neck=700\n",
    "# dropout=0.1\n",
    "# # Enc=EncoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff)\n",
    "# # vec1 = torch.rand(1,2464)\n",
    "# # res,scores=Enc(vec1)\n",
    "# # res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad",
   "metadata": {
    "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278",
   "metadata": {
    "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278"
   },
   "outputs": [],
   "source": [
    "# vec2neck = nn.Linear(d_ff*2, neck)\n",
    "# print(res.shape)\n",
    "# out3=torch.cat([res,res], dim=2)\n",
    "# print(\"neck input:\",out3.shape)\n",
    "# sum_r=torch.sum(out3, dim=1, keepdim=False)\n",
    "# vec2=vec2neck(sum_r)\n",
    "# print(len(vec2))\n",
    "# tanh = nn.Tanh()\n",
    "# neck_t=tanh(vec2)\n",
    "# print(\"neck shape:\",neck_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac",
   "metadata": {
    "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4",
   "metadata": {
    "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa74a80-dee8-4710-a221-a448b37758d1",
   "metadata": {
    "id": "efa74a80-dee8-4710-a221-a448b37758d1"
   },
   "outputs": [],
   "source": [
    "# Dec=DecoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff,neck=neck)\n",
    "# res,scores=Dec(neck_t)\n",
    "# res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf",
   "metadata": {
    "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5",
   "metadata": {
    "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d",
   "metadata": {
    "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65",
   "metadata": {
    "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
    "outputId": "7301efd4-e73d-46ce-baa8-b3b12a63c900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159516, 595620, 88560)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pair),len(train_pair),len(val_pair)#,len(test_tgt),len(train_tgt),len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649",
   "metadata": {
    "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619486cb-4a43-408f-976c-74c7d6a840d9",
   "metadata": {
    "id": "619486cb-4a43-408f-976c-74c7d6a840d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
    "outputId": "9429472d-98a4-47db-c47e-af78aadfba49"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(mod.numParams())\n",
    "# x1 = torch.rand(1,2464)\n",
    "# x2 = torch.rand(1,2464)\n",
    "# mod=mod.to(device).to(torch.float32)\n",
    "\n",
    "# #x1=x1.to(torch.float32)\n",
    "# #x2=x2.to(torch.float32)\n",
    "# x1=x1.to(device)\n",
    "# x2=x2.to(device)\n",
    "# mod=mod.to(device)\n",
    "# out = mod(x1,x2)\n",
    "# print(\"Output Shape: \", out[0].shape)\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "# summary(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1e0eefd-9bb1-4f3e-b722-78f4108efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "class ClassSpecificImageFolder(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dropped_classes=[],\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        self.dropped_classes = dropped_classes\n",
    "        super(ClassSpecificImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                                       transform=transform,\n",
    "                                                       target_transform=target_transform,\n",
    "                                                       is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        classes = [c for c in classes if c not in self.dropped_classes]\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.0,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init module list\n",
    "        self.module_list = nn.ModuleList()\n",
    "        ### ASSUMES 28x28 image size\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(nn.Conv2d(channels_in, 8, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(nn.Conv2d(8, 6, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(nn.Conv2d(6, 4, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                # set bias to some small non-zero value\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "                or isinstance(layer, ORU)\n",
    "                or isinstance(layer, ERU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "def train(model, trainloader, optimizer, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.train()\n",
    "    #print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "        #List_mx.append(mx)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            if data is None:  # Skip None values\n",
    "                continue\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image\n",
    "            labels = labels\n",
    "            # forward pass\n",
    "            outputs = model(image.to(torch.float32))\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "            #List_mx.append(mx)\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "def create_frame(step,ax,data):\n",
    "    ax=ax.cla()\n",
    "    sns.heatmap(data[step][-1].cpu(),annot=True,cmap=\"cubehelix\",ax=ax,cbar=False)\n",
    "    plt.title('Epoch {} training {}'.format(step,exp)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c",
   "metadata": {
    "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c"
   },
   "outputs": [],
   "source": [
    "#L_activations=[\"gelu\",\"relu\",\"silu\",\"leakyrelu\",\"sigmoid\",\"tanh\"]\n",
    "#csv_files,L_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c657276f-7578-45a1-a58b-db8a21914d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5047)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2) in https://arxiv.org/pdf/2209.14733.pdf\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "class LWLN_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWLN_loss, self).__init__()\n",
    "    def forward(self, vec1,vec2):\n",
    "        loss = (torch.mean((vec1[:,0:208]-vec2[:,0:208])**2)/vec2[:,0:208].std() + \n",
    "                 torch.mean((vec1[:,208:1414]-vec2[:,208:1414])**2)/vec2[:,208:1414].std()+ \n",
    "                 torch.mean((vec1[:,1414:1514]-vec2[:,1414:1514])**2)/vec2[:,1414:1514].std()+\n",
    "                 torch.mean((vec1[:,1514:2254]-vec2[:,1514:2254])**2)/vec2[:,1514:2254].std()+\n",
    "                 torch.mean((vec1[:,2254:2464]-vec2[:,2254:2464])**2)/vec2[:,2254:2464].std())/(6)\n",
    "        \n",
    "        return loss\n",
    "LW=LWLN_loss()\n",
    "LW(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48684b12-575d-4354-84ed-04ce490df41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label task 1</th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy task1</th>\n",
       "      <th>label task 2</th>\n",
       "      <th>Accuracy task2</th>\n",
       "      <th>weight 0</th>\n",
       "      <th>weight 1</th>\n",
       "      <th>weight 2</th>\n",
       "      <th>weight 3</th>\n",
       "      <th>weight 4</th>\n",
       "      <th>...</th>\n",
       "      <th>bias 2462</th>\n",
       "      <th>bias 2463</th>\n",
       "      <th>Loader Set</th>\n",
       "      <th>Reconstructed Accuracy ID</th>\n",
       "      <th>Actual Accuracy</th>\n",
       "      <th>Reconstructed Accuracy OOD</th>\n",
       "      <th>Transformer Loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochCNN</th>\n",
       "      <th>ActivationCNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label task 1, index, Accuracy task1, label task 2, Accuracy task2, weight 0, weight 1, weight 2, weight 3, weight 4, weight 5, weight 6, weight 7, weight 8, weight 9, weight 10, weight 11, weight 12, weight 13, weight 14, weight 15, weight 16, weight 17, weight 18, weight 19, weight 20, weight 21, weight 22, weight 23, weight 24, weight 25, weight 26, weight 27, weight 28, weight 29, weight 30, weight 31, weight 32, weight 33, weight 34, weight 35, weight 36, weight 37, weight 38, weight 39, weight 40, weight 41, weight 42, weight 43, weight 44, weight 45, weight 46, weight 47, weight 48, weight 49, weight 50, weight 51, weight 52, weight 53, weight 54, weight 55, weight 56, weight 57, weight 58, weight 59, weight 60, weight 61, weight 62, weight 63, weight 64, weight 65, weight 66, weight 67, weight 68, weight 69, weight 70, weight 71, weight 72, weight 73, weight 74, weight 75, weight 76, weight 77, weight 78, weight 79, weight 80, weight 81, weight 82, weight 83, weight 84, weight 85, weight 86, weight 87, weight 88, weight 89, weight 90, weight 91, weight 92, weight 93, weight 94, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2477 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cols=[\"label task 1\",\"index\",\"Accuracy task1\",\\\n",
    "      \"label task 2\",\"Accuracy task2\"]+ \\\n",
    "[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Loader Set\",\"Reconstructed Accuracy ID\",\"Actual Accuracy\",\"Reconstructed Accuracy OOD\",\"Transformer Loss\",\"lr\",'epochCNN','ActivationCNN'] \n",
    "\n",
    "print(len(Cols))\n",
    "predicted_Weights= pd.DataFrame(columns=Cols)\n",
    "\n",
    "# row=[\"\".format(task1),int(ind[0]),ACC[0],\"\".format(task2),ACC[1]]+vector_aux.to_list()+[\"train\",valid_epoch_acc0,ACC[2],valid_epoch_acc1,L_train[-1]]\n",
    "# predicted_Weights.append(row, ignore_index=True)\n",
    "predicted_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec127-29d7-4d8a-b935-5d0f1dbcb2e5",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd60539-fb7e-4145-a4cb-8183f9f31f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)\n",
    "def scheduler_to(sched, device):\n",
    "    for param in sched.__dict__.values():\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e960c79-58b9-4f1d-93df-cbccebb9a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 15:24:47.852491\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb7763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def loss_Contractive(W, x, recons_x, h, lam):\n",
    "    dh = h * (1 - h) \n",
    "\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    " \n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "\n",
    "    return contractive_loss.mul_(lam)\n",
    "\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "#print(out[1].shape,W.shape)\n",
    "# for name, param in mod.named_parameters():\n",
    "#     if name == 'vec2neck.weight':\n",
    "#         W = param\n",
    "#         break\n",
    "# CL=loss_Contractive(W,vec1,vec2, out[1], 0.005)\n",
    "\n",
    "# CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a86db2-b453-4c47-86b9-77ea21619679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    head=trial.suggest_int(\"heads\",4,4)\n",
    "    #d_model=trial.suggest_int(\"d_model\",200,1200)\n",
    "    neck=trial.suggest_int(\"neck\",700,700)\n",
    "    p=0.237#trial.suggest_float(\"dropout\",0.2,0.4)\n",
    "    mod = TransformerAE(max_seq_len=20,\n",
    "                        N=head,\n",
    "                        heads=4,\n",
    "                        d_model=1200,\n",
    "                        d_ff=1200,\n",
    "                        neck=neck,\n",
    "                        dropout=p\n",
    "                       )\n",
    "    print( \"model params: \",head,neck,p)\n",
    "    return mod,head,neck,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3901085-aa0a-415d-b9a0-a8f4f2d82488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off optuna log notes.\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(\n",
    "            \"Trial {} finished with best value: {} and parameters: {}. \".format(\n",
    "            frozen_trial.number,\n",
    "            frozen_trial.value,\n",
    "            frozen_trial.params,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f355ed7-d02d-45d1-abb7-4cf1b2273369",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from collections import deque\n",
    "from typing import Dict, Optional, Literal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "### Grokfast\n",
    "def gradfilter_ema(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    alpha: float = 0.99,\n",
    "    lamb: float = 5.0,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    if grads is None:\n",
    "        grads = {n: p.grad.data.detach() for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n] = grads[n] * alpha + p.grad.data.detach() * (1 - alpha)\n",
    "            p.grad.data = p.grad.data + grads[n] * lamb\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "### Grokfast-MA\n",
    "def gradfilter_ma(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, deque]] = None,\n",
    "    window_size: int = 128,\n",
    "    lamb: float = 5.0,\n",
    "    filter_type: Literal['mean', 'sum'] = 'mean',\n",
    "    warmup: bool = True,\n",
    "    trigger: bool = False,\n",
    ") -> Dict[str, deque]:\n",
    "    if grads is None:\n",
    "        grads = {n: deque(maxlen=window_size) for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n].append(p.grad.data.detach())\n",
    "\n",
    "            if not warmup or len(grads[n]) == window_size and not trigger:\n",
    "                if filter_type == \"mean\":\n",
    "                    avg = sum(grads[n]) / len(grads[n])\n",
    "                elif filter_type == \"sum\":\n",
    "                    avg = sum(grads[n])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unrecognized filter_type {filter_type}\")\n",
    "                p.grad.data = p.grad.data + avg * lamb\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
    "outputId": "02799af4-014c-4dab-ec46-33d719329174",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder droupout init 0.237\n",
      "encoder droupout init 0.237\n",
      "decoder droupout init 0.237\n",
      "model params:  4 700 0.237\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "TransformerAE                                 --\n",
      "├─EncoderNeuronGroup: 1-1                     --\n",
      "│    └─EmbedderNeuronGroup: 2-1               --\n",
      "│    │    └─Linear: 3-1                       241,200\n",
      "│    │    └─Linear: 3-2                       87,600\n",
      "│    └─PositionalEncoder: 2-2                 --\n",
      "│    └─ModuleList: 2-3                        --\n",
      "│    │    └─EncoderLayer: 3-3                 8,652,000\n",
      "│    │    └─EncoderLayer: 3-4                 8,652,000\n",
      "│    │    └─EncoderLayer: 3-5                 8,652,000\n",
      "│    │    └─EncoderLayer: 3-6                 8,652,000\n",
      "│    └─Norm: 2-4                              2,400\n",
      "├─EncoderNeuronGroup: 1-2                     --\n",
      "│    └─EmbedderNeuronGroup: 2-5               --\n",
      "│    │    └─Linear: 3-7                       241,200\n",
      "│    │    └─Linear: 3-8                       87,600\n",
      "│    └─PositionalEncoder: 2-6                 --\n",
      "│    └─ModuleList: 2-7                        --\n",
      "│    │    └─EncoderLayer: 3-9                 8,652,000\n",
      "│    │    └─EncoderLayer: 3-10                8,652,000\n",
      "│    │    └─EncoderLayer: 3-11                8,652,000\n",
      "│    │    └─EncoderLayer: 3-12                8,652,000\n",
      "│    └─Norm: 2-8                              2,400\n",
      "├─DecoderNeuronGroup: 1-3                     --\n",
      "│    └─Neck2Seq: 2-9                          --\n",
      "│    │    └─ModuleList: 3-13                  16,824,000\n",
      "│    └─PositionalEncoder: 2-10                --\n",
      "│    └─ModuleList: 2-11                       --\n",
      "│    │    └─EncoderLayer: 3-14                8,652,000\n",
      "│    │    └─EncoderLayer: 3-15                8,652,000\n",
      "│    │    └─EncoderLayer: 3-16                8,652,000\n",
      "│    │    └─EncoderLayer: 3-17                8,652,000\n",
      "│    └─Norm: 2-12                             2,400\n",
      "│    └─Seq2Vec: 2-13                          --\n",
      "│    │    └─Linear: 3-18                      59,138,464\n",
      "├─Linear: 1-4                                 1,680,700\n",
      "├─Tanh: 1-5                                   --\n",
      "======================================================================\n",
      "Total params: 182,131,964\n",
      "Trainable params: 182,131,964\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "MSE 0.6 CyclicLR 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:y3gmsarr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f24823d0e8f47e08c54a663bdee7712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Epochs 101 MSE CyclicLR 150</strong> at: <a href='https://wandb.ai/aymentlili/aymen-project/runs/y3gmsarr' target=\"_blank\">https://wandb.ai/aymentlili/aymen-project/runs/y3gmsarr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_152450-y3gmsarr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:y3gmsarr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e76f1cb479344f1891836f52377c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670526183831195, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/crns/Documents/GitHub/Federated-Continual-learning-/New/wandb/run-20240610_152639-22mpg9c7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aymentlili/aymen-project/runs/22mpg9c7' target=\"_blank\">Epochs 101 MSE CyclicLR 150</a></strong> to <a href='https://wandb.ai/aymentlili/aymen-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aymentlili/aymen-project' target=\"_blank\">https://wandb.ai/aymentlili/aymen-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aymentlili/aymen-project/runs/22mpg9c7' target=\"_blank\">https://wandb.ai/aymentlili/aymen-project/runs/22mpg9c7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3970/3970 [1:48:42<00:00,  1.64s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:47:21<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:37<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:47:13<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:36<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:47:14<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:37<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:47:02<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:46:54<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:56<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:53<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:43<00:00,  1.89s/it]\n",
      "100%|██████████| 3970/3970 [1:46:43<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:47:59<00:00,  1.63s/it]\n",
      "100%|██████████| 150/150 [04:48<00:00,  1.92s/it]\n",
      "100%|██████████| 3970/3970 [1:46:57<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:37<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:46:08<00:00,  1.60s/it]\n",
      "100%|██████████| 150/150 [04:35<00:00,  1.84s/it]\n",
      "100%|██████████| 3970/3970 [1:47:33<00:00,  1.63s/it]\n",
      "100%|██████████| 150/150 [04:44<00:00,  1.89s/it]\n",
      "100%|██████████| 3970/3970 [1:47:49<00:00,  1.63s/it]\n",
      "100%|██████████| 150/150 [04:37<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:46:58<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:37<00:00,  1.85s/it]\n",
      "100%|██████████| 3970/3970 [1:46:53<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:38<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:31<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:37<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:39<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:49<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:41<00:00,  1.88s/it]\n",
      "100%|██████████| 3970/3970 [1:46:42<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:39<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:44<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:39<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:41<00:00,  1.88s/it]\n",
      "100%|██████████| 3970/3970 [1:46:40<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:38<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:37<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:42<00:00,  1.88s/it]\n",
      "100%|██████████| 3970/3970 [1:46:42<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:41<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:52<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:38<00:00,  1.86s/it]\n",
      " 38%|███▊      | 1496/3970 [40:19<1:06:50,  1.62s/it]wandb: Network error (ConnectionError), entering retry loop.\n",
      "100%|██████████| 3970/3970 [1:46:55<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:43<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:41<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:43<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:47<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      "100%|██████████| 3970/3970 [1:46:59<00:00,  1.62s/it]\n",
      "100%|██████████| 150/150 [04:39<00:00,  1.86s/it]\n",
      "100%|██████████| 3970/3970 [1:46:49<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:42<00:00,  1.88s/it]\n",
      "100%|██████████| 3970/3970 [1:46:44<00:00,  1.61s/it]\n",
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n",
      " 13%|█▎        | 517/3970 [13:56<1:33:05,  1.62s/it]\n",
      "[W 2024-06-13 12:31:16,843] Trial 0 failed with parameters: {'Loss function': 'MSE', 'heads': 4, 'neck': 700, 'scheduler': 'CyclicLR'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_489799/3562222122.py\", line 112, in objective\n",
      "    Dataset,EXP,ACC,U = cs_tr[i]\n",
      "  File \"/home/crns/Documents/GitHub/Federated-Continual-learning-/New/Double_input_transformer.py\", line 97, in __getitem__\n",
      "    rowk=self.df[(self.df[\"label\"]=='{}'.format(tg))&(self.df[\"epoch\"]==int(self.D_epoch[str(batch[i][2])]))&(self.df[self.D_activ[str(batch[i][3])]]==float(1))]\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\", line 70, in new_method\n",
      "    return method(self, other)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\", line 40, in __eq__\n",
      "    return self._cmp_method(other, operator.eq)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\", line 5623, in _cmp_method\n",
      "    res_values = ops.comparison_op(lvalues, rvalues, op)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\", line 283, in comparison_op\n",
      "    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\", line 73, in comp_method_OBJECT_ARRAY\n",
      "    result = libops.scalar_compare(x.ravel(), y, op)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-13 12:31:16,854] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_489799/3562222122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_tr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_489799/3562222122.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m#start_time_batch = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEXP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcs_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Federated-Continual-learning-/New/Double_input_transformer.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mrowk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_activ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mind3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5622\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5623\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv \n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "import gc\n",
    "from accelerate import Accelerator\n",
    "global track\n",
    "\n",
    "track=0\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "storage = JournalStorage(JournalFileStorage(\"optuna-journal DDP 3 Losses.log\"))\n",
    "\n",
    "def objective(trial):\n",
    "    global track\n",
    "    grads=None\n",
    "    accelerator = Accelerator()\n",
    "    Loss=trial.suggest_categorical(\"Loss function\",[\"MSE\"])#,\"LWLN\",\"Contractive\",])\n",
    "    Lambda=0\n",
    "    if Loss==\"MSE\":\n",
    "        results_path=\"/media/crns/ADATA HD330/Experiments/model MSE/\"\n",
    "    if Loss==\"Contractive\":\n",
    "        results_path=\"./Contractive model/\"\n",
    "        Lambda=trial.suggest_float(\"Contractive_Lambda\",0.00001,0.0001)\n",
    "    if Loss==\"LWLN\":\n",
    "        results_path=\"./mixed model/\"\n",
    "        \n",
    "    cnn_acc_ID=[]\n",
    "    cnn_acc_OOD=[]\n",
    "    \n",
    "    step_size=0\n",
    "    factor=0\n",
    "    threshhold=0\n",
    "    threshold_mode = 0\n",
    "    eps=0\n",
    "   \n",
    "    \n",
    "    mod,head,neck,p=define_model(trial)\n",
    "    print(summary(mod))\n",
    "    lr=0.6 #trial.suggest_float(\"Learning_rate\",0.0002,0.5)\n",
    "    optimizer = Adam(mod.parameters(), lr=lr,eps=1e-10,weight_decay=0.005)\n",
    "    sched_name=trial.suggest_categorical(\"scheduler\",[\"CyclicLR\"])#,\"ReduceLROnPlateau\"])\n",
    "    if sched_name==\"CyclicLR\" :\n",
    "        step_size=120000#trial.suggest_int(\"step_size_up\",900,2800)\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=0.9, step_size_up=step_size, step_size_down=80000,scale_mode=\"iterations\",mode=\"triangular2\", cycle_momentum=False)\n",
    "    if sched_name==\"ReduceLROnPlateau\" :\n",
    "        factor=trial.suggest_float(\"R-lr-OP_factor\",0.001,0.5)\n",
    "        threshhold=trial.suggest_float(\"R-lr-OP_threshhold\",0.0001,0.001)\n",
    "        threshold_mode = trial.suggest_categorical(\"thresh_mod\",[\"rel\",\"abs\"])\n",
    "        eps=trial.suggest_float(\"R-lr-OP_eps\",1e-08,1e-05)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=5, threshold=threshhold, threshold_mode=threshold_mode, cooldown=2, min_lr=0, eps=eps)\n",
    "    \n",
    "    \n",
    "    batch_size=150#trial.suggest_int(\"batch_size\",150)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    LW=LWLN_loss()\n",
    "    \n",
    "    num_epochs=101\n",
    "    #device = accelerator.device\n",
    "    print(Loss, lr,sched_name,batch_size)\n",
    " \n",
    "    run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"aymen-project\",\n",
    "    name= \"Epochs \"+str(num_epochs)+\" \"+Loss+\" \"+sched_name+\" \"+str(batch_size),\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"Loss\":Loss,\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"head\": head,\n",
    "        \"neck\": neck,\n",
    "        \"p\": p,\n",
    "        \"sched_name\": sched_name,\n",
    "        \"step_size\": step_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"step_size\":step_size,\n",
    "        \"factor\":factor,\n",
    "        \"threshhold\":threshhold,\n",
    "        \"threshold_mode\":threshold_mode,\n",
    "        \"eps\":eps,\n",
    "        \"Lambda\":Lambda\n",
    "    },\n",
    ")\n",
    "    \n",
    "    cs_tr=CustomDataset(train_pair,batch_size=batch_size)\n",
    "    nb_batches = len(cs_tr)//batch_size\n",
    "\n",
    "    #optimizer_to(optimizer,device)\n",
    "    #scheduler_to(scheduler,device)\n",
    "\n",
    "    mod, optimizer, cs_tr, scheduler = accelerator.prepare(mod, optimizer, cs_tr, scheduler)\n",
    "\n",
    "    mod.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        #start_time_epoch = time.time()\n",
    "        for i in tqdm(range(nb_batches)):\n",
    "            #start_time_batch = time.time()\n",
    "            Dataset,EXP,ACC,U = cs_tr[i]\n",
    "            x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]\n",
    "            try:\n",
    "                if (Loss==\"Contractive\") and (i%50==0):\n",
    "                    for name, param in mod.named_parameters():\n",
    "                        if name == 'vec2neck.weight':\n",
    "                            W = param\n",
    "                            break\n",
    "                       \n",
    "\n",
    "                \n",
    "                x1=x1.cuda() #.to(torch.float32)\n",
    "                x2=x2.cuda() #.to(torch.float32)\n",
    "                tg=tg.cuda() #.to(torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = mod(x1,x2)\n",
    "                if Loss==\"MSE\":\n",
    "                    loss_tr = criterion(output[0],tg)\n",
    "                if Loss==\"Contractive\":\n",
    "                    CL=loss_Contractive(W,vec1,vec2, output[1], Lambda)\n",
    "                    loss_tr = criterion(output[0],tg)+CL\n",
    "                if Loss==\"LWLN\":\n",
    "                    loss_tr = criterion(output[0],tg)+LW(vec1,vec2)\n",
    "               \n",
    "               \n",
    "            except Exception as e:\n",
    "                # Print the exception\n",
    "                print(\"An exception occurred:\", e)\n",
    "                traceback.print_exc()\n",
    "                # Continue with the loop\n",
    "                continue\n",
    "\n",
    "            \n",
    "            accelerator.backward(loss_tr)\n",
    "            grads = gradfilter_ema(mod, grads=grads, alpha=0.98, lamb=2)\n",
    "            optimizer.step()\n",
    "            if sched_name==\"ReduceLROnPlateau\" :\n",
    "                scheduler.step(loss_tr)\n",
    "            else:\n",
    "                 scheduler.step()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            loss_to_save = float(loss_tr.detach().cpu().item())\n",
    "            wandb.log({\"Loss\":loss_to_save})\n",
    "            wandb.log({\"CNN_IID\":(np.mean(cnn_acc_ID))})\n",
    "            wandb.log({\"CNN_OOD\":(np.mean(cnn_acc_OOD))})\n",
    "            wandb.log({\"lr\": lr})    \n",
    "            \n",
    "        if i in [int(nb_batches/4),int(nb_batches/4)*2,int(nb_batches/4)*3,nb_batches-1] :\n",
    "            cnn_acc_ID=[]\n",
    "            cnn_acc_OOD=[]\n",
    "            for vect in tqdm(range(len(x1))):\n",
    "                y_pred=torch.unsqueeze(output[0][vect], 0) \n",
    "                y =torch.unsqueeze(tg[vect], 0) \n",
    "                \n",
    "                selected_row = cs_tr.df.iloc[int(U[vect][0]), 11:17]  \n",
    "                columns_with_one = selected_row[selected_row == 1].index.tolist()\n",
    "                activ=columns_with_one\n",
    "                epochCNN=cs_tr.df.loc[int(U[vect][0])]['epoch']\n",
    "                \n",
    "                \n",
    "                checkpoint=OrderedDict()\n",
    "                vector_aux= output[0][vect].detach()\n",
    "                y_pred=vector_aux.cpu()\n",
    "    \n",
    "                task1=[int(x) for x in EXP[vect][0]]\n",
    "                task2=[int(x) for x in EXP[vect][1]]\n",
    "                task3=sorted(task1+task2)\n",
    "    \n",
    "    \n",
    "                All=list(range(10))\n",
    "                L2=[k for k in All if k not in task3] #Classes to test on (In distribution)\n",
    "                L_others=[k for k in All if k not in task3] # Out of distribution classes\n",
    "    \n",
    "                checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(y_pred[0:200]).reshape([8, 1, 5, 5]))\n",
    "                checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(y_pred[200:208]).reshape([8]))\n",
    "    \n",
    "                checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(y_pred[208:1408]).reshape([6, 8, 5, 5]))\n",
    "                checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(y_pred[1408:1414]).reshape([6]))\n",
    "    \n",
    "                checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(y_pred[1414:1510]).reshape([4, 6, 2, 2]))\n",
    "                checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(y_pred[1510:1514]).reshape([4]))\n",
    "    \n",
    "                checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(y_pred[1514:2234]).reshape([20,36]))\n",
    "                checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(y_pred[2234:2254]).reshape([20]))\n",
    "    \n",
    "                checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(y_pred[2254:2454]).reshape([10,20]))\n",
    "                checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(y_pred[2454:2464]).reshape([10]))\n",
    "    \n",
    "                Brain = CNN(1,activ[0],0,\"kaiming_uniform\")\n",
    "    \n",
    "                model=copy.deepcopy(Brain).to(torch.float32)\n",
    "                model.load_state_dict(checkpoint)\n",
    "    \n",
    "                criterion_CNN0=CrossEntropyLoss()\n",
    "    \n",
    "                test_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Ts_DL0 = DataLoader(dataset=test_IF0, batch_size=20, num_workers=0, shuffle=True)\n",
    "                \n",
    "                _, valid_epoch_acc0,_= validate(model, Ts_DL0,  criterion_CNN0,10)\n",
    "                if len(task3)==10:\n",
    "                    valid_epoch_acc1=valid_epoch_acc0\n",
    "                    continue\n",
    "                else:\n",
    "                    criterion_CNN1=CrossEntropyLoss()\n",
    "                    test_IF1=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in task3],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                    Ts_DL1 = DataLoader(dataset=test_IF1, batch_size=20, num_workers=0, shuffle=True)\n",
    "                \n",
    "                valid_epoch_loss0, valid_epoch_acc1,L_mx= validate(model, Ts_DL1,  criterion_CNN1,10)\n",
    "                cnn_acc_ID.append(valid_epoch_acc0)\n",
    "                cnn_acc_OOD.append(valid_epoch_acc1)\n",
    "                lr = optimizer.param_groups[0][\"lr\"]\n",
    "                \n",
    "        \n",
    "        if epoch%10==0:\n",
    "            torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'Batch Loss':loss_tr.detach().cpu().item()},results_path+'AE epoch {} {}.pth'.format(track,epoch))\n",
    "    # if trial.should_prune():\n",
    "    #     raise optuna.exceptions.TrialPruned()\n",
    "    wandb.finish()\n",
    "    track=+1\n",
    "    return loss_tr\n",
    "study= optuna.create_study(direction=\"minimize\",storage=storage)\n",
    "study.optimize(objective,n_trials=15,callbacks=[lambda study, trial: gc.collect()]+[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540a0ab-08fa-4671-bf42-3f70a2974173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.nccl.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9b3f3-5205-41d8-8ee1-1319ccde799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a853a-0078-46fa-9e81-056caac19f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    ",EXP,ACC,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d0df8-f15c-41c9-8fbb-fdc74274c3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d206787-c1b6-41a6-abf0-05e4f2c702cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch%30==0 or (epoch in [1,3,5,10]):\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            vectstring=f\"{y_pred.tolist()}\".replace(\" \", \"\")[1:-1].split(',')\n",
    "            row_part=f\"{task1};{int(U[vect][0])};{float(ACC[vect][0])};{task2};{float(ACC[vect][1])}\".split(\";\")\n",
    "            row_part2=f\"train,{valid_epoch_acc0},{float(ACC[vect][2])},{valid_epoch_acc1},{float(loss_tr.detach().cpu())},{lr},{epochCNN},{activ[0]}\".split(\",\")\n",
    "            row=row_part+vectstring+row_part2\n",
    "            \n",
    "            temp_file = os.path.join(results_path,f'AE Tracking {track}.csv')\n",
    "        \n",
    "            if vect%150==0:\n",
    "                print(task3,len(Ts_DL0.dataset))\n",
    "                print(L2,len(Ts_DL1.dataset))\n",
    "                print(\"epoch\" ,epoch, \"\\t\", \"\\t batch: \",f\"/{len(Dataset)}\",f\"\\t Learning rate :\" ,f\"{lr:.8f}\")\n",
    "                temp_file = os.path.join(results_path, f'AE Tracking {track}.csv')\n",
    "                with open(temp_file, mode='a', newline='\\n') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(Cols)\n",
    "                \n",
    "            with open(temp_file, mode='a', newline='\\n') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(row)\n",
    "            if vect%150==0:\n",
    "                track += 1\n",
    "\n",
    "        csv_files = [file for file in os.listdir(results_path) if file.endswith(\".csv\")]\n",
    "        csv_files.sort(key=lambda x: int(x.split(\" \")[2][:-4]))\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(results_path, \"AE Tracking 0.csv\"),header=[0])\n",
    "        res= pd.DataFrame(columns=df.columns)\n",
    "        for file in csv_files:\n",
    "            df = pd.read_csv(os.path.join(results_path, file), header=[0])\n",
    "            res = res.append(df, ignore_index=True)\n",
    "        print(\"epoch\",epoch,'\\n','worst_CNN_ACC \\t',  float(min(res[[\"Reconstructed Accuracy ID\"]].values)),'\\n','best_CNN_ACC \\t',float(max(res[[\"Reconstructed Accuracy ID\"]].values)),'\\n','max_Transformer_loss \\t',float(max(res[[\"Transformer Loss\"]].values)),'\\n','min_CNN_ACC \\t',float(min(res[[\"Transformer Loss\"]].values)))\n",
    "                torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'Batch Loss':loss_tr.detach().cpu().item(),'last_batch_CNN_ACC':valid_epoch_acc0,'worst_CNN_ACC':  float(min(res[[\"Reconstructed Accuracy ID\"]].values)),'best_CNN_ACC':float(max(res[[\"Reconstructed Accuracy ID\"]].values)),'max_Transformer_loss':float(max(res[[\"Transformer Loss\"]].values)),'min_CNN_ACC':float(min(res[[\"Transformer Loss\"]].values))},results_path+'AE epoch {}.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddb1dd-7ba0-4d3a-b94a-132b7c9ac4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d678-66e0-4fdc-b4b3-11f1c42fca65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f9ea2-757f-4c08-a838-968f9b27d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2949b-41d1-4cb9-90e5-ec389c2e6e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38362539-dd58-4e3c-925e-f313b21e4819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54092b-8cfd-4691-a8f9-caa1b00eb39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7993d-f994-485c-9169-827e94211812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbfa86-331e-4c39-92f4-e35133be58bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699aba2-6928-4425-b344-ad810f9fc144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4966281-ab38-4bac-aaef-98d1ff59e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df29ecd-9235-45f4-951a-ecfe9cc1a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616cff7-b29e-4984-9dc5-f8b13aec2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73672723-0e7f-42b2-8c86-1dad689519f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa23f52-93fa-410f-918e-d9da64b9145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/memory-management-using-pytorch-cuda-alloc-conf/157850\n",
    "#https://stackoverflow.com/questions/73747731/runtimeerror-cuda-out-of-memory-how-can-i-set-max-split-size-mb\n",
    "\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
