{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c",
   "metadata": {
    "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "import random\n",
    "import ast\n",
    "        \n",
    "\n",
    "import torch.nn.functional as F\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from torch.optim import Adam ,SGD ,Adadelta\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation ,FFMpegWriter ,PillowWriter\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os \n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c973ef-a1c2-4c67-88f5-5c2cdc634f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceed1bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maymentlili\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/crns/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"ab631efc36e2c87f5f54d82b5cdbd6c501d5221f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecd06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c395ca-191a-49f4-b45c-e87ecd231e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
    "outputId": "9229fdc7-630d-4e87-d54b-3771391ef44c"
   },
   "outputs": [],
   "source": [
    "seed=74\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a1e1f6-dcf6-4c01-b2c3-ab25ee771a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Double_input_transformer import CustomDataset,TransformerAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655000ba-32ed-41d3-93a3-522336521239",
   "metadata": {
    "id": "655000ba-32ed-41d3-93a3-522336521239"
   },
   "source": [
    "# Trainloader code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2e5630-1312-47db-b6b1-1646cb9eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the list\n",
    "train_pair2 = np.load('train_pair++.npy', allow_pickle=True)\n",
    "test_pair2 = np.load('test_pair++.npy', allow_pickle=True)\n",
    "val_pair2 = np.load('val_pair++.npy', allow_pickle=True)\n",
    "train_pair2 = [ list(x) for x in train_pair2]\n",
    "test_pair2 = [ list(x) for x in test_pair2]\n",
    "val_pair2 = [ list(x) for x in val_pair2]\n",
    "random.shuffle(train_pair2)\n",
    "random.shuffle(test_pair2)\n",
    "random.shuffle(val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96f0b1d-6532-48da-9cfb-44a1fe16465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10]]\n"
     ]
    }
   ],
   "source": [
    "def batchify(lst, batch_size):\n",
    "    return [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]\n",
    "\n",
    "# Example usage:\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "batch_size = 4\n",
    "batches = batchify(my_list, batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e37e4a-a947-407d-9700-352fec773e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15822, 3743, 3871)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pair2),len(test_pair2),len(val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f58a0b2-cde4-4e58-9f7a-61c3576e245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All = list(train_pair2)+list(test_pair2)+list(val_pair2)\n",
    "All = [ list(x) for x in All]\n",
    "All.sort(reverse=True)\n",
    "len(All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83dd4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_pair2=[]\n",
    "# test_pair2=[]\n",
    "# val_pair2=[]\n",
    "# for i,L1 in tqdm(enumerate(All)) :\n",
    "#     matches=[]\n",
    "#     for L2 in All :\n",
    "#         if L2[2]==4 and L2[3]==0 and L1[2]==4 and L1[3]==0 and L1[0]==L2[0] and L2 not in matches and L2 not in train_pair2 and L2 not in test_pair2  and L2 not in val_pair2 :\n",
    "#             matches.append(L2)\n",
    "#     train_pair2.extend(matches[:int(len(matches)*0.7)])\n",
    "#     test_pair2.extend(matches[int(len(matches)*0.7):int(len(matches)*0.85)])\n",
    "#     val_pair2.extend(matches[int(len(matches)*0.85):])\n",
    "#     if L1[0]==[0,1,2,3,4,5,6,7] :\n",
    "#         print(len(matches))\n",
    "# print(len(train_pair2))\n",
    "# print(len(test_pair2))\n",
    "# print(len(val_pair2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c882cca-06d4-42a3-ab31-3cfed2e7d410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs_tr=CustomDataset(train_pair,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c1f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset,EXP,ACC,U = cs_tr[0]\n",
    "#x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4e714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 2, 5, 6, 8, 9], [4, 7], 4, 0], [[0, 3, 9], [2, 4, 5], 4, 0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x1.shape\n",
    "train_pair2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0930913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All = list(train_pair)+list(test_pair)+list(val_pair)\n",
    "# All = [ list(x) for x in All]\n",
    "# train_pair=[]\n",
    "# test_pair=[]\n",
    "# val_pair=[]\n",
    "# for L1 in tqdm(All) :\n",
    "#     matches=[]\n",
    "#     for L2 in All :\n",
    "#         if L1[0]==L2[0] and L2 not in matches and L2[2]==4 and L2[3]==0 :\n",
    "#             matches.append(L2)\n",
    "#     train_pair.extend(matches[:int(len(matches)*0.7)])\n",
    "#     test_pair.extend(matches[int(len(matches)*0.7):int(len(matches)*0.85)])\n",
    "#     val_pair.extend(matches[int(len(matches)*0.85):])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8df0e3-2ced-4468-a5aa-75d9102b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pair=test_pair[int(len(test_pair)/2):]\n",
    "# test_pair=test_pair[:int(len(test_pair)/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86052495-ee40-454c-a374-25172cfa6083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a0a5b4-7b2e-4abb-b007-6b4cf79c7a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1, 3], [2, 4, 5, 7], 4, 0], 15822)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pair2[0] ,len(train_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7adeaf93-b728-4094-9c5c-1ace4bd7f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"train_pair++\", train_pair2)\n",
    "# np.save(\"test_pair++\", test_pair2)\n",
    "# np.save(\"val_pair++\", val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0baa11-e37f-4903-8215-2b7c0e0b8ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2",
   "metadata": {
    "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "387b2953-3794-42d9-a327-5e7cca27939d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387b2953-3794-42d9-a327-5e7cca27939d",
    "outputId": "29fef800-a2d7-43d4-dafb-9fa69bda52ca"
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b",
   "metadata": {
    "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30",
   "metadata": {
    "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72",
   "metadata": {
    "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a",
   "metadata": {
    "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a"
   },
   "outputs": [],
   "source": [
    "class EmbedderNeuronGroup(nn.Module):\n",
    "    def __init__(self, d_model, seed=22):\n",
    "        super().__init__()\n",
    "        #print(\"EmbedderNeuroneGroup\")\n",
    "        self.neuron_l1 = nn.Linear(200, d_model) #8\n",
    "        self.neuron_l2 = nn.Linear(72, d_model) #12\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.multiLinear(x)\n",
    "\n",
    "    def multiLinear(self, v):\n",
    "        #print(\"multi-linear method\",v.shape)\n",
    "\n",
    "        l = []\n",
    "\n",
    "        for ndx in range(8):\n",
    "            idx_start = ndx * 200\n",
    "            idx_end = idx_start + 200\n",
    "            l.append(self.neuron_l1(v[:,idx_start:idx_end]))\n",
    "\n",
    "        # l2\n",
    "        for ndx in range(12):\n",
    "            idx_start = 200*8 + ndx * 72\n",
    "            idx_end = idx_start + 72\n",
    "            l.append(self.neuron_l2(v[:,idx_start:idx_end]))\n",
    "        #print(len(l))\n",
    "        #print(len(l[0]))\n",
    "        final = torch.stack(l, dim=1)\n",
    "\n",
    "        # print(final.shape)\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2",
   "metadata": {
    "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f",
   "metadata": {
    "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f"
   },
   "outputs": [],
   "source": [
    "# max_seq_len=176,\n",
    "# N=4\n",
    "# heads=3\n",
    "# d_model=900\n",
    "# d_ff=900\n",
    "# neck=700\n",
    "# dropout=0.1\n",
    "# # Enc=EncoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff)\n",
    "# # vec1 = torch.rand(1,2464)\n",
    "# # res,scores=Enc(vec1)\n",
    "# # res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad",
   "metadata": {
    "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278",
   "metadata": {
    "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278"
   },
   "outputs": [],
   "source": [
    "# vec2neck = nn.Linear(d_ff*2, neck)\n",
    "# print(res.shape)\n",
    "# out3=torch.cat([res,res], dim=2)\n",
    "# print(\"neck input:\",out3.shape)\n",
    "# sum_r=torch.sum(out3, dim=1, keepdim=False)\n",
    "# vec2=vec2neck(sum_r)\n",
    "# print(len(vec2))\n",
    "# tanh = nn.Tanh()\n",
    "# neck_t=tanh(vec2)\n",
    "# print(\"neck shape:\",neck_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac",
   "metadata": {
    "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4",
   "metadata": {
    "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa74a80-dee8-4710-a221-a448b37758d1",
   "metadata": {
    "id": "efa74a80-dee8-4710-a221-a448b37758d1"
   },
   "outputs": [],
   "source": [
    "# Dec=DecoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff,neck=neck)\n",
    "# res,scores=Dec(neck_t)\n",
    "# res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf",
   "metadata": {
    "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5",
   "metadata": {
    "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d",
   "metadata": {
    "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65",
   "metadata": {
    "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
    "outputId": "7301efd4-e73d-46ce-baa8-b3b12a63c900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3743, 15822, 3871)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pair2),len(train_pair2),len(val_pair2)#,len(test_tgt),len(train_tgt),len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649",
   "metadata": {
    "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649"
   },
   "outputs": [],
   "source": [
    "#test_pair=[ x for x in test_pair  if (0 in x[0]) and (1 in x[0]) and (2 in x[0] or 2 in x[1] ) and (3 in[0] or 2 in x[1]) and (4 in[0] or 2 in x[1] ) ]\n",
    "#len(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "619486cb-4a43-408f-976c-74c7d6a840d9",
   "metadata": {
    "id": "619486cb-4a43-408f-976c-74c7d6a840d9"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "class ClassSpecificImageFolder(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dropped_classes=[],\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        self.dropped_classes = dropped_classes\n",
    "        super(ClassSpecificImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                                       transform=transform,\n",
    "                                                       target_transform=target_transform,\n",
    "                                                       is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        classes = [c for c in classes if c not in self.dropped_classes]\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
    "outputId": "9429472d-98a4-47db-c47e-af78aadfba49"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(mod.numParams())\n",
    "# x1 = torch.rand(1,2464)\n",
    "# x2 = torch.rand(1,2464)\n",
    "# mod=mod.to(device).to(torch.float32)\n",
    "\n",
    "# #x1=x1.to(torch.float32)\n",
    "# #x2=x2.to(torch.float32)\n",
    "# x1=x1.to(device)\n",
    "# x2=x2.to(device)\n",
    "# mod=mod.to(device)\n",
    "# out = mod(x1,x2)\n",
    "# print(\"Output Shape: \", out[0].shape)\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "# summary(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e0eefd-9bb1-4f3e-b722-78f4108efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.0,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init module list\n",
    "        self.module_list = nn.ModuleList()\n",
    "        ### ASSUMES 28x28 image size\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(nn.Conv2d(channels_in, 8, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(nn.Conv2d(8, 6, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(nn.Conv2d(6, 4, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                # set bias to some small non-zero value\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "                or isinstance(layer, ORU)\n",
    "                or isinstance(layer, ERU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "def train(model, trainloader, optimizer, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.train()\n",
    "    #print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "        #List_mx.append(mx)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "        if i == len(trainloader)/20:\n",
    "            break\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            if data is None:  # Skip None values\n",
    "                continue\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image\n",
    "            labels = labels\n",
    "            # forward pass\n",
    "            outputs = model(image.to(torch.float32))\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "            #List_mx.append(mx)\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "def create_frame(step,ax,data):\n",
    "    ax=ax.cla()\n",
    "    sns.heatmap(data[step][-1].cpu(),annot=True,cmap=\"cubehelix\",ax=ax,cbar=False)\n",
    "    plt.title('Epoch {} training {}'.format(step,exp)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c",
   "metadata": {
    "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c"
   },
   "outputs": [],
   "source": [
    "#L_activations=[\"gelu\",\"relu\",\"silu\",\"leakyrelu\",\"sigmoid\",\"tanh\"]\n",
    "#csv_files,L_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c657276f-7578-45a1-a58b-db8a21914d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4551)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2) in https://arxiv.org/pdf/2209.14733.pdf\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "class LWLN_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWLN_loss, self).__init__()\n",
    "    def forward(self, vec1,vec2):\n",
    "        loss = (torch.mean((vec1[:,0:208]-vec2[:,0:208])**2)/vec2[:,0:208].std() + \n",
    "                 torch.mean((vec1[:,208:1414]-vec2[:,208:1414])**2)/vec2[:,208:1414].std()+ \n",
    "                 torch.mean((vec1[:,1414:1514]-vec2[:,1414:1514])**2)/vec2[:,1414:1514].std()+\n",
    "                 torch.mean((vec1[:,1514:2254]-vec2[:,1514:2254])**2)/vec2[:,1514:2254].std()+\n",
    "                 torch.mean((vec1[:,2254:2464]-vec2[:,2254:2464])**2)/vec2[:,2254:2464].std())/(6)\n",
    "        \n",
    "        return loss\n",
    "LW=LWLN_loss()\n",
    "LW(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48684b12-575d-4354-84ed-04ce490df41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label task 1</th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy task1</th>\n",
       "      <th>label task 2</th>\n",
       "      <th>Accuracy task2</th>\n",
       "      <th>weight 0</th>\n",
       "      <th>weight 1</th>\n",
       "      <th>weight 2</th>\n",
       "      <th>weight 3</th>\n",
       "      <th>weight 4</th>\n",
       "      <th>...</th>\n",
       "      <th>bias 2462</th>\n",
       "      <th>bias 2463</th>\n",
       "      <th>Loader Set</th>\n",
       "      <th>Reconstructed Accuracy ID</th>\n",
       "      <th>Actual Accuracy</th>\n",
       "      <th>Reconstructed Accuracy OOD</th>\n",
       "      <th>Transformer Loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochCNN</th>\n",
       "      <th>ActivationCNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label task 1, index, Accuracy task1, label task 2, Accuracy task2, weight 0, weight 1, weight 2, weight 3, weight 4, weight 5, weight 6, weight 7, weight 8, weight 9, weight 10, weight 11, weight 12, weight 13, weight 14, weight 15, weight 16, weight 17, weight 18, weight 19, weight 20, weight 21, weight 22, weight 23, weight 24, weight 25, weight 26, weight 27, weight 28, weight 29, weight 30, weight 31, weight 32, weight 33, weight 34, weight 35, weight 36, weight 37, weight 38, weight 39, weight 40, weight 41, weight 42, weight 43, weight 44, weight 45, weight 46, weight 47, weight 48, weight 49, weight 50, weight 51, weight 52, weight 53, weight 54, weight 55, weight 56, weight 57, weight 58, weight 59, weight 60, weight 61, weight 62, weight 63, weight 64, weight 65, weight 66, weight 67, weight 68, weight 69, weight 70, weight 71, weight 72, weight 73, weight 74, weight 75, weight 76, weight 77, weight 78, weight 79, weight 80, weight 81, weight 82, weight 83, weight 84, weight 85, weight 86, weight 87, weight 88, weight 89, weight 90, weight 91, weight 92, weight 93, weight 94, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2477 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cols=[\"label task 1\",\"index\",\"Accuracy task1\",\\\n",
    "      \"label task 2\",\"Accuracy task2\"]+ \\\n",
    "[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Loader Set\",\"Reconstructed Accuracy ID\",\"Actual Accuracy\",\"Reconstructed Accuracy OOD\",\"Transformer Loss\",\"lr\",'epochCNN','ActivationCNN'] \n",
    "\n",
    "print(len(Cols))\n",
    "predicted_Weights= pd.DataFrame(columns=Cols)\n",
    "\n",
    "# row=[\"\".format(task1),int(ind[0]),ACC[0],\"\".format(task2),ACC[1]]+vector_aux.to_list()+[\"train\",valid_epoch_acc0,ACC[2],valid_epoch_acc1,L_train[-1]]\n",
    "# predicted_Weights.append(row, ignore_index=True)\n",
    "predicted_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec127-29d7-4d8a-b935-5d0f1dbcb2e5",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcd60539-fb7e-4145-a4cb-8183f9f31f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)\n",
    "def scheduler_to(sched, device):\n",
    "    for param in sched.__dict__.values():\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e960c79-58b9-4f1d-93df-cbccebb9a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 11:30:39.770379\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb7763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def loss_Contractive(W, x, recons_x, h, lam):\n",
    "    dh = h * (1 - h) \n",
    "\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    " \n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "\n",
    "    return contractive_loss.mul_(lam)\n",
    "\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "#print(out[1].shape,W.shape)\n",
    "# for name, param in mod.named_parameters():\n",
    "#     if name == 'vec2neck.weight':\n",
    "#         W = param\n",
    "#         break\n",
    "# CL=loss_Contractive(W,vec1,vec2, out[1], 0.005)\n",
    "\n",
    "# CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31a86db2-b453-4c47-86b9-77ea21619679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    head=4 #trial.suggest_int(\"heads\",4,4)\n",
    "    #d_model=trial.suggest_int(\"d_model\",200,1200)\n",
    "    #neck=trial.suggest_int(\"neck\",700,700)\n",
    "    #p=0.237#trial.suggest_float(\"dropout\",0.2,0.4)\n",
    "    mod = TransformerAE(max_seq_len=20,\n",
    "                        N=head,\n",
    "                        heads=4,\n",
    "                        d_model=800,\n",
    "                        d_ff=800,\n",
    "                        neck=500,\n",
    "                        dropout=0.2\n",
    "                       )\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3901085-aa0a-415d-b9a0-a8f4f2d82488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off optuna log notes.\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(\n",
    "            \"Trial {} finished with best value: {} and parameters: {}. \".format(\n",
    "            frozen_trial.number,\n",
    "            frozen_trial.value,\n",
    "            frozen_trial.params,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f355ed7-d02d-45d1-abb7-4cf1b2273369",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from collections import deque\n",
    "from typing import Dict, Optional, Literal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "### Grokfast\n",
    "def gradfilter_ema(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    alpha: float = 0.99,\n",
    "    lamb: float = 5.0,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    if grads is None:\n",
    "        grads = {n: p.grad.data.detach() for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n] = grads[n] * alpha + p.grad.data.detach() * (1 - alpha)\n",
    "            p.grad.data = p.grad.data + grads[n] * lamb\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "### Grokfast-MA\n",
    "def gradfilter_ma(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, deque]] = None,\n",
    "    window_size: int = 128,\n",
    "    lamb: float = 5.0,\n",
    "    filter_type: Literal['mean', 'sum'] = 'mean',\n",
    "    warmup: bool = True,\n",
    "    trigger: bool = False,\n",
    ") -> Dict[str, deque]:\n",
    "    if grads is None:\n",
    "        grads = {n: deque(maxlen=window_size) for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n].append(p.grad.data.detach())\n",
    "\n",
    "            if not warmup or len(grads[n]) == window_size and not trigger:\n",
    "                if filter_type == \"mean\":\n",
    "                    avg = sum(grads[n]) / len(grads[n])\n",
    "                elif filter_type == \"sum\":\n",
    "                    avg = sum(grads[n])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unrecognized filter_type {filter_type}\")\n",
    "                p.grad.data = p.grad.data + avg * lamb\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
    "outputId": "02799af4-014c-4dab-ec46-33d719329174",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder droupout init 0.12\n",
      "encoder droupout init 0.12\n",
      "decoder droupout init 0.12\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "TransformerAE                                      --\n",
      "├─EncoderNeuronGroup: 1-1                          --\n",
      "│    └─EmbedderNeuronGroup: 2-1                    --\n",
      "│    │    └─Linear: 3-1                            17,476\n",
      "│    │    └─Linear: 3-2                            83,268\n",
      "│    └─PositionalEncoder: 2-2                      --\n",
      "│    └─ModuleList: 2-3                             --\n",
      "│    │    └─EncoderLayer: 3-3                      6,350,984\n",
      "│    │    └─EncoderLayer: 3-4                      6,350,984\n",
      "│    │    └─EncoderLayer: 3-5                      6,350,984\n",
      "│    │    └─EncoderLayer: 3-6                      6,350,984\n",
      "│    └─Norm: 2-4                                   2,056\n",
      "├─EncoderNeuronGroup: 1-2                          --\n",
      "│    └─EmbedderNeuronGroup: 2-5                    --\n",
      "│    │    └─Linear: 3-7                            17,476\n",
      "│    │    └─Linear: 3-8                            83,268\n",
      "│    └─PositionalEncoder: 2-6                      --\n",
      "│    └─ModuleList: 2-7                             --\n",
      "│    │    └─EncoderLayer: 3-9                      6,350,984\n",
      "│    │    └─EncoderLayer: 3-10                     6,350,984\n",
      "│    │    └─EncoderLayer: 3-11                     6,350,984\n",
      "│    │    └─EncoderLayer: 3-12                     6,350,984\n",
      "│    └─Norm: 2-8                                   2,056\n",
      "├─DecoderNeuronGroup: 1-3                          --\n",
      "│    └─Neck2Seq: 2-9                               --\n",
      "│    │    └─ModuleList: 3-13                       13,209,800\n",
      "│    └─PositionalEncoder: 2-10                     --\n",
      "│    └─ModuleList: 2-11                            --\n",
      "│    │    └─EncoderLayer: 3-14                     6,350,984\n",
      "│    │    └─EncoderLayer: 3-15                     6,350,984\n",
      "│    │    └─EncoderLayer: 3-16                     6,350,984\n",
      "│    │    └─EncoderLayer: 3-17                     6,350,984\n",
      "│    └─Norm: 2-12                                  2,056\n",
      "│    └─Seq2Vec: 2-13                               --\n",
      "│    │    └─Linear: 3-18                           126,652,064\n",
      "├─Linear: 1-4                                      526,592\n",
      "├─Tanh: 1-5                                        --\n",
      "===========================================================================\n",
      "Total params: 216,807,920\n",
      "Trainable params: 216,807,920\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 484.00 MiB (GPU 0; 11.76 GiB total capacity; 10.57 GiB already allocated; 176.38 MiB free; 10.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5543/1718917527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0moptimizerEnc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerENC2_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0moptimizerDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerDense_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0moptimizerDec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizerDec_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \"\"\"\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# deepcopy, to be consistent with module API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Validate the state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                        \"different type.\")\n\u001b[1;32m    109\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;31m# quantizer_params can be different type based on torch attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_wrapped_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sizeof__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/storage.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m\"\"\"Returns a copy of this storage\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 484.00 MiB (GPU 0; 11.76 GiB total capacity; 10.57 GiB already allocated; 176.38 MiB free; 10.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv \n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "import gc\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "track=0\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "#storage = JournalStorage(JournalFileStorage(\"optuna-journal DDP 3 Losses.log\"))\n",
    "\n",
    "#def objective(trial):\n",
    "global track , output , model\n",
    "grads=None\n",
    "accelerator = Accelerator()\n",
    "Loss=\"LWLN\" #trial.suggest_categorical(\"Loss function\",[\"MSE\"])#,\"LWLN\",\"Contractive\",])\n",
    "Lambda=0\n",
    "if Loss==\"MSE\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments/model MSE/\"\n",
    "if Loss==\"Contractive\":\n",
    "    results_path=\"./Contractive model/\"\n",
    "    Lambda=0 #trial.suggest_float(\"Contractive_Lambda\",0.00001,0.0001)\n",
    "if Loss==\"LWLN\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments//mixed model/\"\n",
    "\n",
    "cnn_acc_ID=[]\n",
    "cnn_acc_OOD=[]\n",
    "\n",
    "step_size=0\n",
    "factor=0\n",
    "threshhold=0\n",
    "threshold_mode = 0\n",
    "eps=0\n",
    "\n",
    "#alpha = trial.suggest_float(\"grokalpha\",0.0,1.0)\n",
    "#lamb = trial.suggest_int(\"groklamb\",1,15)\n",
    "mod= TransformerAE(max_seq_len=50,\n",
    "                        N=4,\n",
    "                        heads=4,\n",
    "                        d_model=1028,\n",
    "                        d_ff=1028,\n",
    "                        neck=256,\n",
    "                        dropout=0.12\n",
    "                       ) #define_model(trial)\n",
    "print(summary(mod))\n",
    "lrE1=0.15 #trial.suggest_float(\"Learning_rate\",0.0002,0.5)\n",
    "lrE2=0.15 \n",
    "lrL=0.15 \n",
    "lrD=0.085\n",
    "optimizerEnc1 = Adam(mod.parameters(), lr=lrE1,eps=1e-10,weight_decay=0.005)\n",
    "optimizerEnc2 = Adadelta(mod.parameters(), lr=lrE2,eps=1e-10,weight_decay=0.005)\n",
    "optimizerDense = SGD(mod.vec2neck.parameters(), lr=lrL,weight_decay=0.005)\n",
    "optimizerDec = Adadelta(mod.parameters(), lr=lrD,eps=1e-10,weight_decay=0.01)\n",
    "\n",
    "\n",
    "\n",
    "sched_name=\"CyclicLR\"#trial.suggest_categorical(\"scheduler\",[\"CyclicLR\"])#,\"ReduceLROnPlateau\"])\n",
    "if sched_name==\"CyclicLR\" :\n",
    "    step_size=24000#trial.suggest_int(\"step_size_up\",900,2800)\n",
    "    schedulerEnc1 = torch.optim.lr_scheduler.CyclicLR(optimizerEnc1, base_lr=1e-4, max_lr=lrE1, step_size_up=step_size, step_size_down=80000,scale_mode=\"iterations\",mode=\"triangular2\",cycle_momentum=False)\n",
    "    schedulerEnc2 = torch.optim.lr_scheduler.CyclicLR(optimizerEnc2, base_lr=1e-4, max_lr=lrE2, step_size_up=step_size, step_size_down=80000,scale_mode=\"iterations\",mode=\"triangular2\",cycle_momentum=False)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizerDense, base_lr=1e-4, max_lr=lrD, step_size_up=8000, step_size_down=8000,scale_mode=\"iterations\",mode=\"triangular\",cycle_momentum=False)\n",
    "    \n",
    "    \n",
    "# if sched_name==\"ReduceLROnPlateau\" :\n",
    "#     factor=trial.suggest_float(\"R-lr-OP_factor\",0.001,0.5)\n",
    "#     threshhold=trial.suggest_float(\"R-lr-OP_threshhold\",0.0001,0.001)\n",
    "#     threshold_mode = trial.suggest_categorical(\"thresh_mod\",[\"rel\",\"abs\"])\n",
    "#     eps=trial.suggest_float(\"R-lr-OP_eps\",1e-08,1e-05)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=5, threshold=threshhold, threshold_mode=threshold_mode, cooldown=2, min_lr=0, eps=eps)\n",
    "\n",
    "\n",
    "\n",
    "ch=torch.load(\"/media/crns/ADATA HD330/Experiments/mixed model/AE epoch 0 100.pth\")\n",
    "resume_epoch=ch[\"epoch\"]\n",
    "mod.load_state_dict(ch['model_state_dict'])\n",
    "optimizerEnc1.load_state_dict(ch['optimizerENC1_state_dict'])\n",
    "optimizerEnc2.load_state_dict(ch['optimizerENC2_state_dict'])\n",
    "optimizerDense.load_state_dict(ch['optimizerDense_state_dict'])\n",
    "optimizerDec.load_state_dict(ch['optimizerDec_state_dict'])\n",
    "\n",
    "del(ch)\n",
    "\n",
    "\n",
    "batch_size=80#trial.suggest_int(\"batch_size\",150)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "LW=LWLN_loss()\n",
    "\n",
    "num_epochs=151\n",
    "\n",
    "# #device = accelerator.device\n",
    "# run = wandb.init(\n",
    "# # Set the project where this run will be logged\n",
    "# project=\"aymen-project\",\n",
    "# name= f\"1(activation,age) data,new paperarch-{Loss}\" ,\n",
    "# # Track hyperparameters and run metadata\n",
    "# config={\n",
    "#     \"Loss\":Loss,\n",
    "#     \"lr Encoder 1\": lrE1,\n",
    "#     \"lr Encoder 2\": lrE2,\n",
    "#     \"lr Linear\": lrL,\n",
    "#     \"lr Decoder\": lrD,\n",
    "#     \"epochs\": num_epochs,\n",
    "#     \"sched_name\": sched_name,\n",
    "#     \"step_size\": step_size,\n",
    "#     \"batch_size\": batch_size,\n",
    "#     \"step_size\":step_size,\n",
    "#     \"Lambda_contractive\":Lambda\n",
    "# },)\n",
    "\n",
    "run = wandb.init(project=\"aymen-project\", id=\"05dpo9s9\", resume=\"must\")\n",
    "\n",
    "# \"factor\":factor,\n",
    "#     \"threshhold\":threshhold,\n",
    "#     \"threshold_mode\":threshold_mode,\n",
    "#     \"eps\":eps,\n",
    "cs_tr=CustomDataset(train_pair2,batch_size=batch_size)\n",
    "nb_batches = len(cs_tr)//batch_size\n",
    "\n",
    "cs_val=CustomDataset(val_pair2,batch_size=batch_size)\n",
    "nb_val_batches = len(cs_val)//batch_size\n",
    "\n",
    "#optimizer_to(optimizer,device)\n",
    "#scheduler_to(scheduler,device)\n",
    "\n",
    "mod, optimizerEnc1,optimizerEnc2,optimizerDense,optimizerDec, cs_tr= accelerator.prepare(mod, optimizerEnc1,optimizerEnc2,optimizerDense,optimizerDec,cs_tr)\n",
    "# wandb.watch(mod, log_freq=10000 ,criterion=criterion,\n",
    "#     log='parameters',\n",
    "#     log_graph=True)\n",
    "mod.train()\n",
    "for epoch in range(100,num_epochs):\n",
    "    #start_time_epoch = time.time()\n",
    "    for i in tqdm(range(nb_batches)):\n",
    "        #start_time_batch = time.time()\n",
    "        Dataset,EXP,ACC,U = cs_tr[i]\n",
    "        x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]\n",
    "        try:\n",
    "            if (Loss==\"Contractive\") and (i%50==0):\n",
    "                for name, param in mod.named_parameters():\n",
    "                    if name == 'vec2neck.weight':\n",
    "                        W = param\n",
    "                        break\n",
    "\n",
    "\n",
    "            x1=x1.cuda() #.to(torch.float32)\n",
    "            x2=x2.cuda() #.to(torch.float32)\n",
    "            tg=tg.cuda() #.to(torch.float32)\n",
    "\n",
    "            optimizerEnc1.zero_grad()\n",
    "            optimizerEnc2.zero_grad()\n",
    "            optimizerDense.zero_grad()\n",
    "            optimizerDec.zero_grad()\n",
    "\n",
    "            output = mod(x1,x2)\n",
    "            #print(output[2].shape ,output[3].shape,output[4].shape) \n",
    "            if Loss==\"MSE\":\n",
    "                loss_tr = criterion(output[0],tg)\n",
    "            if Loss==\"Contractive\":\n",
    "                CL=loss_Contractive(W,vec1,vec2, output[1], Lambda)\n",
    "                loss_tr = criterion(output[0],tg)+CL\n",
    "            if Loss==\"LWLN\":\n",
    "                loss_tr = criterion(output[0],tg)+LW(vec1,vec2)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print the exception\n",
    "            print(\"An exception occurred:\", e)\n",
    "            traceback.print_exc()\n",
    "            # Continue with the loop\n",
    "            continue\n",
    "\n",
    "\n",
    "        accelerator.backward(loss_tr)\n",
    "        #grads = gradfilter_ema(mod, grads=grads, alpha=alpha, lamb=lamb)\n",
    "        optimizerEnc1.step()\n",
    "        optimizerEnc2.step()\n",
    "        optimizerDense.step()\n",
    "        optimizerDec.step()\n",
    "        if sched_name==\"ReduceLROnPlateau\" :\n",
    "            scheduler.step(loss_tr)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            schedulerEnc1.step()\n",
    "            schedulerEnc2.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_to_save = float(loss_tr.detach().cpu().item())\n",
    "\n",
    "            #(nb_batches/2),\n",
    "        if (i in [nb_batches-1] and (epoch%5==0)) or (i==0 and epoch==0):\n",
    "            for block in [2,3,4]:\n",
    "                for head in range(4):\n",
    "                    plt.figure(figsize=(20, 20))\n",
    "                    hm=sns.heatmap(torch.mean( torch.mean(output[block][head], dim=1), dim=0).detach().cpu(), annot=False, cmap='cubehelix')\n",
    "                    plt.title('Attention Heatmap')\n",
    "                    heatmap_path = f'heatmap {block-2}_{head}_step_{i}.png'\n",
    "                    #plt.savefig(results_path+\"Attention/\"+heatmap_path)#,format='svg', dpi=800)\n",
    "                    wandb.log({f\"attention_heatmap {block-2}_{head}\":  wandb.Image(hm,caption=f\"attention_heatmap attention_heatmap {block-2}_{head}\")})\n",
    "                    plt.close()\n",
    "            mod.eval()\n",
    "            loss_val = []\n",
    "            for i_val in range(nb_val_batches):\n",
    "                #start_time_batch = time.time()\n",
    "                Dataset_val,EXP_val,ACC_val,U_val = cs_val[i_val]\n",
    "                x1_val,x2_val,tg_val = Dataset_val[:,0,:], Dataset_val[:,1,:],Dataset_val[:,2,:]\n",
    "                x1_val=x1_val.cuda() #.to(torch.float32)\n",
    "                x2_val=x2_val.cuda() #.to(torch.float32)\n",
    "                tg_val=tg_val.cuda() #.to(torch.float32)\n",
    "                with torch.no_grad():\n",
    "                    #output_val = mod(x1_val,x2_val)\n",
    "                    loss_val.append(criterion(mod(x1_val,x2_val)[0],tg_val))\n",
    "            loss_val = sum(loss_val)/len(loss_val)\n",
    "            wandb.log({f\"val_loss\":loss_val})\n",
    "            cnn_acc_ID=[]\n",
    "            cnn_acc_OOD=[]\n",
    "            #print(f\"Validating ... {loss_val}\")\n",
    "            for vect in [0,10,40,50,70]:\n",
    "                y_pred=torch.unsqueeze(output[0][vect], 0) \n",
    "                y =torch.unsqueeze(tg[vect], 0) \n",
    "\n",
    "                selected_row = cs_tr.df.iloc[int(U[vect][0]), 11:17]  \n",
    "                columns_with_one = selected_row[selected_row == 1].index.tolist()\n",
    "                activ=columns_with_one\n",
    "                epochCNN=cs_tr.df.loc[int(U[vect][0])]['epoch']\n",
    "\n",
    "\n",
    "                checkpoint=OrderedDict()\n",
    "                vector_aux= output[0][vect].detach()\n",
    "                y_pred=vector_aux.cpu()\n",
    "\n",
    "                task1=[int(x) for x in EXP[vect][0]]\n",
    "                task2=[int(x) for x in EXP[vect][1]]\n",
    "                task3=sorted(task1+task2)\n",
    "\n",
    "\n",
    "                All=list(range(10))\n",
    "                L2=[k for k in All if k not in task3] # Out of distribution classes\n",
    "                L_others=[k for k in All if k not in task3] #Classes to test on (In distribution)\n",
    "\n",
    "                checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(y_pred[0:200]).reshape([8, 1, 5, 5]))\n",
    "                checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(y_pred[200:208]).reshape([8]))\n",
    "\n",
    "                checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(y_pred[208:1408]).reshape([6, 8, 5, 5]))\n",
    "                checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(y_pred[1408:1414]).reshape([6]))\n",
    "\n",
    "                checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(y_pred[1414:1510]).reshape([4, 6, 2, 2]))\n",
    "                checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(y_pred[1510:1514]).reshape([4]))\n",
    "\n",
    "                checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(y_pred[1514:2234]).reshape([20,36]))\n",
    "                checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(y_pred[2234:2254]).reshape([20]))\n",
    "\n",
    "                checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(y_pred[2254:2454]).reshape([10,20]))\n",
    "                checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(y_pred[2454:2464]).reshape([10]))\n",
    "\n",
    "                Brain = CNN(1,activ[0],0,\"kaiming_uniform\")\n",
    "\n",
    "                model=copy.deepcopy(Brain)\n",
    "                model.load_state_dict(checkpoint)\n",
    "\n",
    "                criterion_CNN0=CrossEntropyLoss()\n",
    "\n",
    "                test_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Ts_DL0 = DataLoader(dataset=test_IF0, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "                _, valid_epoch_acc0,_= validate(model, Ts_DL0,  criterion_CNN0,10)\n",
    "                if len(task3)==10:\n",
    "                    valid_epoch_acc1=valid_epoch_acc0\n",
    "                    continue\n",
    "                else:\n",
    "                    criterion_CNN1=CrossEntropyLoss()\n",
    "                    test_IF1=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in task3],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                    Ts_DL1 = DataLoader(dataset=test_IF1, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "                valid_epoch_loss0, valid_epoch_acc1,L_mx= validate(model, Ts_DL1,  criterion_CNN1,10)\n",
    "                cnn_acc_ID.append(valid_epoch_acc0)\n",
    "                cnn_acc_OOD.append(valid_epoch_acc1)\n",
    "                #lr = optimizer.param_groups[0][\"lr\"]\n",
    "                lrE1=optimizerEnc1.param_groups[0][\"lr\"]\n",
    "                lrE2=optimizerEnc2.param_groups[0][\"lr\"]\n",
    "                lrL=optimizerDense.param_groups[0][\"lr\"]\n",
    "                lrD=optimizerDec.param_groups[0][\"lr\"]\n",
    "                \n",
    "                \n",
    "                \n",
    "            #print(f\"Reconstructing ... {valid_epoch_acc0}\")\n",
    "                optimizerCNN = Adam(model.parameters(), lr=0.05)\n",
    "                schedulerCNN = torch.optim.lr_scheduler.CyclicLR(optimizerCNN ,base_lr=1e-3, max_lr=0.1, step_size_up=400, mode=\"triangular2\", cycle_momentum=False)\n",
    "                criterion_CNN=CrossEntropyLoss()\n",
    "                \n",
    "                \n",
    "                train_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/train/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Tr_DLr = DataLoader(dataset=train_IF0, batch_size=100, num_workers=0, shuffle=True)\n",
    "                \n",
    "                \n",
    "                wandb.define_metric(f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_loss train {task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_acc train{task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                \n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_loss test {task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_acc test{task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                fine_tune_needed=0\n",
    "                #print(task1,task2,task3)\n",
    "                for epoch_cnn in range(15):\n",
    "                    \n",
    "                    # for param in model.parameters():\n",
    "                    #     print(f\"Param before step: {param.data[0]}\")\n",
    "                    #     break\n",
    "                    train_epoch_loss, train_epoch_acc,_ = train(model, Tr_DLr, optimizerCNN, criterion_CNN,10)\n",
    "                    valid_epoch_loss0FN, valid_epoch_acc0FN,_= validate(model, Ts_DL0,  criterion_CNN,10)\n",
    "                    schedulerCNN.step()\n",
    "                    # for param in model.parameters():\n",
    "                    #     print(f\"Param after step: {param.data[0]}\")\n",
    "                    #     break\n",
    "                    fine_tune_needed+=1\n",
    "                    #if fine_tune_needed%5==0:\n",
    "                        #print(f\"Accuracy of {train_epoch_acc:.2f} / ACC[vect][2] after {fine_tune_needed} epochs\")\n",
    "                    wandb.log({f\"[{epoch}]CNN_fn_loss train {task1}{task2}{task3}\":train_epoch_loss,f\"[{epoch}]CNN_fn_acc train {task1}{task2}{task3}\":train_epoch_acc , f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    wandb.log({f\"[{epoch}]CNN_fn_loss test {task1}{task2}{task3}\":valid_epoch_loss0FN,f\"[{epoch}]CNN_fn_acc test {task1}{task2}{task3}\":valid_epoch_acc0FN , f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    \n",
    "                          \n",
    "                    wandb.log({f\"[{epoch}]finetune ratio {task1}{task2}{task3}\":valid_epoch_acc0FN/ACC[vect][2], f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    wandb.log({f\"combined target accuracy {task1}{task2}{task3}\":ACC[vect][2], f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                # define our custom x axis metric\n",
    "\n",
    "            \n",
    "        wandb.log({\"Loss\":loss_to_save})\n",
    "        wandb.log({\"CNN_IID_no_fine_tune\":(np.mean(cnn_acc_ID))})\n",
    "        wandb.log({\"CNN_OOD_no_fine_tune\":(np.mean(cnn_acc_OOD))})\n",
    "        wandb.log({\"lr Encoder 1\": lrE1,\"lr Encoder 2\": lrE2,\"lr Linear\": lrL,\"lr Decoder\": lrD})\n",
    "    if epoch%20==0 or epoch in [5,10]:\n",
    "        torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),\n",
    "                    'optimizerENC1_state_dict':  optimizerEnc1.state_dict() ,\n",
    "                    'optimizerENC2_state_dict':optimizerEnc2.state_dict(),\n",
    "                    'optimizerDense_state_dict':optimizerDense.state_dict(),\n",
    "                    'optimizerDec_state_dict': optimizerDec.state_dict(),\n",
    "                    'Batch Loss':loss_tr.detach().cpu().item()},\n",
    "                   results_path+'AE epoch {} {}.pth'.format(track,epoch))\n",
    "wandb.finish()\n",
    "track=+1\n",
    "#     return loss_tr\n",
    "# study= optuna.create_study(direction=\"minimize\",storage=storage)\n",
    "# study.optimize(objective,n_trials=2,callbacks=[lambda study, trial: gc.collect()]+[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d0df8-f15c-41c9-8fbb-fdc74274c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),\n",
    "                    'optimizerENC1_state_dict':  optimizerEnc1.state_dict() ,\n",
    "                    'optimizerENC2_state_dict':optimizerEnc2.state_dict(),\n",
    "                    'optimizerDense_state_dict':optimizerDense.state_dict(),\n",
    "                    'optimizerDec_state_dict': optimizerDec.state_dict(),\n",
    "                    'Batch Loss':loss_tr.detach().cpu().item()},\n",
    "                   results_path+'AE epoch {} {}.pth'.format(track,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddb1dd-7ba0-4d3a-b94a-132b7c9ac4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d678-66e0-4fdc-b4b3-11f1c42fca65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f9ea2-757f-4c08-a838-968f9b27d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "hm=sns.heatmap(torch.mean( torch.mean(output[4][-1], dim=1), dim=0).detach().cpu(), annot=False, cmap='cubehelix')\n",
    "plt.title('Attention Heatmap')\n",
    "\n",
    "heatmap_path = f'heatmap 1 _step_{0}.svg'\n",
    "plt.savefig(heatmap_path,format='svg', dpi=800)\n",
    "plt.close()\n",
    "\n",
    "#wandb.log({\"attention_heatmap 1\": wandb.Image(heatmap_path)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2949b-41d1-4cb9-90e5-ec389c2e6e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38362539-dd58-4e3c-925e-f313b21e4819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54092b-8cfd-4691-a8f9-caa1b00eb39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7993d-f994-485c-9169-827e94211812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbfa86-331e-4c39-92f4-e35133be58bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699aba2-6928-4425-b344-ad810f9fc144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4966281-ab38-4bac-aaef-98d1ff59e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df29ecd-9235-45f4-951a-ecfe9cc1a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616cff7-b29e-4984-9dc5-f8b13aec2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73672723-0e7f-42b2-8c86-1dad689519f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa23f52-93fa-410f-918e-d9da64b9145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/memory-management-using-pytorch-cuda-alloc-conf/157850\n",
    "#https://stackoverflow.com/questions/73747731/runtimeerror-cuda-out-of-memory-how-can-i-set-max-split-size-mb\n",
    "\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
