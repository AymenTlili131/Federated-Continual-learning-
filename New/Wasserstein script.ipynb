{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c",
   "metadata": {
    "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "import random\n",
    "import ast\n",
    "        \n",
    "\n",
    "import torch.nn.functional as F\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from torch.optim import Adam ,SGD ,Adadelta\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation ,FFMpegWriter ,PillowWriter\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os \n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c973ef-a1c2-4c67-88f5-5c2cdc634f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceed1bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maymentlili\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/crns/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"ab631efc36e2c87f5f54d82b5cdbd6c501d5221f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecd06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c395ca-191a-49f4-b45c-e87ecd231e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
    "outputId": "9229fdc7-630d-4e87-d54b-3771391ef44c"
   },
   "outputs": [],
   "source": [
    "seed=74\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a1e1f6-dcf6-4c01-b2c3-ab25ee771a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Double_input_transformer import CustomDataset,TransformerAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655000ba-32ed-41d3-93a3-522336521239",
   "metadata": {
    "id": "655000ba-32ed-41d3-93a3-522336521239"
   },
   "source": [
    "# Trainloader code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2e5630-1312-47db-b6b1-1646cb9eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the list\n",
    "train_pair2 = np.load('train_pair++.npy', allow_pickle=True)\n",
    "test_pair2 = np.load('test_pair++.npy', allow_pickle=True)\n",
    "val_pair2 = np.load('val_pair++.npy', allow_pickle=True)\n",
    "train_pair2 = [ list(x) for x in train_pair2]\n",
    "test_pair2 = [ list(x) for x in test_pair2]\n",
    "val_pair2 = [ list(x) for x in val_pair2]\n",
    "random.shuffle(train_pair2)\n",
    "random.shuffle(test_pair2)\n",
    "random.shuffle(val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96f0b1d-6532-48da-9cfb-44a1fe16465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10]]\n"
     ]
    }
   ],
   "source": [
    "def batchify(lst, batch_size):\n",
    "    return [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]\n",
    "\n",
    "# Example usage:\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "batch_size = 4\n",
    "batches = batchify(my_list, batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e37e4a-a947-407d-9700-352fec773e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15822, 3743, 3871)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pair2),len(test_pair2),len(val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f58a0b2-cde4-4e58-9f7a-61c3576e245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All = list(train_pair2)+list(test_pair2)+list(val_pair2)\n",
    "All = [ list(x) for x in All]\n",
    "All.sort(reverse=True)\n",
    "len(All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83dd4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_pair2=[]\n",
    "# test_pair2=[]\n",
    "# val_pair2=[]\n",
    "# for i,L1 in tqdm(enumerate(All)) :\n",
    "#     matches=[]\n",
    "#     for L2 in All :\n",
    "#         if L2[2]==4 and L2[3]==0 and L1[2]==4 and L1[3]==0 and L1[0]==L2[0] and L2 not in matches and L2 not in train_pair2 and L2 not in test_pair2  and L2 not in val_pair2 :\n",
    "#             matches.append(L2)\n",
    "#     train_pair2.extend(matches[:int(len(matches)*0.7)])\n",
    "#     test_pair2.extend(matches[int(len(matches)*0.7):int(len(matches)*0.85)])\n",
    "#     val_pair2.extend(matches[int(len(matches)*0.85):])\n",
    "#     if L1[0]==[0,1,2,3,4,5,6,7] :\n",
    "#         print(len(matches))\n",
    "# print(len(train_pair2))\n",
    "# print(len(test_pair2))\n",
    "# print(len(val_pair2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c882cca-06d4-42a3-ab31-3cfed2e7d410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs_tr=CustomDataset(train_pair,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c1f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset,EXP,ACC,U = cs_tr[0]\n",
    "#x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4e714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 6, 7, 9], [2, 5, 8], 4, 0], [[0, 4, 5, 6, 7, 8], [1, 9], 4, 0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x1.shape\n",
    "random.shuffle(train_pair2)\n",
    "train_pair2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0930913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All = list(train_pair)+list(test_pair)+list(val_pair)\n",
    "# All = [ list(x) for x in All]\n",
    "# train_pair=[]\n",
    "# test_pair=[]\n",
    "# val_pair=[]\n",
    "# for L1 in tqdm(All) :\n",
    "#     matches=[]\n",
    "#     for L2 in All :\n",
    "#         if L1[0]==L2[0] and L2 not in matches and L2[2]==4 and L2[3]==0 :\n",
    "#             matches.append(L2)\n",
    "#     train_pair.extend(matches[:int(len(matches)*0.7)])\n",
    "#     test_pair.extend(matches[int(len(matches)*0.7):int(len(matches)*0.85)])\n",
    "#     val_pair.extend(matches[int(len(matches)*0.85):])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8df0e3-2ced-4468-a5aa-75d9102b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pair=test_pair[int(len(test_pair)/2):]\n",
    "# test_pair=test_pair[:int(len(test_pair)/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86052495-ee40-454c-a374-25172cfa6083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a0a5b4-7b2e-4abb-b007-6b4cf79c7a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1, 3], [2, 4, 5, 7], 4, 0], 15822)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pair2[0] ,len(train_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7adeaf93-b728-4094-9c5c-1ace4bd7f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"train_pair++\", train_pair2)\n",
    "# np.save(\"test_pair++\", test_pair2)\n",
    "# np.save(\"val_pair++\", val_pair2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0baa11-e37f-4903-8215-2b7c0e0b8ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2",
   "metadata": {
    "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "387b2953-3794-42d9-a327-5e7cca27939d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387b2953-3794-42d9-a327-5e7cca27939d",
    "outputId": "29fef800-a2d7-43d4-dafb-9fa69bda52ca"
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b",
   "metadata": {
    "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30",
   "metadata": {
    "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72",
   "metadata": {
    "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a",
   "metadata": {
    "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a"
   },
   "outputs": [],
   "source": [
    "class EmbedderNeuronGroup(nn.Module):\n",
    "    def __init__(self, d_model, seed=22):\n",
    "        super().__init__()\n",
    "        #print(\"EmbedderNeuroneGroup\")\n",
    "        self.neuron_l1 = nn.Linear(200, d_model) #8\n",
    "        self.neuron_l2 = nn.Linear(72, d_model) #12\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.multiLinear(x)\n",
    "\n",
    "    def multiLinear(self, v):\n",
    "        #print(\"multi-linear method\",v.shape)\n",
    "\n",
    "        l = []\n",
    "\n",
    "        for ndx in range(8):\n",
    "            idx_start = ndx * 200\n",
    "            idx_end = idx_start + 200\n",
    "            l.append(self.neuron_l1(v[:,idx_start:idx_end]))\n",
    "\n",
    "        # l2\n",
    "        for ndx in range(12):\n",
    "            idx_start = 200*8 + ndx * 72\n",
    "            idx_end = idx_start + 72\n",
    "            l.append(self.neuron_l2(v[:,idx_start:idx_end]))\n",
    "        #print(len(l))\n",
    "        #print(len(l[0]))\n",
    "        final = torch.stack(l, dim=1)\n",
    "\n",
    "        # print(final.shape)\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2",
   "metadata": {
    "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f",
   "metadata": {
    "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f"
   },
   "outputs": [],
   "source": [
    "# max_seq_len=176,\n",
    "# N=4\n",
    "# heads=3\n",
    "# d_model=900\n",
    "# d_ff=900\n",
    "# neck=700\n",
    "# dropout=0.1\n",
    "# # Enc=EncoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff)\n",
    "# # vec1 = torch.rand(1,2464)\n",
    "# # res,scores=Enc(vec1)\n",
    "# # res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad",
   "metadata": {
    "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278",
   "metadata": {
    "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278"
   },
   "outputs": [],
   "source": [
    "# vec2neck = nn.Linear(d_ff*2, neck)\n",
    "# print(res.shape)\n",
    "# out3=torch.cat([res,res], dim=2)\n",
    "# print(\"neck input:\",out3.shape)\n",
    "# sum_r=torch.sum(out3, dim=1, keepdim=False)\n",
    "# vec2=vec2neck(sum_r)\n",
    "# print(len(vec2))\n",
    "# tanh = nn.Tanh()\n",
    "# neck_t=tanh(vec2)\n",
    "# print(\"neck shape:\",neck_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac",
   "metadata": {
    "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4",
   "metadata": {
    "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa74a80-dee8-4710-a221-a448b37758d1",
   "metadata": {
    "id": "efa74a80-dee8-4710-a221-a448b37758d1"
   },
   "outputs": [],
   "source": [
    "# Dec=DecoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff,neck=neck)\n",
    "# res,scores=Dec(neck_t)\n",
    "# res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf",
   "metadata": {
    "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5",
   "metadata": {
    "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d",
   "metadata": {
    "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65",
   "metadata": {
    "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
    "outputId": "7301efd4-e73d-46ce-baa8-b3b12a63c900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3743, 15822, 3871)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pair2),len(train_pair2),len(val_pair2)#,len(test_tgt),len(train_tgt),len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649",
   "metadata": {
    "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649"
   },
   "outputs": [],
   "source": [
    "#test_pair=[ x for x in test_pair  if (0 in x[0]) and (1 in x[0]) and (2 in x[0] or 2 in x[1] ) and (3 in[0] or 2 in x[1]) and (4 in[0] or 2 in x[1] ) ]\n",
    "#len(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "619486cb-4a43-408f-976c-74c7d6a840d9",
   "metadata": {
    "id": "619486cb-4a43-408f-976c-74c7d6a840d9"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "class ClassSpecificImageFolder(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dropped_classes=[],\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        self.dropped_classes = dropped_classes\n",
    "        super(ClassSpecificImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                                       transform=transform,\n",
    "                                                       target_transform=target_transform,\n",
    "                                                       is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        classes = [c for c in classes if c not in self.dropped_classes]\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
    "outputId": "9429472d-98a4-47db-c47e-af78aadfba49"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(mod.numParams())\n",
    "# x1 = torch.rand(1,2464)\n",
    "# x2 = torch.rand(1,2464)\n",
    "# mod=mod.to(device).to(torch.float32)\n",
    "\n",
    "# #x1=x1.to(torch.float32)\n",
    "# #x2=x2.to(torch.float32)\n",
    "# x1=x1.to(device)\n",
    "# x2=x2.to(device)\n",
    "# mod=mod.to(device)\n",
    "# out = mod(x1,x2)\n",
    "# print(\"Output Shape: \", out[0].shape)\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "# summary(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e0eefd-9bb1-4f3e-b722-78f4108efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.0,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init module list\n",
    "        self.module_list = nn.ModuleList()\n",
    "        ### ASSUMES 28x28 image size\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(nn.Conv2d(channels_in, 8, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(nn.Conv2d(8, 6, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(nn.Conv2d(6, 4, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                # set bias to some small non-zero value\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "                or isinstance(layer, ORU)\n",
    "                or isinstance(layer, ERU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "def train(model, trainloader, optimizer, criterion,nb_classes,First=False,df=None):\n",
    "    List_mx=[]\n",
    "    model.train()\n",
    "    #print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "        #List_mx.append(mx)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "        if First==True and i%25==0 :\n",
    "            epoch_loss = train_running_loss / counter\n",
    "            epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "            #print(f\"step {i}:\",epoch_loss, epoch_acc)\n",
    "            df.at[track,f\"Step {i}\"]=epoch_acc\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            if data is None:  # Skip None values\n",
    "                continue\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image\n",
    "            labels = labels\n",
    "            # forward pass\n",
    "            outputs = model(image.to(torch.float32))\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "            #List_mx.append(mx)\n",
    "            \n",
    "            \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "def create_frame(step,ax,data):\n",
    "    ax=ax.cla()\n",
    "    sns.heatmap(data[step][-1].cpu(),annot=True,cmap=\"cubehelix\",ax=ax,cbar=False)\n",
    "    plt.title('Epoch {} training {}'.format(step,exp)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c",
   "metadata": {
    "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c"
   },
   "outputs": [],
   "source": [
    "#L_activations=[\"gelu\",\"relu\",\"silu\",\"leakyrelu\",\"sigmoid\",\"tanh\"]\n",
    "#csv_files,L_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c657276f-7578-45a1-a58b-db8a21914d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4551)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2) in https://arxiv.org/pdf/2209.14733.pdf\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "class LWLN_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWLN_loss, self).__init__()\n",
    "    def forward(self, vec1,vec2):\n",
    "        loss = (torch.mean((vec1[:,0:208]-vec2[:,0:208])**2)/vec2[:,0:208].std() + \n",
    "                 torch.mean((vec1[:,208:1414]-vec2[:,208:1414])**2)/vec2[:,208:1414].std()+ \n",
    "                 torch.mean((vec1[:,1414:1514]-vec2[:,1414:1514])**2)/vec2[:,1414:1514].std()+\n",
    "                 torch.mean((vec1[:,1514:2254]-vec2[:,1514:2254])**2)/vec2[:,1514:2254].std()+\n",
    "                 torch.mean((vec1[:,2254:2464]-vec2[:,2254:2464])**2)/vec2[:,2254:2464].std())/(6)\n",
    "        \n",
    "        return loss\n",
    "LW=LWLN_loss()\n",
    "LW(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48684b12-575d-4354-84ed-04ce490df41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label task 1</th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy task1</th>\n",
       "      <th>label task 2</th>\n",
       "      <th>Accuracy task2</th>\n",
       "      <th>weight 0</th>\n",
       "      <th>weight 1</th>\n",
       "      <th>weight 2</th>\n",
       "      <th>weight 3</th>\n",
       "      <th>weight 4</th>\n",
       "      <th>...</th>\n",
       "      <th>bias 2462</th>\n",
       "      <th>bias 2463</th>\n",
       "      <th>Loader Set</th>\n",
       "      <th>Reconstructed Accuracy ID</th>\n",
       "      <th>Actual Accuracy</th>\n",
       "      <th>Reconstructed Accuracy OOD</th>\n",
       "      <th>Transformer Loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochCNN</th>\n",
       "      <th>ActivationCNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label task 1, index, Accuracy task1, label task 2, Accuracy task2, weight 0, weight 1, weight 2, weight 3, weight 4, weight 5, weight 6, weight 7, weight 8, weight 9, weight 10, weight 11, weight 12, weight 13, weight 14, weight 15, weight 16, weight 17, weight 18, weight 19, weight 20, weight 21, weight 22, weight 23, weight 24, weight 25, weight 26, weight 27, weight 28, weight 29, weight 30, weight 31, weight 32, weight 33, weight 34, weight 35, weight 36, weight 37, weight 38, weight 39, weight 40, weight 41, weight 42, weight 43, weight 44, weight 45, weight 46, weight 47, weight 48, weight 49, weight 50, weight 51, weight 52, weight 53, weight 54, weight 55, weight 56, weight 57, weight 58, weight 59, weight 60, weight 61, weight 62, weight 63, weight 64, weight 65, weight 66, weight 67, weight 68, weight 69, weight 70, weight 71, weight 72, weight 73, weight 74, weight 75, weight 76, weight 77, weight 78, weight 79, weight 80, weight 81, weight 82, weight 83, weight 84, weight 85, weight 86, weight 87, weight 88, weight 89, weight 90, weight 91, weight 92, weight 93, weight 94, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2477 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cols=[\"label task 1\",\"index\",\"Accuracy task1\",\\\n",
    "      \"label task 2\",\"Accuracy task2\"]+ \\\n",
    "[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Loader Set\",\"Reconstructed Accuracy ID\",\"Actual Accuracy\",\"Reconstructed Accuracy OOD\",\"Transformer Loss\",\"lr\",'epochCNN','ActivationCNN'] \n",
    "\n",
    "print(len(Cols))\n",
    "predicted_Weights= pd.DataFrame(columns=Cols)\n",
    "\n",
    "# row=[\"\".format(task1),int(ind[0]),ACC[0],\"\".format(task2),ACC[1]]+vector_aux.to_list()+[\"train\",valid_epoch_acc0,ACC[2],valid_epoch_acc1,L_train[-1]]\n",
    "# predicted_Weights.append(row, ignore_index=True)\n",
    "predicted_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec127-29d7-4d8a-b935-5d0f1dbcb2e5",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcd60539-fb7e-4145-a4cb-8183f9f31f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)\n",
    "def scheduler_to(sched, device):\n",
    "    for param in sched.__dict__.values():\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e960c79-58b9-4f1d-93df-cbccebb9a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-06 13:23:10.526144\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb7763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def loss_Contractive(W, x, recons_x, h, lam):\n",
    "    dh = h * (1 - h) \n",
    "\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    " \n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "\n",
    "    return contractive_loss.mul_(lam)\n",
    "\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "#print(out[1].shape,W.shape)\n",
    "# for name, param in mod.named_parameters():\n",
    "#     if name == 'vec2neck.weight':\n",
    "#         W = param\n",
    "#         break\n",
    "# CL=loss_Contractive(W,vec1,vec2, out[1], 0.005)\n",
    "\n",
    "# CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "538a483f-172d-42bc-b98d-d1abb8811164",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = torch.rand(5,2464)\n",
    "vec2 = torch.rand(5,2464)\n",
    "from scipy.stats import wasserstein_distance\n",
    "# Convert to numpy arrays\n",
    "vec1_np = vec1.numpy()\n",
    "vec2_np = vec2.numpy()\n",
    "\n",
    "# Compute Wasserstein distance for each pair of vectors\n",
    "wsd_list = [wasserstein_distance(vec1_np[i], vec2_np[i]) for i in range(vec1_np.shape[0])]\n",
    "\n",
    "# If you need an aggregate measure, you can compute the average distance\n",
    "average_wsd = sum(wsd_list) / len(wsd_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31a86db2-b453-4c47-86b9-77ea21619679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(model, inputs):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Set requires_grad to True for input tensor\n",
    "    inputs = inputs.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass to get the output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Compute the Jacobian\n",
    "    jacobian = []\n",
    "    for i in range(outputs.shape[1]):\n",
    "        grad_outputs = torch.zeros_like(outputs)\n",
    "        grad_outputs[:, i] = 1\n",
    "        jac_i = autograd.grad(outputs, inputs, grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "        jacobian.append(jac_i)\n",
    "\n",
    "    jacobian = torch.stack(jacobian, dim=1)\n",
    "    return jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc6c4dc1-f297-4e42-af78-026fc8909ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm_loss(model, inputs):\n",
    "    jacobian = compute_jacobian(model, inputs)\n",
    "    frobenius_norm = torch.norm(jacobian, p='fro')\n",
    "    return frobenius_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f31b9-6e21-4477-9c26-4f0feb5b3c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6599bc9-e8cc-45b7-b881-180256365842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb885f80-b009-40b2-82dc-e2160b880167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f63ab-947a-465e-8854-72f8a7a8b7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3901085-aa0a-415d-b9a0-a8f4f2d82488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off optuna log notes.\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(\n",
    "            \"Trial {} finished with best value: {} and parameters: {}. \".format(\n",
    "            frozen_trial.number,\n",
    "            frozen_trial.value,\n",
    "            frozen_trial.params,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f355ed7-d02d-45d1-abb7-4cf1b2273369",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from collections import deque\n",
    "from typing import Dict, Optional, Literal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "### Grokfast\n",
    "def gradfilter_ema(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    alpha: float = 0.99,\n",
    "    lamb: float = 5.0,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    if grads is None:\n",
    "        grads = {n: p.grad.data.detach() for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n] = grads[n] * alpha + p.grad.data.detach() * (1 - alpha)\n",
    "            p.grad.data = p.grad.data + grads[n] * lamb\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "### Grokfast-MA\n",
    "def gradfilter_ma(\n",
    "    m: nn.Module,\n",
    "    grads: Optional[Dict[str, deque]] = None,\n",
    "    window_size: int = 128,\n",
    "    lamb: float = 5.0,\n",
    "    filter_type: Literal['mean', 'sum'] = 'mean',\n",
    "    warmup: bool = True,\n",
    "    trigger: bool = False,\n",
    ") -> Dict[str, deque]:\n",
    "    if grads is None:\n",
    "        grads = {n: deque(maxlen=window_size) for n, p in m.named_parameters() if p.requires_grad}\n",
    "\n",
    "    for n, p in m.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            grads[n].append(p.grad.data.detach())\n",
    "\n",
    "            if not warmup or len(grads[n]) == window_size and not trigger:\n",
    "                if filter_type == \"mean\":\n",
    "                    avg = sum(grads[n]) / len(grads[n])\n",
    "                elif filter_type == \"sum\":\n",
    "                    avg = sum(grads[n])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unrecognized filter_type {filter_type}\")\n",
    "                p.grad.data = p.grad.data + avg * lamb\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5fb637-3239-431d-bffa-3d739edfa27f",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
    "outputId": "02799af4-014c-4dab-ec46-33d719329174",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder droupout init 0.12\n",
      "encoder droupout init 0.12\n",
      "decoder droupout init 0.12\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "TransformerAE                                      --\n",
      "├─EncoderNeuronGroup: 1-1                          --\n",
      "│    └─EmbedderNeuronGroup: 2-1                    --\n",
      "│    │    └─Linear: 3-1                            15,980\n",
      "│    │    └─Linear: 3-2                            76,140\n",
      "│    └─PositionalEncoder: 2-2                      --\n",
      "│    └─ModuleList: 2-3                             --\n",
      "│    │    └─EncoderLayer: 3-3                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-4                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-5                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-6                      5,311,000\n",
      "│    └─Norm: 2-4                                   1,880\n",
      "├─EncoderNeuronGroup: 1-2                          --\n",
      "│    └─EmbedderNeuronGroup: 2-5                    --\n",
      "│    │    └─Linear: 3-7                            15,980\n",
      "│    │    └─Linear: 3-8                            76,140\n",
      "│    └─PositionalEncoder: 2-6                      --\n",
      "│    └─ModuleList: 2-7                             --\n",
      "│    │    └─EncoderLayer: 3-9                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-10                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-11                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-12                     5,311,000\n",
      "│    └─Norm: 2-8                                   1,880\n",
      "├─DecoderNeuronGroup: 1-3                          --\n",
      "│    └─Neck2Seq: 2-9                               --\n",
      "│    │    └─ModuleList: 3-13                       12,079,000\n",
      "│    └─PositionalEncoder: 2-10                     --\n",
      "│    └─ModuleList: 2-11                            --\n",
      "│    │    └─EncoderLayer: 3-14                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-15                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-16                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-17                     5,311,000\n",
      "│    └─Norm: 2-12                                  1,880\n",
      "│    └─Seq2Vec: 2-13                               --\n",
      "│    │    └─Linear: 3-18                           115,810,464\n",
      "├─Linear: 1-4                                      481,536\n",
      "├─Tanh: 1-5                                        --\n",
      "===========================================================================\n",
      "Total params: 192,292,880\n",
      "Trainable params: 192,292,880\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "Problem at: /tmp/ipykernel_664926/2455366188.py 108 <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_664926/2455366188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m run = wandb.init(\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;31m# Set the project where this run will be logged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aymen-project\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mrun_start_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeliver_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;31m# TODO: add progress to let user know we are doing something\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0mrun_start_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_start_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_start_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mrun_start_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabandon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mMailboxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transport failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabandoned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# Always update progress to 100% when done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv \n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "import gc\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "track=0\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "#storage = JournalStorage(JournalFileStorage(\"optuna-journal DDP 3 Losses.log\"))\n",
    "\n",
    "#def objective(trial):\n",
    "global track , output , model\n",
    "grads=None\n",
    "accelerator = Accelerator()\n",
    "Loss=\"LWLN\" #trial.suggest_categorical(\"Loss function\",[\"MSE\"])#,\"LWLN\",\"Contractive\",])\n",
    "Lambda=0\n",
    "if Loss==\"MSE\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments/model MSE/\"\n",
    "if Loss==\"Contractive\":\n",
    "    results_path=\"./Contractive model/\"\n",
    "    Lambda=0 #trial.suggest_float(\"Contractive_Lambda\",0.00001,0.0001)\n",
    "if Loss==\"LWLN\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments//mixed model/\"\n",
    "\n",
    "cnn_acc_ID=[]\n",
    "cnn_acc_OOD=[]\n",
    "\n",
    "step_size=0\n",
    "factor=0\n",
    "threshhold=0\n",
    "threshold_mode = 0\n",
    "eps=0\n",
    "\n",
    "minimal_loss=10\n",
    "#alpha = trial.suggest_float(\"grokalpha\",0.0,1.0)\n",
    "#lamb = trial.suggest_int(\"groklamb\",1,15)\n",
    "mod= TransformerAE(max_seq_len=50,\n",
    "                        N=4,\n",
    "                        heads=4,\n",
    "                        d_model=940,\n",
    "                        d_ff=940,\n",
    "                        neck=256,\n",
    "                        dropout=0.12\n",
    "                       ) #define_model(trial)\n",
    "print(summary(mod))\n",
    "lrE1=0.15 #trial.suggest_float(\"Learning_rate\",0.0002,0.5)\n",
    "lrE2=0.15 \n",
    "lrL=0.15 \n",
    "lrD=0.085\n",
    "optimizerEnc1 = Adam(mod.parameters(), lr=lrE1,eps=1e-10,weight_decay=0.005)\n",
    "optimizerEnc2 = Adadelta(mod.parameters(), lr=lrE2,eps=1e-10,weight_decay=0.005)\n",
    "optimizerDense = SGD(mod.vec2neck.parameters(), lr=lrL,weight_decay=0.005)\n",
    "optimizerDec = Adadelta(mod.parameters(), lr=lrD,eps=1e-10,weight_decay=0.01)\n",
    "\n",
    "\n",
    "\n",
    "sched_name=\"CyclicLR\"#trial.suggest_categorical(\"scheduler\",[\"CyclicLR\"])#,\"ReduceLROnPlateau\"])\n",
    "if sched_name==\"CyclicLR\" :\n",
    "    step_size=24000#trial.suggest_int(\"step_size_up\",900,2800)\n",
    "    schedulerEnc1 = torch.optim.lr_scheduler.CyclicLR(optimizerEnc1, base_lr=1e-4, max_lr=lrE1, step_size_up=step_size, step_size_down=80000,scale_mode=\"iterations\",mode=\"triangular2\",cycle_momentum=False)\n",
    "    schedulerEnc2 = torch.optim.lr_scheduler.CyclicLR(optimizerEnc2, base_lr=1e-4, max_lr=lrE2, step_size_up=step_size, step_size_down=80000,scale_mode=\"iterations\",mode=\"triangular2\",cycle_momentum=False)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizerDense, base_lr=1e-4, max_lr=lrD, step_size_up=8000, step_size_down=8000,scale_mode=\"iterations\",mode=\"triangular\",cycle_momentum=False)\n",
    "    \n",
    "    \n",
    "# if sched_name==\"ReduceLROnPlateau\" :\n",
    "#     factor=trial.suggest_float(\"R-lr-OP_factor\",0.001,0.5)\n",
    "#     threshhold=trial.suggest_float(\"R-lr-OP_threshhold\",0.0001,0.001)\n",
    "#     threshold_mode = trial.suggest_categorical(\"thresh_mod\",[\"rel\",\"abs\"])\n",
    "#     eps=trial.suggest_float(\"R-lr-OP_eps\",1e-08,1e-05)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=5, threshold=threshhold, threshold_mode=threshold_mode, cooldown=2, min_lr=0, eps=eps)\n",
    "\n",
    "\n",
    "\n",
    "# ch=torch.load(\"/media/crns/ADATA HD330/Experiments/mixed model/AE epoch 0 600.pth\")\n",
    "# resume_epoch=ch[\"epoch\"]\n",
    "# mod.load_state_dict(ch['model_state_dict'])\n",
    "# optimizerEnc1.load_state_dict(ch['optimizerENC1_state_dict'])\n",
    "# optimizerEnc2.load_state_dict(ch['optimizerENC2_state_dict'])\n",
    "# optimizerDense.load_state_dict(ch['optimizerDense_state_dict'])\n",
    "# optimizerDec.load_state_dict(ch['optimizerDec_state_dict'])\n",
    "\n",
    "# del(ch)\n",
    "\n",
    "\n",
    "batch_size=50 #trial.suggest_int(\"batch_size\",150)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "LW=LWLN_loss()\n",
    "\n",
    "num_epochs=1750\n",
    "\n",
    "device = accelerator.device\n",
    "run = wandb.init(\n",
    "# Set the project where this run will be logged\n",
    "project=\"aymen-project\",\n",
    "name= f\"Shuffled 100%(activation,age) data,new paperarch-{Loss} + wasserstein\" ,\n",
    "# Track hyperparameters and run metadata\n",
    "config={\n",
    "    \"Loss\":Loss,\n",
    "    \"lr Encoder 1\": lrE1,\n",
    "    \"lr Encoder 2\": lrE2,\n",
    "    \"lr Linear\": lrL,\n",
    "    \"lr Decoder\": lrD,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"sched_name\": sched_name,\n",
    "    \"step_size\": step_size,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"step_size\":step_size,\n",
    "    \"Lambda_contractive\":Lambda\n",
    "},)\n",
    "\n",
    "#run = wandb.init(project=\"aymen-project\", id=\"y7pm5vwk\", resume=\"must\")\n",
    "\n",
    "# \"factor\":factor,\n",
    "#     \"threshhold\":threshhold,\n",
    "#     \"threshold_mode\":threshold_mode,\n",
    "#     \"eps\":eps,\n",
    "random.shuffle(train_pair2)\n",
    "cs_tr=CustomDataset(train_pair2,batch_size=batch_size)\n",
    "nb_batches = len(cs_tr)//batch_size\n",
    "\n",
    "cs_val=CustomDataset(val_pair2,batch_size=batch_size)\n",
    "nb_val_batches = len(cs_val)//batch_size\n",
    "\n",
    "#optimizer_to(optimizer,device)\n",
    "#scheduler_to(scheduler,device)\n",
    "\n",
    "mod, optimizerEnc1,optimizerEnc2,optimizerDense,optimizerDec, cs_tr= accelerator.prepare(mod, optimizerEnc1,optimizerEnc2,optimizerDense,optimizerDec,cs_tr)\n",
    "# wandb.watch(mod, log_freq=10000 ,criterion=criterion,\n",
    "#     log='parameters',\n",
    "#     log_graph=True)\n",
    "mod.train()\n",
    "for epoch in range(600,num_epochs):\n",
    "    random.shuffle(train_pair2)\n",
    "    cs_tr=CustomDataset(train_pair2,batch_size=batch_size)\n",
    "    cs_tr=accelerator.prepare(cs_tr)\n",
    "    #start_time_epoch = time.time()\n",
    "    for i in tqdm(range(nb_batches)):\n",
    "        #start_time_batch = time.time()\n",
    "        Dataset,EXP,ACC,U = cs_tr[i]\n",
    "        x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]\n",
    "        # if (Loss==\"Contractive\") and (i%50==0):\n",
    "        #     for name, param in mod.named_parameters():\n",
    "        #         if name == 'vec2neck.weight':\n",
    "        #             W = param\n",
    "        #             break\n",
    "\n",
    "\n",
    "        x1=x1.cuda() #.to(torch.float32)\n",
    "        x2=x2.cuda() #.to(torch.float32)\n",
    "        tg=tg.cuda() #.to(torch.float32)\n",
    "\n",
    "        optimizerEnc1.zero_grad()\n",
    "        optimizerEnc2.zero_grad()\n",
    "        optimizerDense.zero_grad()\n",
    "        optimizerDec.zero_grad()\n",
    "\n",
    "        output = mod(x1,x2)\n",
    "\n",
    "        #print(output[2].shape ,output[3].shape,output[4].shape) \n",
    "        # if Loss==\"MSE\":\n",
    "        #     loss_tr = criterion(output[0],tg)\n",
    "        # if Loss==\"Contractive\":\n",
    "        #     CL=loss_Contractive(W,vec1,vec2, output[1], Lambda)\n",
    "        #     loss_tr = criterion(output[0],tg)+CL\n",
    "        if Loss==\"LWLN\":\n",
    "            vec1_np = output[0].detach().cpu().numpy()\n",
    "            vec2_np = tg.detach().cpu().numpy()\n",
    "\n",
    "            # Compute Wasserstein distance for each pair of vectors\n",
    "            wsd_list = [wasserstein_distance(vec1_np[i], vec2_np[i]) for i in range(vec1_np.shape[0])]\n",
    "\n",
    "            # If you need an aggregate measure, you can compute the average distance\n",
    "            average_wsd = sum(wsd_list) / len(wsd_list)\n",
    "            loss_tr = criterion(output[0],tg)+average_wsd\n",
    "\n",
    "\n",
    "#         except Exception as e:\n",
    "#             # Print the exception\n",
    "#             print(\"An exception occurred:\", e)\n",
    "#             traceback.print_exc()\n",
    "#             # Continue with the loop\n",
    "#             continue\n",
    "\n",
    "\n",
    "        accelerator.backward(loss_tr)\n",
    "        #grads = gradfilter_ema(mod, grads=grads, alpha=alpha, lamb=lamb)\n",
    "        optimizerEnc1.step()\n",
    "        optimizerEnc2.step()\n",
    "        optimizerDense.step()\n",
    "        optimizerDec.step()\n",
    "        if sched_name==\"ReduceLROnPlateau\" :\n",
    "            scheduler.step(loss_tr)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            schedulerEnc1.step()\n",
    "            schedulerEnc2.step()\n",
    "        \n",
    "        loss_to_save = float(loss_tr.detach().cpu().item())\n",
    "        wandb.log({\"Loss\":loss_to_save})\n",
    "    if loss_tr.detach().cpu().item()<minimal_loss:\n",
    "        minimal_loss=loss_tr.detach().cpu().item()\n",
    "        torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),\n",
    "                    'optimizerENC1_state_dict':  optimizerEnc1.state_dict() ,\n",
    "                    'optimizerENC2_state_dict':optimizerEnc2.state_dict(),\n",
    "                    'optimizerDense_state_dict':optimizerDense.state_dict(),\n",
    "                    'optimizerDec_state_dict': optimizerDec.state_dict(),\n",
    "                    'Batch Loss':loss_tr.detach().cpu().item()},\n",
    "                   results_path+'AE epoch best.pth')\n",
    "    if epoch%30==0 :\n",
    "        for block in [2,3,4]:\n",
    "                for head in range(4):\n",
    "                    plt.figure(figsize=(20, 20))\n",
    "                    hm=sns.heatmap(torch.mean( torch.mean(output[block][head], dim=1), dim=0).detach().cpu(), annot=False, cmap='cubehelix')\n",
    "                    plt.title('Attention Heatmap')\n",
    "                    heatmap_path = f'heatmap {block-2}_{head}_step_{i}.png'\n",
    "                    #plt.savefig(results_path+\"Attention/\"+heatmap_path)#,format='svg', dpi=800)\n",
    "                    wandb.log({f\"attention_heatmap {block-2}_{head}\":  wandb.Image(hm,caption=f\"attention_heatmap attention_heatmap {block-2}_{head}\")})\n",
    "                    plt.close()\n",
    "        mod.eval()\n",
    "        loss_val = []\n",
    "        for i_val in range(nb_val_batches):\n",
    "            #start_time_batch = time.time()\n",
    "            Dataset_val,EXP_val,ACC_val,U_val = cs_val[i_val]\n",
    "            x1_val,x2_val,tg_val = Dataset_val[:,0,:], Dataset_val[:,1,:],Dataset_val[:,2,:]\n",
    "            x1_val=x1_val.cuda() #.to(torch.float32)\n",
    "            x2_val=x2_val.cuda() #.to(torch.float32)\n",
    "            tg_val=tg_val.cuda() #.to(torch.float32)\n",
    "            with torch.no_grad():\n",
    "                #output_val = mod(x1_val,x2_val)\n",
    "                loss_val.append(criterion(mod(x1_val,x2_val)[0],tg_val))\n",
    "        loss_val = sum(loss_val)/len(loss_val)\n",
    "        wandb.log({f\"val_loss\":loss_val})\n",
    "            \n",
    "        torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),\n",
    "                    'optimizerENC1_state_dict':  optimizerEnc1.state_dict() ,\n",
    "                    'optimizerENC2_state_dict':optimizerEnc2.state_dict(),\n",
    "                    'optimizerDense_state_dict':optimizerDense.state_dict(),\n",
    "                    'optimizerDec_state_dict': optimizerDec.state_dict(),\n",
    "                    'Batch Loss':loss_tr.detach().cpu().item()},\n",
    "                   results_path+'AE epoch {} {}.pth'.format(track,epoch))\n",
    "        torch.cuda.empty_cache()\n",
    "wandb.finish()\n",
    "track=+1\n",
    "#     return loss_tr\n",
    "# study= optuna.create_study(direction=\"minimize\",storage=storage)\n",
    "# study.optimize(objective,n_trials=2,callbacks=[lambda study, trial: gc.collect()]+[logging_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d9d4d-1fa7-4720-98fb-1552f197bbd7",
   "metadata": {},
   "source": [
    "Testing loop :\n",
    "```[tasklist]\n",
    "### track MSE \n",
    "- [ ] add Classification report for 1 CNN\n",
    "- [ ] per layer MSE\n",
    "- [ ] Deeplift\n",
    "- [ ] Grackel\n",
    "### Loss functions + apply per layer\n",
    "- [ ] KL divergence\n",
    "- [ ] Wassertsiein\n",
    "- [ ] dataset distance\n",
    "- [ ] Layerwise normalisations\n",
    "- [ ] Cook's distance \n",
    "### Track weights and their saturation\n",
    "- [ ] Contractive\n",
    "- [ ] L2\n",
    "- [ ] saturated percentage\n",
    "- [ ] Experiment with pruning the CNNs\n",
    "### Topology of learned weights\n",
    "- [ ] Reebs + Smole complex\n",
    "- [ ] Persistant homolgy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9608b875-a0ba-499b-ab69-543c156ce475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7485\n"
     ]
    }
   ],
   "source": [
    "Cols=[\"label task 1\",\"label task 2\"]+ \\\n",
    "[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Pred weight {}\".format(x) for x in range(200)]+[\"Pred bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"Pred weight {}\".format(x) for x in range(208,1408)]+[\"Pred bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"Pred weight {}\".format(x) for x in range(1414,1510)]+[\"Pred bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"Pred weight {}\".format(x) for x in range(1514,2234)]+[\"Pred bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"Pred weight {}\".format(x) for x in range(2254,2454)]+[\"Pred bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"FN weight {}\".format(x) for x in range(200)]+[\"FN bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"FN weight {}\".format(x) for x in range(208,1408)]+[\"FN bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"FN weight {}\".format(x) for x in range(1414,1510)]+[\"FN bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"FN weight {}\".format(x) for x in range(1514,2234)]+[\"FN bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"FN weight {}\".format(x) for x in range(2254,2454)]+[\"FN bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Actual Accuracy\",\"Reconstructed Accuracy ID\",\"Transformer train Loss\"]+\\\n",
    "[\"MSE\",\"MSE 1\",\"MSE 2\",\"MSE 3\",\"MSE 4\",\"MSE 5\",\"KL divergence\",\"KL 1\",\"KL 2\",\"KL 3\",\"KL 4\",\"KL 5\",\"LWLN\"]+\\\n",
    "[\"Wasserstein Loss\",\"WS 1\",\"WS 2\",\"WS 3\",\"WS 4\",\"WS 5\",\"contractive distance\",\"N1\",\"N11\",\"N12\",\"N13\",\"N14\",\"N15\",\"N2\",\"N21\",\"N22\",\"N23\",\"N24\",\"N25\",\"saturated in pred(%)\",\"saturated in GT(%)\"]+\\\n",
    "[\"MSE FN\",\"MSE 1 FN\",\"MSE 2 FN\",\"MSE 3 FN\",\"MSE 4 FN\",\"MSE 5 FN\",\"KL divergence FN\",\"KL 1 FN\",\"KL 2 FN\",\"KL 3 FN\",\"KL 4 FN\",\"KL 5 FN\",\"LWLN FN\"]+\\\n",
    "[\"Wasserstein Loss FN\",\"WS 1 FN\",\"WS 2 FN\",\"WS 3 FN\",\"WS 4 FN\",\"WS 5 FN\",\"contractive distance FN\",\"N1 FN\",\"N11 FN\",\"N12 FN\",\"N13 FN\",\"N14 FN\",\"N15 FN\",\"N2 FN\",\"N21 FN\",\"N22 FN\",\"N23 FN\",\"N24 FN\",\"N25 FN\",\"saturated in pred FN(%)\",\"saturated in GT FN(%)\"]+\\\n",
    "[\"Step 0\",\"Step 25\",\"Step 50\",\"Step 75\",\"Step 100\",\"Step 125\",\"Step 150\",\"Step 175\",\"Step 200\",\"Step 225\",\"Step 250\",\"Step 275\",\"epoch 0\",\"epoch 1\",\"epoch 2\"]+\\\n",
    "[\"epoch 3\",\"epoch 4\",\"epoch 5\",\"epoch 6\",\"epoch 7\"]\n",
    "#incoporate Norm                                                     \n",
    "#The Fisher information metric X norm of the target  \n",
    "#dataset distance , topological distance ,UMAP distance\n",
    "\n",
    "print(len(Cols))\n",
    "DF= pd.DataFrame(columns=Cols)\n",
    "\n",
    "# row=[\"\".format(task1),int(ind[0]),ACC[0],\"\".format(task2),ACC[1]]+vector_aux.to_list()+[\"train\",valid_epoch_acc0,ACC[2],valid_epoch_acc1,L_train[-1]]\n",
    "# predicted_Weights.append(row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98643644-b4fc-4271-9aaf-c2eb44be2bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fb0cf-d13d-4729-ad50-e68214bf5846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e820345-4dfa-448c-bd4e-b528f52ea90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5990acfd-7770-473a-a0fa-c492920eb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e87b5c5a-65b0-4dba-a538-cf0dbdc762d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "# [\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "# [\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "# [\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "# [\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]\n",
    "class LWLN_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWLN_loss, self).__init__()\n",
    "    def forward(self, vec1,vec2):\n",
    "        loss = (torch.mean((vec1[0:208]-vec2[0:208])**2)/vec2[0:208].std() + \n",
    "                 torch.mean((vec1[208:1414]-vec2[208:1414])**2)/vec2[208:1414].std()+ \n",
    "                 torch.mean((vec1[1414:1514]-vec2[1414:1514])**2)/vec2[1414:1514].std()+\n",
    "                 torch.mean((vec1[1514:2254]-vec2[1514:2254])**2)/vec2[1514:2254].std()+\n",
    "                 torch.mean((vec1[2254:2464]-vec2[2254:2464])**2)/vec2[2254:2464].std())/(6)\n",
    "        \n",
    "        return loss\n",
    "LW=LWLN_loss()\n",
    "LW(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe1c6c11-2cbc-4a49-a88e-d894ef052778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('AE epoch 0 1230.pth'.split(' ')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "124ae4db-f17c-479d-b626-b6faaf739cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label task 1</th>\n",
       "      <th>label task 2</th>\n",
       "      <th>weight 0</th>\n",
       "      <th>weight 1</th>\n",
       "      <th>weight 2</th>\n",
       "      <th>weight 3</th>\n",
       "      <th>weight 4</th>\n",
       "      <th>weight 5</th>\n",
       "      <th>weight 6</th>\n",
       "      <th>weight 7</th>\n",
       "      <th>...</th>\n",
       "      <th>Step 250</th>\n",
       "      <th>Step 275</th>\n",
       "      <th>epoch 0</th>\n",
       "      <th>epoch 1</th>\n",
       "      <th>epoch 2</th>\n",
       "      <th>epoch 3</th>\n",
       "      <th>epoch 4</th>\n",
       "      <th>epoch 5</th>\n",
       "      <th>epoch 6</th>\n",
       "      <th>epoch 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 7485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label task 1, label task 2, weight 0, weight 1, weight 2, weight 3, weight 4, weight 5, weight 6, weight 7, weight 8, weight 9, weight 10, weight 11, weight 12, weight 13, weight 14, weight 15, weight 16, weight 17, weight 18, weight 19, weight 20, weight 21, weight 22, weight 23, weight 24, weight 25, weight 26, weight 27, weight 28, weight 29, weight 30, weight 31, weight 32, weight 33, weight 34, weight 35, weight 36, weight 37, weight 38, weight 39, weight 40, weight 41, weight 42, weight 43, weight 44, weight 45, weight 46, weight 47, weight 48, weight 49, weight 50, weight 51, weight 52, weight 53, weight 54, weight 55, weight 56, weight 57, weight 58, weight 59, weight 60, weight 61, weight 62, weight 63, weight 64, weight 65, weight 66, weight 67, weight 68, weight 69, weight 70, weight 71, weight 72, weight 73, weight 74, weight 75, weight 76, weight 77, weight 78, weight 79, weight 80, weight 81, weight 82, weight 83, weight 84, weight 85, weight 86, weight 87, weight 88, weight 89, weight 90, weight 91, weight 92, weight 93, weight 94, weight 95, weight 96, weight 97, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 7485 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c66eb2d5-b52f-4c0a-848e-c46dc632a12a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10916/1395850525.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mL_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L_files' is not defined"
     ]
    }
   ],
   "source": [
    "random.shuffle(L_files)\n",
    "L_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4562651c-24f9-459f-928c-51fb37c675bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10916/1674297626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#vec1.tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mL_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mL_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL_files\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'AE epoch'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_path' is not defined"
     ]
    }
   ],
   "source": [
    "#vec1.tolist()\n",
    "\n",
    "L_files=os.listdir(results_path)\n",
    "L_files=[ x for x in L_files if 'AE epoch' in x ]\n",
    "def extract_epoch(filename):\n",
    "    epoch_str = filename.split(' ')[-1].split('.')[0]\n",
    "    return int(epoch_str) if epoch_str.isdigit() else float('inf')\n",
    "# Sort the list using the epoch number as the key\n",
    "L_files = sorted(L_files, key=extract_epoch,reverse=True)\n",
    "L_files[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2cf35b4-115b-4b79-bc05-bb0855a393a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder droupout init 0.12\n",
      "encoder droupout init 0.12\n",
      "decoder droupout init 0.12\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "TransformerAE                                      --\n",
      "├─EncoderNeuronGroup: 1-1                          --\n",
      "│    └─EmbedderNeuronGroup: 2-1                    --\n",
      "│    │    └─Linear: 3-1                            15,980\n",
      "│    │    └─Linear: 3-2                            76,140\n",
      "│    └─PositionalEncoder: 2-2                      --\n",
      "│    └─ModuleList: 2-3                             --\n",
      "│    │    └─EncoderLayer: 3-3                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-4                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-5                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-6                      5,311,000\n",
      "│    └─Norm: 2-4                                   1,880\n",
      "├─EncoderNeuronGroup: 1-2                          --\n",
      "│    └─EmbedderNeuronGroup: 2-5                    --\n",
      "│    │    └─Linear: 3-7                            15,980\n",
      "│    │    └─Linear: 3-8                            76,140\n",
      "│    └─PositionalEncoder: 2-6                      --\n",
      "│    └─ModuleList: 2-7                             --\n",
      "│    │    └─EncoderLayer: 3-9                      5,311,000\n",
      "│    │    └─EncoderLayer: 3-10                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-11                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-12                     5,311,000\n",
      "│    └─Norm: 2-8                                   1,880\n",
      "├─DecoderNeuronGroup: 1-3                          --\n",
      "│    └─Neck2Seq: 2-9                               --\n",
      "│    │    └─ModuleList: 3-13                       12,079,000\n",
      "│    └─PositionalEncoder: 2-10                     --\n",
      "│    └─ModuleList: 2-11                            --\n",
      "│    │    └─EncoderLayer: 3-14                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-15                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-16                     5,311,000\n",
      "│    │    └─EncoderLayer: 3-17                     5,311,000\n",
      "│    └─Norm: 2-12                                  1,880\n",
      "│    └─Seq2Vec: 2-13                               --\n",
      "│    │    └─Linear: 3-18                           115,810,464\n",
      "├─Linear: 1-4                                      481,536\n",
      "├─Tanh: 1-5                                        --\n",
      "===========================================================================\n",
      "Total params: 192,292,880\n",
      "Trainable params: 192,292,880\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "AE epoch 0 900.pth Checkpoint Epoch \t 900 Loss \t 0.1744433343410492\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10916/1204616599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mnb_test_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcs_ts\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m                 \u001b[0;31m# MS-AMP will handle the device placement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 \u001b[0mdevice_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             result = tuple(\n\u001b[0m\u001b[1;32m   1293\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 \u001b[0mdevice_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             result = tuple(\n\u001b[0;32m-> 1293\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m             )\n\u001b[1;32m   1295\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m_prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 )\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdevice_placement\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluation_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             if self.distributed_type in (\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv \n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "import gc\n",
    "from accelerate import Accelerator\n",
    "from scipy.stats import wasserstein_distance\n",
    "#WSD=wasserstein_distance(vec1,vec2)\n",
    "\n",
    "track=0\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "#storage = JournalStorage(JournalFileStorage(\"optuna-journal DDP 3 Losses.log\"))\n",
    "\n",
    "#def objective(trial):\n",
    "global track , output , model\n",
    "grads=None\n",
    "accelerator = Accelerator()\n",
    "Loss=\"LWLN\" #trial.suggest_categorical(\"Loss function\",[\"MSE\"])#,\"LWLN\",\"Contractive\",])\n",
    "Lambda=0\n",
    "if Loss==\"MSE\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments/model MSE/\"\n",
    "if Loss==\"Contractive\":\n",
    "    results_path=\"./Contractive model/\"\n",
    "    Lambda=0 #trial.suggest_float(\"Contractive_Lambda\",0.00001,0.0001)\n",
    "if Loss==\"LWLN\":\n",
    "    results_path=\"/media/crns/ADATA HD330/Experiments//mixed model/\"\n",
    "\n",
    "\n",
    "step_size=0\n",
    "factor=0\n",
    "threshhold=0\n",
    "threshold_mode = 0\n",
    "eps=0\n",
    "\n",
    "minimal_loss=10\n",
    "#alpha = trial.suggest_float(\"grokalpha\",0.0,1.0)\n",
    "#lamb = trial.suggest_int(\"groklamb\",1,15)\n",
    "mod= TransformerAE(max_seq_len=50,\n",
    "                        N=4,\n",
    "                        heads=4,\n",
    "                        d_model=940,\n",
    "                        d_ff=940,\n",
    "                        neck=256,\n",
    "                        dropout=0.12\n",
    "                       ) #define_model(trial)\n",
    "mod=mod.to(\"cpu\")\n",
    "print(summary(mod))\n",
    "\n",
    "\n",
    "L_files=os.listdir(results_path)\n",
    "L_files=[ x for x in L_files if 'AE epoch' in x ]\n",
    "def extract_epoch(filename):\n",
    "    epoch_str = filename.split(' ')[-1].split('.')[0]\n",
    "    return int(epoch_str) if epoch_str.isdigit() else float('inf')\n",
    "# Sort the list using the epoch number as the key\n",
    "L_files = sorted(L_files, key=extract_epoch,reverse=True)\n",
    "\n",
    "\n",
    "for file in ['AE epoch 0 900.pth']:\n",
    "    DF= pd.DataFrame(columns=Cols)\n",
    "    ch=torch.load(f\"/media/crns/ADATA HD330/Experiments//mixed model/{file}\", map_location='cpu')\n",
    "    resume_epoch=ch[\"epoch\"]\n",
    "    l=ch[\"Batch Loss\"]\n",
    "    mod.load_state_dict(ch['model_state_dict'])\n",
    "    print(file ,\"Checkpoint Epoch \\t\" , resume_epoch,\"Loss \\t\",l)\n",
    "    cnn_acc_ID=[]\n",
    "    cnn_acc_OOD=[]\n",
    "    DF.at[track,\"Transformer train Loss\"]=l\n",
    "    del(ch)\n",
    "    mod=mod.to('cpu')\n",
    "\n",
    "    batch_size=80 #trial.suggest_int(\"batch_size\",150)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    LW=LWLN_loss()\n",
    "\n",
    "    cs_ts=CustomDataset(test_pair2,batch_size=batch_size)\n",
    "    nb_test_batches = len(cs_ts)//batch_size\n",
    "\n",
    "    mod,cs_ts= accelerator.prepare(mod, cs_ts)\n",
    "    mod.eval()\n",
    "\n",
    "    loss_values = []\n",
    "    for i in tqdm(range(nb_test_batches)):\n",
    "\n",
    "        Dataset,EXP,ACC,U = cs_ts[i]\n",
    "        x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]\n",
    "\n",
    "        x1=x1.cuda() #.to(torch.float32)\n",
    "        x2=x2.cuda() #.to(torch.float32)\n",
    "        tg=tg.cuda() #.to(torch.float32)\n",
    "        with torch.no_grad():\n",
    "            output = mod(x1,x2)\n",
    "            loss_values.append(criterion(output[0],tg))\n",
    "        for vec in range(len(x1)):\n",
    "            DF.at[track,\"label task 1\"]=f'{EXP[vec][0]}'\n",
    "            DF.at[track,\"label task 2\"]=f'{EXP[vec][1]}'\n",
    "            #print(Cols[2:2466][-2:],Cols[2466:4930][-2:],Cols[4930:7394][-2:])\n",
    "            \n",
    "            vec1=output[0][vec].cpu()\n",
    "            vec2=tg[vec].cpu()\n",
    "            DF.loc[track,Cols[2:2466]]=vec2.tolist()\n",
    "            DF.loc[track,Cols[2466:4930]]=vec1.tolist()#Cols[4930:7394][-2:])\n",
    "            \n",
    "            \n",
    "            \n",
    "            MSE=criterion(vec1,vec2).item()\n",
    "            MS1=criterion(vec1[:208],vec2[:208]).item()\n",
    "            MS2=criterion(vec1[208:1414],vec2[208:1414]).item()\n",
    "            MS3=criterion(vec1[1414:1514],vec2[1414:1514]).item()\n",
    "            MS4=criterion(vec1[1514:2254],vec2[1514:2254]).item()\n",
    "            MS5=criterion(vec1[2254:],vec2[2254:]).item()\n",
    "            #print(\"MSE :\",MS1,MS2,MS3,MS4,MS5,MSE)\n",
    "            DF.at[track,\"MSE\"]=MSE\n",
    "            DF.at[track,\"MSE 1\"]=MS1\n",
    "            DF.at[track,\"MSE 2\"]=MS2\n",
    "            DF.at[track,\"MSE 3\"]=MS3\n",
    "            DF.at[track,\"MSE 4\"]=MS4\n",
    "            DF.at[track,\"MSE 5\"]=MS5\n",
    "            \n",
    "            \n",
    "            \n",
    "            kl_loss = nn.KLDivLoss(reduction=\"mean\")\n",
    "            KLD=kl_loss(vec1,vec2).item() #pred, true\n",
    "            KL1=kl_loss(vec1[:208],vec2[:208]).item()\n",
    "            KL2=kl_loss(vec1[208:1414],vec2[208:1414]).item()\n",
    "            KL3=kl_loss(vec1[1414:1514],vec2[1414:1514]).item()\n",
    "            KL4=kl_loss(vec1[1514:2254],vec2[1514:2254]).item()\n",
    "            KL5=kl_loss(vec1[2254:],vec2[2254:]).item()\n",
    "            #print(\"KLD :\",KLD,KL1,KL2,KL3,KL4,KL5)\n",
    "            DF.at[track,\"KLD\"]=KLD\n",
    "            DF.at[track,\"KL 1\"]=KL1\n",
    "            DF.at[track,\"KL 2\"]=KL2\n",
    "            DF.at[track,\"KL 3\"]=KL3\n",
    "            DF.at[track,\"KL 4\"]=KL4\n",
    "            DF.at[track,\"KL 5\"]=KL5\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            WSD=wasserstein_distance(vec1,vec2)\n",
    "            WS1=wasserstein_distance(vec1[:208],vec2[:208])\n",
    "            WS2=wasserstein_distance(vec1[208:1414],vec2[208:1414])\n",
    "            WS3=wasserstein_distance(vec1[1414:1514],vec2[1414:1514])\n",
    "            WS4=wasserstein_distance(vec1[1514:2254],vec2[1514:2254])\n",
    "            WS5=wasserstein_distance(vec1[2254:],vec2[2254:])\n",
    "            #print(\"WSD :\",WSD,WS1,WS2,WS3,WS4,WS5)\n",
    "            DF.at[track,\"Wasserstein Loss\"]=WSD\n",
    "            DF.at[track,\"WS 1\"]=WS1\n",
    "            DF.at[track,\"WS 2\"]=WS2\n",
    "            DF.at[track,\"WS 3\"]=WS3\n",
    "            DF.at[track,\"WS 4\"]=WS4\n",
    "            DF.at[track,\"WS 5\"]=WS5\n",
    "            \n",
    "            for name, param in mod.named_parameters():\n",
    "                if name == 'vec2neck.weight':\n",
    "                    W = param\n",
    "                    break\n",
    "                    \n",
    "            CL=loss_Contractive(W,vec1,vec2, output[1], 0.00001)\n",
    "            DF.at[track,\"contractive distance\"]=CL.cpu().item()\n",
    "            \n",
    "            #print(\"Contractive :\",CL.cpu().item())\n",
    "            Norm1=np.sum(np.abs(vec1.numpy()))\n",
    "            N11=np.sum(np.abs(vec1[:208].numpy()))\n",
    "            N12=np.sum(np.abs(vec1[208:1414].numpy()))\n",
    "            N13=np.sum(np.abs(vec1[1414:1514].numpy()))\n",
    "            N14=np.sum(np.abs(vec1[1514:2254].numpy()))\n",
    "            N15=np.sum(np.abs(vec1[2254:].numpy()))\n",
    "            #print(\"Weight pred L1: \",Norm1, N11,N12,N13,N14,N15)\n",
    "            DF.at[track,\"N1\"]=Norm1\n",
    "            DF.at[track,\"N11\"]=N11\n",
    "            DF.at[track,\"N12\"]=N12\n",
    "            DF.at[track,\"N13\"]=N13\n",
    "            DF.at[track,\"N14\"]=N14\n",
    "            DF.at[track,\"N15\"]=N15\n",
    "            \n",
    "            Norm2=np.sum(np.abs(vec2.numpy()))\n",
    "            N21=np.sum(np.abs(vec2[:208].numpy()))\n",
    "            N22=np.sum(np.abs(vec2[208:1414].numpy()))\n",
    "            N23=np.sum(np.abs(vec2[1414:1514].numpy()))\n",
    "            N24=np.sum(np.abs(vec2[1514:2254].numpy()))\n",
    "            N25=np.sum(np.abs(vec2[2254:].numpy()))\n",
    "            #print(\"Weight GT L1: \",Norm2, N21,N22,N23,N24,N25)\n",
    "            DF.at[track,\"N2\"]=Norm2\n",
    "            DF.at[track,\"N21\"]=N21\n",
    "            DF.at[track,\"N22\"]=N22\n",
    "            DF.at[track,\"N23\"]=N23\n",
    "            DF.at[track,\"N24\"]=N24\n",
    "            DF.at[track,\"N25\"]=N25\n",
    "            \n",
    "            DF.at[track,\"saturated in pred(%)\"]=100*sum(1 for x in vec1 if x > 0.95 or x<0.05)/len(vec1)\n",
    "            DF.at[track,\"saturated in GT(%)\"]=100*sum(1 for x in vec2 if x > 0.95 or x<0.05)/len(vec2)\n",
    "            DF.at[track,\"LWLN\"]=LW(vec1,vec2).cpu().item()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(vec1.cpu().numpy().flatten(), label='Predicted', alpha=0.7)\n",
    "            plt.plot(tg[0].cpu().numpy().flatten(), label='target', alpha=0.7)\n",
    "\n",
    "            # Add vertical lines\n",
    "            # for x in range(len(vec1_np)):\n",
    "            #     plt.axvline(x=x, color='gray', linestyle='--', alpha=0.2)\n",
    "\n",
    "            # Add legend and labels\n",
    "            plt.legend()\n",
    "            plt.xlabel('Neurone Index')\n",
    "            plt.ylabel('Neurone Value')\n",
    "            plt.title('Plot of pred vs target')\n",
    "\n",
    "\n",
    "            #import umap\n",
    "            # reducer = umap.UMAP()\n",
    "            # Batch_UMAP=torch.rand(80,2464)\n",
    "            # fitted_reduced = reducer.fit(Batch_UMAP)\n",
    "            # fitted_reduced.transform(vec1)\n",
    "\n",
    "            ###########RECONSTRUCTING##############\n",
    "            y_pred=torch.unsqueeze(output[0][vec], 0) \n",
    "            y =torch.unsqueeze(tg[vec], 0) \n",
    "\n",
    "            selected_row = cs_ts.df.iloc[int(U[vec][0]), 11:17]  \n",
    "            columns_with_one = selected_row[selected_row == 1].index.tolist()\n",
    "            activ=columns_with_one\n",
    "            epochCNN=cs_ts.df.loc[int(U[vec][0])]['epoch']\n",
    "\n",
    "\n",
    "            checkpoint=OrderedDict()\n",
    "            vector_aux= output[0][vec].detach()\n",
    "            y_pred=vector_aux.cpu()\n",
    "\n",
    "            task1=[int(x) for x in EXP[vec][0]]\n",
    "            task2=[int(x) for x in EXP[vec][1]]\n",
    "            task3=sorted(task1+task2)\n",
    "\n",
    "\n",
    "            All=list(range(10))\n",
    "            L2=[k for k in All if k not in task3] # Out of distribution classes\n",
    "            L_others=[k for k in All if k not in task3] #Classes to test on (In distribution)\n",
    "\n",
    "            checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(y_pred[0:200]).reshape([8, 1, 5, 5]))\n",
    "            checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(y_pred[200:208]).reshape([8]))\n",
    "\n",
    "            checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(y_pred[208:1408]).reshape([6, 8, 5, 5]))\n",
    "            checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(y_pred[1408:1414]).reshape([6]))\n",
    "\n",
    "            checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(y_pred[1414:1510]).reshape([4, 6, 2, 2]))\n",
    "            checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(y_pred[1510:1514]).reshape([4]))\n",
    "\n",
    "            checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(y_pred[1514:2234]).reshape([20,36]))\n",
    "            checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(y_pred[2234:2254]).reshape([20]))\n",
    "\n",
    "            checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(y_pred[2254:2454]).reshape([10,20]))\n",
    "            checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(y_pred[2454:2464]).reshape([10]))\n",
    "\n",
    "            Brain = CNN(1,activ[0],0,\"kaiming_uniform\")\n",
    "\n",
    "            model=copy.deepcopy(Brain)\n",
    "            model.load_state_dict(checkpoint)\n",
    "\n",
    "            criterion_CNN0=CrossEntropyLoss()\n",
    "\n",
    "            test_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "            Ts_DL0 = DataLoader(dataset=test_IF0, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "            _, valid_epoch_acc0,_= validate(model, Ts_DL0,  criterion_CNN0,10)\n",
    "            if len(task3)==10:\n",
    "                valid_epoch_acc1=valid_epoch_acc0\n",
    "                continue\n",
    "            else:\n",
    "                criterion_CNN1=CrossEntropyLoss()\n",
    "                test_IF1=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in task3],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Ts_DL1 = DataLoader(dataset=test_IF1, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "            #valid_epoch_loss0, valid_epoch_acc1,L_mx= validate(model, Ts_DL1,  criterion_CNN1,10)\n",
    "            #print(\"Reconstructed cnn acc ID\",valid_epoch_acc0)\n",
    "            #print(\"Reconstructed cnn acc OOD\",valid_epoch_acc1)\n",
    "            DF.at[track,\"Reconstructed Accuracy ID\"]=valid_epoch_acc0\n",
    "            \n",
    "            optimizerCNN = Adam(model.parameters(), lr=0.05)\n",
    "            schedulerCNN = torch.optim.lr_scheduler.CyclicLR(optimizerCNN ,base_lr=1e-3, max_lr=0.1, step_size_up=400, mode=\"triangular2\", cycle_momentum=False)\n",
    "            criterion_CNN=CrossEntropyLoss()\n",
    "\n",
    "\n",
    "            train_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/train/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "            Tr_DLr = DataLoader(dataset=train_IF0, batch_size=150, num_workers=0, shuffle=True)\n",
    "\n",
    "\n",
    "            fine_tune_needed=0\n",
    "            #FINETUNING\n",
    "            for epoch_cnn in range(8):\n",
    "                if epoch_cnn==0:\n",
    "                    train_epoch_loss, train_epoch_acc,_ = train(model, Tr_DLr, optimizerCNN, criterion_CNN,10,df=DF,First=True)\n",
    "                    valid_epoch_loss0FN, valid_epoch_acc0FN,_= validate(model, Ts_DL0,  criterion_CNN,10)\n",
    "                    DF.at[track,\"epoch 0\"]=valid_epoch_acc0FN\n",
    "                else:\n",
    "                    train_epoch_loss, train_epoch_acc,_ = train(model, Tr_DLr, optimizerCNN, criterion_CNN,10)\n",
    "                    valid_epoch_loss0FN, valid_epoch_acc0FN,_= validate(model, Ts_DL0,  criterion_CNN,10)\n",
    "                    DF.at[track,f\"epoch {epoch_cnn}\"]=valid_epoch_acc0FN\n",
    "                schedulerCNN.step()\n",
    "                fine_tune_needed+=1\n",
    "            L_param=[]\n",
    "            for param in model.parameters():\n",
    "                m = nn.Flatten(0,-1)\n",
    "                L_param.append(m(param))\n",
    "            vec1FN = torch.Tensor()\n",
    "            for idx in L_param:\n",
    "                vec1FN = torch.cat((vec1FN, idx.view(-1)))\n",
    "            vec1FN=vec1FN.detach().cpu()\n",
    "            vec2=tg[vec].cpu()\n",
    "            DF.loc[track,Cols[4930:7394]]=vec1FN.tolist()\n",
    "            MSE=criterion(vec1FN,vec2).item()\n",
    "            MS1=criterion(vec1FN[:208],vec2[:208]).item()\n",
    "            MS2=criterion(vec1FN[208:1414],vec2[208:1414]).item()\n",
    "            MS3=criterion(vec1FN[1414:1514],vec2[1414:1514]).item()\n",
    "            MS4=criterion(vec1FN[1514:2254],vec2[1514:2254]).item()\n",
    "            MS5=criterion(vec1FN[2254:],vec2[2254:]).item()\n",
    "            \n",
    "            \n",
    "            #print(\"MSE :\",MS1,MS2,MS3,MS4,MS5,MSE)\n",
    "            DF.at[track,\"MSE FN\"]=MSE\n",
    "            DF.at[track,\"MSE 1 FN\"]=MS1\n",
    "            DF.at[track,\"MSE 2 FN\"]=MS2\n",
    "            DF.at[track,\"MSE 3 FN\"]=MS3\n",
    "            DF.at[track,\"MSE 4 FN\"]=MS4\n",
    "            DF.at[track,\"MSE 5 FN\"]=MS5\n",
    "            kl_loss = nn.KLDivLoss(reduction=\"mean\")\n",
    "            KLD=kl_loss(vec1FN,vec2).item() #pred, true\n",
    "            KL1=kl_loss(vec1FN[:208],vec2[:208]).item()\n",
    "            KL2=kl_loss(vec1FN[208:1414],vec2[208:1414]).item()\n",
    "            KL3=kl_loss(vec1FN[1414:1514],vec2[1414:1514]).item()\n",
    "            KL4=kl_loss(vec1FN[1514:2254],vec2[1514:2254]).item()\n",
    "            KL5=kl_loss(vec1FN[2254:],vec2[2254:]).item()\n",
    "            #print(\"KLD :\",KLD,KL1,KL2,KL3,KL4,KL5)\n",
    "            DF.at[track,\"KL divergence FN\"]=KLD\n",
    "            DF.at[track,\"KL 1 FN\"]=KL1\n",
    "            DF.at[track,\"KL 2 FN\"]=KL2\n",
    "            DF.at[track,\"KL 3 FN\"]=KL3\n",
    "            DF.at[track,\"KL 4 FN\"]=KL4\n",
    "            DF.at[track,\"KL 5 FN\"]=KL5\n",
    "\n",
    "            WSD=wasserstein_distance(vec1FN,vec2)\n",
    "            WS1=wasserstein_distance(vec1FN[:208],vec2[:208])\n",
    "            WS2=wasserstein_distance(vec1FN[208:1414],vec2[208:1414])\n",
    "            WS3=wasserstein_distance(vec1FN[1414:1514],vec2[1414:1514])\n",
    "            WS4=wasserstein_distance(vec1FN[1514:2254],vec2[1514:2254])\n",
    "            WS5=wasserstein_distance(vec1FN[2254:],vec2[2254:])\n",
    "            #print(\"WSD :\",WSD,WS1,WS2,WS3,WS4,WS5)\n",
    "            \n",
    "            DF.at[track,\"WSD FN\"]=WSD\n",
    "            DF.at[track,\"WS 1 FN\"]=WS1\n",
    "            DF.at[track,\"WS 2 FN\"]=WS2\n",
    "            DF.at[track,\"WS 3 FN\"]=WS3\n",
    "            DF.at[track,\"WS 4 FN\"]=WS4\n",
    "            DF.at[track,\"WS 5 FN\"]=WS5\n",
    "            for name, param in mod.named_parameters():\n",
    "                if name == 'vec2neck.weight':\n",
    "                    W = param\n",
    "                    break\n",
    "            CL=loss_Contractive(W,vec1FN,vec2, output[1], 0.00001)        \n",
    "            #print(\"Contractive :\",CL.cpu().item())\n",
    "            DF.at[track,\"contractive distance FN\"]=CL.cpu().item()\n",
    "            Norm1=np.sum(np.abs(vec1FN.numpy()))\n",
    "            N11=np.sum(np.abs(vec1FN[:208].numpy()))\n",
    "            N12=np.sum(np.abs(vec1FN[208:1414].numpy()))\n",
    "            N13=np.sum(np.abs(vec1FN[1414:1514].numpy()))\n",
    "            N14=np.sum(np.abs(vec1FN[1514:2254].numpy()))\n",
    "            N15=np.sum(np.abs(vec1FN[2254:].numpy()))\n",
    "            #print(\"Weight pred L1: \",Norm1, N11,N12,N13,N14,N15)\n",
    "            DF.at[track,\"N1 FN\"]=Norm1\n",
    "            DF.at[track,\"N11 FN\"]=N11\n",
    "            DF.at[track,\"N12 FN\"]=N12\n",
    "            DF.at[track,\"N13 FN\"]=N13\n",
    "            DF.at[track,\"N14 FN\"]=N14\n",
    "            DF.at[track,\"N15 FN\"]=N15\n",
    "            Norm2=np.sum(np.abs(vec2.numpy()))\n",
    "            N21=np.sum(np.abs(vec2[:208].numpy()))\n",
    "            N22=np.sum(np.abs(vec2[208:1414].numpy()))\n",
    "            N23=np.sum(np.abs(vec2[1414:1514].numpy()))\n",
    "            N24=np.sum(np.abs(vec2[1514:2254].numpy()))\n",
    "            N25=np.sum(np.abs(vec2[2254:].numpy()))\n",
    "            #print(\"Weight GT L1: \",Norm2, N21,N22,N23,N24,N25)\n",
    "            DF.at[track,\"N2 FN\"]=Norm2\n",
    "            DF.at[track,\"N21 FN\"]=N21\n",
    "            DF.at[track,\"N22 FN\"]=N22\n",
    "            DF.at[track,\"N23 FN\"]=N23\n",
    "            DF.at[track,\"N24 FN\"]=N24\n",
    "            DF.at[track,\"N25 FN\"]=N25\n",
    "            #print(\"Saturation in pred \",100*sum(1 for x in vec1FN if x > 0.95 or x<0.05)/len(vec1FN),\"% \\t saturaion in target\",100*sum(1 for x in vec2 if x > 0.95 or x<0.05)/len(vec2),\"%\")\n",
    "            #print(\"LWLN \",LW(vec1FN,vec2).item())\n",
    "            DF.at[track,\"saturated in pred FN(%)\"]=100*sum(1 for x in vec1FN if x > 0.95 or x<0.05)/len(vec1FN)\n",
    "            DF.at[track,\"saturated in GT FN(%)\"]=100*sum(1 for x in vec2 if x > 0.95 or x<0.05)/len(vec2)\n",
    "            DF.at[track,\"LWLN FN\"]=LW(vec1FN,vec2).cpu().item()\n",
    "            \n",
    "            #print(\"----------------------\")\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(vec1FN.cpu().numpy().flatten(), label='Predicted', alpha=0.7)\n",
    "            plt.plot(tg[vec].cpu().numpy().flatten(), label='target', alpha=0.7)\n",
    "\n",
    "            # Add vertical lines\n",
    "            # for x in range(len(vec1_np)):\n",
    "            #     plt.axvline(x=x, color='gray', linestyle='--', alpha=0.2)\n",
    "\n",
    "            # Add legend and labels\n",
    "            plt.legend()\n",
    "            plt.xlabel('Neurone Index')\n",
    "            plt.ylabel('Neurone Value')\n",
    "            plt.title(f'{file} {EXP[vec][0]} {EXP[vec][1]} {valid_epoch_acc0FN} %')\n",
    "            DF.to_csv(results_path+\"Tracking/\"+file[:-3]+\"csv\")\n",
    "            track=track+1\n",
    "\n",
    "        if i%100==0 and i>0 :\n",
    "            print(loss_values[-1])\n",
    "            for block in [2,3,4]:\n",
    "                    for head in range(4):\n",
    "                        plt.figure(figsize=(20, 20))\n",
    "                        hm=sns.heatmap(torch.mean( torch.mean(output[block][head], dim=1), dim=0).detach().cpu(), annot=False, cmap='cubehelix')\n",
    "                        plt.title('Attention Heatmap')\n",
    "                        heatmap_path = f'heatmap {file} {block-2}_{head}_step_{i}.png'\n",
    "                        plt.savefig(results_path+\"Attention/\"+heatmap_path)#,format='svg', dpi=800)\n",
    "                        #wandb.log({f\"attention_heatmap {block-2}_{head}\":  wandb.Image(hm,caption=f\"attention_heatmap attention_heatmap {block-2}_{head}\")})\n",
    "                        plt.close()\n",
    "    print(\"Transformer Test set: \\t\",file, (sum(loss_values)/len(loss_values)).cpu().item())\n",
    "    # Create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8219ac75-ba09-46af-a7a2-5acddb8f8a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Accuracy</th>\n",
       "      <th>Reconstructed Accuracy ID</th>\n",
       "      <th>Transformer train Loss</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE 1</th>\n",
       "      <th>MSE 2</th>\n",
       "      <th>MSE 3</th>\n",
       "      <th>MSE 4</th>\n",
       "      <th>MSE 5</th>\n",
       "      <th>KL divergence</th>\n",
       "      <th>...</th>\n",
       "      <th>Step 250</th>\n",
       "      <th>Step 275</th>\n",
       "      <th>epoch 0</th>\n",
       "      <th>epoch 1</th>\n",
       "      <th>epoch 2</th>\n",
       "      <th>epoch 3</th>\n",
       "      <th>epoch 4</th>\n",
       "      <th>epoch 5</th>\n",
       "      <th>epoch 6</th>\n",
       "      <th>epoch 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Actual Accuracy, Reconstructed Accuracy ID, Transformer train Loss, MSE, MSE 1, MSE 2, MSE 3, MSE 4, MSE 5, KL divergence, KL 1, KL 2, KL 3, KL 4, KL 5, LWLN, Wasserstein Loss, WS 1, WS 2, WS 3, WS 4, WS 5, contractive distance, N1, N11, N12, N13, N14, N15, N2, N21, N22, N23, N24, N25, saturated in pred(%), saturated in GT(%), MSE FN, MSE 1 FN, MSE 2 FN, MSE 3 FN, MSE 4 FN, MSE 5 FN, KL divergence FN, KL 1 FN, KL 2 FN, KL 3 FN, KL 4 FN, KL 5 FN, LWLN FN, Wasserstein Loss FN, WS 1 FN, WS 2 FN, WS 3 FN, WS 4 FN, WS 5 FN, contractive distance FN, N1 FN, N11 FN, N12 FN, N13 FN, N14 FN, N15 FN, N2 FN, N21 FN, N22 FN, N23 FN, N24 FN, N25 FN, saturated in pred FN(%), saturated in GT FN(%), Step 0, Step 25, Step 50, Step 75, Step 100, Step 125, Step 150, Step 175, Step 200, Step 225, Step 250, Step 275, epoch 0, epoch 1, epoch 2, epoch 3, epoch 4, epoch 5, epoch 6, epoch 7]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 91 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=DF[Cols[7394:]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5cdebd87-d0df-44a8-b02a-f593737880c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# [\"Actual Accuracy\",\"Reconstructed Accuracy ID\",\"Transformer train Loss\"]+\\\n",
    "# [\"MSE\",\"MSE 1\",\"MSE 2\",\"MSE 3\",\"MSE 4\",\"MSE 5\",\"KL divergence\",\"KL 1\",\"KL 2\",\"KL 3\",\"KL 4\",\"KL 5\",\"LWLN\"]+\\\n",
    "# [\"Wasserstein Loss\",\"WS 1\",\"WS 2\",\"WS 3\",\"WS 4\",\"WS 5\",\"contractive distance\",\"N1\",\"N11\",\"N12\",\"N13\",\"N14\",\"N15\",\"N2\",\"N21\",\"N22\",\"N23\",\"N24\",\"N25\",\"saturated in pred(%)\",\"saturated in GT(%)\"]+\\\n",
    "# [\"MSE FN\",\"MSE 1 FN\",\"MSE 2 FN\",\"MSE 3 FN\",\"MSE 4 FN\",\"MSE 5 FN\",\"KL divergence FN\",\"KL 1 FN\",\"KL 2 FN\",\"KL 3 FN\",\"KL 4 FN\",\"KL 5 FN\",\"LWLN FN\"]+\\\n",
    "# [\"Wasserstein Loss FN\",\"WS 1 FN\",\"WS 2 FN\",\"WS 3 FN\",\"WS 4 FN\",\"WS 5 FN\",\"contractive distance FN\",\"N1 FN\",\"N11 FN\",\"N12 FN\",\"N13 FN\",\"N14 FN\",\"N15 FN\",\"N2 FN\",\"N21 FN\",\"N22 FN\",\"N23 FN\",\"N24 FN\",\"N25 FN\",\"saturated in pred FN(%)\",\"saturated in GT FN(%)\"]+\\\n",
    "# [\"Step 0\",\"Step 25\",\"Step 50\",\"Step 75\",\"Step 100\",\"Step 125\",\"Step 150\",\"Step 175\",\"Step 200\",\"Step 225\",\"Step 250\",\"Step 275\",\"epoch 0\",\"epoch 1\",\"epoch 2\"]+\\\n",
    "# [\"epoch 3\",\"epoch 4\",\"epoch 5\",\"epoch 6\",\"epoch 7\"]\n",
    "\n",
    "columns_to_plot = [\"Step 0\",\"Step 25\",\"Step 50\",\"Step 75\",\"Step 100\",\"Step 125\",\"Step 150\",\"Step 175\",\"Step 200\",\"Step 225\",\"Step 250\",\"Step 275\",\"epoch 0\",\"epoch 1\",\"epoch 2\"]+\\\n",
    "[\"epoch 3\",\"epoch 4\",\"epoch 5\",\"epoch 6\",\"epoch 7\"]\n",
    "\n",
    "# Plotting the boxplot\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.boxplot(data=DF[columns_to_plot])\n",
    "plt.title('Boxplot of Selected Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9a28cb3-d30d-49fc-8f7d-7e6fd4899439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define groups of columns\n",
    "df= pd.DataFrame(columns=Cols[7394:])\n",
    "group1_columns = [\"N1 FN\",\"N11 FN\",\"N12 FN\",\"N13 FN\",\"N14 FN\",\"N15 FN\"]\n",
    "group2_columns = [\"N2 FN\",\"N21 FN\",\"N22 FN\",\"N23 FN\",\"N24 FN\",\"N25 FN\"]\n",
    "\n",
    "# Create a long-format DataFrame for seaborn\n",
    "group1_melted = results[group1_columns].melt(var_name='Columns', value_name='Values')\n",
    "group1_melted['Group'] = 'Group 1'\n",
    "\n",
    "group2_melted = results[group2_columns].melt(var_name='Columns', value_name='Values')\n",
    "group2_melted['Group'] = 'Group 2'\n",
    "\n",
    "# Combine the data\n",
    "melted_df = pd.concat([group1_melted, group2_melted])\n",
    "\n",
    "# Plotting the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Columns', y='Values', hue='Group', data=melted_df)\n",
    "plt.title('Comparaison of Two Groups of Columns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ec9099d-fee3-444f-9db5-64bd78110071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 5, 7]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP[40][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d0df8-f15c-41c9-8fbb-fdc74274c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    " if (i in [nb_batches-1] and (epoch%5==0)) or (i==0 and epoch==0):\n",
    "            \n",
    "            \n",
    "            #print(f\"Validating ... {loss_val}\")\n",
    "            for vect in [0,10,40,50,70]:\n",
    "                y_pred=torch.unsqueeze(output[0][vect], 0) \n",
    "                y =torch.unsqueeze(tg[vect], 0) \n",
    "\n",
    "                selected_row = cs_tr.df.iloc[int(U[vect][0]), 11:17]  \n",
    "                columns_with_one = selected_row[selected_row == 1].index.tolist()\n",
    "                activ=columns_with_one\n",
    "                epochCNN=cs_tr.df.loc[int(U[vect][0])]['epoch']\n",
    "\n",
    "\n",
    "                checkpoint=OrderedDict()\n",
    "                vector_aux= output[0][vect].detach()\n",
    "                y_pred=vector_aux.cpu()\n",
    "\n",
    "                task1=[int(x) for x in EXP[vect][0]]\n",
    "                task2=[int(x) for x in EXP[vect][1]]\n",
    "                task3=sorted(task1+task2)\n",
    "\n",
    "\n",
    "                All=list(range(10))\n",
    "                L2=[k for k in All if k not in task3] # Out of distribution classes\n",
    "                L_others=[k for k in All if k not in task3] #Classes to test on (In distribution)\n",
    "\n",
    "                checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(y_pred[0:200]).reshape([8, 1, 5, 5]))\n",
    "                checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(y_pred[200:208]).reshape([8]))\n",
    "\n",
    "                checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(y_pred[208:1408]).reshape([6, 8, 5, 5]))\n",
    "                checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(y_pred[1408:1414]).reshape([6]))\n",
    "\n",
    "                checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(y_pred[1414:1510]).reshape([4, 6, 2, 2]))\n",
    "                checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(y_pred[1510:1514]).reshape([4]))\n",
    "\n",
    "                checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(y_pred[1514:2234]).reshape([20,36]))\n",
    "                checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(y_pred[2234:2254]).reshape([20]))\n",
    "\n",
    "                checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(y_pred[2254:2454]).reshape([10,20]))\n",
    "                checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(y_pred[2454:2464]).reshape([10]))\n",
    "\n",
    "                Brain = CNN(1,activ[0],0,\"kaiming_uniform\")\n",
    "\n",
    "                model=copy.deepcopy(Brain)\n",
    "                model.load_state_dict(checkpoint)\n",
    "\n",
    "                criterion_CNN0=CrossEntropyLoss()\n",
    "\n",
    "                test_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnistDistilled/test/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Ts_DL0 = DataLoader(dataset=test_IF0, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "                _, valid_epoch_acc0,_= validate(model, Ts_DL0,  criterion_CNN0,10)\n",
    "                if len(task3)==10:\n",
    "                    valid_epoch_acc1=valid_epoch_acc0\n",
    "                    continue\n",
    "                else:\n",
    "                    criterion_CNN1=CrossEntropyLoss()\n",
    "                    test_IF1=ClassSpecificImageFolder( root=\"./data/SplitMnistDistilled/test/\",dropped_classes=[str(x) for x in task3],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                    Ts_DL1 = DataLoader(dataset=test_IF1, batch_size=120, num_workers=0, shuffle=False)\n",
    "\n",
    "                valid_epoch_loss0, valid_epoch_acc1,L_mx= validate(model, Ts_DL1,  criterion_CNN1,10)\n",
    "                cnn_acc_ID.append(valid_epoch_acc0)\n",
    "                cnn_acc_OOD.append(valid_epoch_acc1)\n",
    "                #lr = optimizer.param_groups[0][\"lr\"]\n",
    "                lrE1=optimizerEnc1.param_groups[0][\"lr\"]\n",
    "                lrE2=optimizerEnc2.param_groups[0][\"lr\"]\n",
    "                lrL=optimizerDense.param_groups[0][\"lr\"]\n",
    "                lrD=optimizerDec.param_groups[0][\"lr\"]\n",
    "                \n",
    "                \n",
    "                \n",
    "            #print(f\"Reconstructing ... {valid_epoch_acc0}\")\n",
    "                optimizerCNN = Adam(model.parameters(), lr=0.05)\n",
    "                schedulerCNN = torch.optim.lr_scheduler.CyclicLR(optimizerCNN ,base_lr=1e-3, max_lr=0.1, step_size_up=400, mode=\"triangular2\", cycle_momentum=False)\n",
    "                criterion_CNN=CrossEntropyLoss()\n",
    "                \n",
    "                \n",
    "                train_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnistDistilled/train/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Tr_DLr = DataLoader(dataset=train_IF0, batch_size=100, num_workers=0, shuffle=True)\n",
    "                \n",
    "                \n",
    "                wandb.define_metric(f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_loss train {task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_acc train{task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                \n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_loss test {task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                wandb.define_metric(f\"[{epoch}]CNN_fn_acc test{task1}{task2}{task3}\", step_metric=f\"finetune_step for epoch {epoch}\")\n",
    "                fine_tune_needed=0\n",
    "                #print(task1,task2,task3)\n",
    "                for epoch_cnn in range(15):\n",
    "                    \n",
    "                    # for param in model.parameters():\n",
    "                    #     print(f\"Param before step: {param.data[0]}\")\n",
    "                    #     break\n",
    "                    train_epoch_loss, train_epoch_acc,_ = train(model, Tr_DLr, optimizerCNN, criterion_CNN,10)\n",
    "                    valid_epoch_loss0FN, valid_epoch_acc0FN,_= validate(model, Ts_DL0,  criterion_CNN,10)\n",
    "                    schedulerCNN.step()\n",
    "                    # for param in model.parameters():\n",
    "                    #     print(f\"Param after step: {param.data[0]}\")\n",
    "                    #     break\n",
    "                    fine_tune_needed+=1\n",
    "                    #if fine_tune_needed%5==0:\n",
    "                        #print(f\"Accuracy of {train_epoch_acc:.2f} / ACC[vect][2] after {fine_tune_needed} epochs\")\n",
    "                    wandb.log({f\"[{epoch}]CNN_fn_loss train {task1}{task2}{task3}\":train_epoch_loss,f\"[{epoch}]CNN_fn_acc train {task1}{task2}{task3}\":train_epoch_acc , f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    wandb.log({f\"[{epoch}]CNN_fn_loss test {task1}{task2}{task3}\":valid_epoch_loss0FN,f\"[{epoch}]CNN_fn_acc test {task1}{task2}{task3}\":valid_epoch_acc0FN , f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    \n",
    "                          \n",
    "                    wandb.log({f\"[{epoch}]finetune ratio {task1}{task2}{task3}\":valid_epoch_acc0FN/ACC[vect][2], f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                    wandb.log({f\"combined target accuracy {task1}{task2}{task3}\":ACC[vect][2], f\"finetune_step for epoch {epoch}\": fine_tune_needed})\n",
    "                # define our custom x axis metric\n",
    "\n",
    "            \n",
    "        wandb.log({\"Loss\":loss_to_save})\n",
    "        wandb.log({\"CNN_IID_no_fine_tune\":(np.mean(cnn_acc_ID))})\n",
    "        wandb.log({\"CNN_OOD_no_fine_tune\":(np.mean(cnn_acc_OOD))})\n",
    "        wandb.log({\"lr Encoder 1\": lrE1,\"lr Encoder 2\": lrE2,\"lr Linear\": lrL,\"lr Decoder\": lrD})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddb1dd-7ba0-4d3a-b94a-132b7c9ac4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d678-66e0-4fdc-b4b3-11f1c42fca65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f9ea2-757f-4c08-a838-968f9b27d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "hm=sns.heatmap(torch.mean( torch.mean(output[4][-1], dim=1), dim=0).detach().cpu(), annot=False, cmap='cubehelix')\n",
    "plt.title('Attention Heatmap')\n",
    "\n",
    "heatmap_path = f'heatmap 1 _step_{0}.svg'\n",
    "plt.savefig(heatmap_path,format='svg', dpi=800)\n",
    "plt.close()\n",
    "\n",
    "#wandb.log({\"attention_heatmap 1\": wandb.Image(heatmap_path)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2949b-41d1-4cb9-90e5-ec389c2e6e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38362539-dd58-4e3c-925e-f313b21e4819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54092b-8cfd-4691-a8f9-caa1b00eb39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7993d-f994-485c-9169-827e94211812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbfa86-331e-4c39-92f4-e35133be58bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699aba2-6928-4425-b344-ad810f9fc144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4966281-ab38-4bac-aaef-98d1ff59e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df29ecd-9235-45f4-951a-ecfe9cc1a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616cff7-b29e-4984-9dc5-f8b13aec2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73672723-0e7f-42b2-8c86-1dad689519f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa23f52-93fa-410f-918e-d9da64b9145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/memory-management-using-pytorch-cuda-alloc-conf/157850\n",
    "#https://stackoverflow.com/questions/73747731/runtimeerror-cuda-out-of-memory-how-can-i-set-max-split-size-mb\n",
    "\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
