{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c",
   "metadata": {
    "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "import random\n",
    "import ast\n",
    "        \n",
    "\n",
    "import torch.nn.functional as F\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation ,FFMpegWriter ,PillowWriter\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os \n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c973ef-a1c2-4c67-88f5-5c2cdc634f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: wandb in /home/crns/anaconda3/lib/python3.9/site-packages (0.14.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (1.19.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (4.8.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/crns/anaconda3/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/crns/anaconda3/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/crns/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crns/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/crns/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crns/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/crns/anaconda3/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceed1bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maymentlili\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/crns/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"ab631efc36e2c87f5f54d82b5cdbd6c501d5221f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd06b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
    "outputId": "9229fdc7-630d-4e87-d54b-3771391ef44c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "random.seed(881)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a1e1f6-dcf6-4c01-b2c3-ab25ee771a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Double_input_transformer import CustomDataset,TransformerAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655000ba-32ed-41d3-93a3-522336521239",
   "metadata": {
    "id": "655000ba-32ed-41d3-93a3-522336521239"
   },
   "source": [
    "# Trainloader code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2e5630-1312-47db-b6b1-1646cb9eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the list\n",
    "train_pair = np.load('train_pair_seed881.npy', allow_pickle=True)\n",
    "test_pair = np.load('test_pair_seed881.npy', allow_pickle=True)\n",
    "val_pair = np.load('val_pair_seed881.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96f0b1d-6532-48da-9cfb-44a1fe16465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10]]\n"
     ]
    }
   ],
   "source": [
    "def batchify(lst, batch_size):\n",
    "    return [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]\n",
    "\n",
    "# Example usage:\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "batch_size = 4\n",
    "batches = batchify(my_list, batch_size)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d535da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_tr=CustomDataset(train_pair,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c1f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset,EXP,ACC,U = cs_tr[0]\n",
    "x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4e714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2464])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0930913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2",
   "metadata": {
    "id": "f045b5b9-750a-4236-b6d4-3cea89fdf1a2"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387b2953-3794-42d9-a327-5e7cca27939d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387b2953-3794-42d9-a327-5e7cca27939d",
    "outputId": "29fef800-a2d7-43d4-dafb-9fa69bda52ca"
   },
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b",
   "metadata": {
    "id": "f4e1b3c7-eae9-472b-8d5e-2fcade409e9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30",
   "metadata": {
    "id": "8f7cb2ca-7fee-4e0e-ad6a-bfbd880f1d30"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72",
   "metadata": {
    "id": "6e4cd349-fa4c-42c1-8330-6c8b77c63f72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a",
   "metadata": {
    "id": "f3bbd0b1-6ed0-4c53-9762-6e323034719a"
   },
   "outputs": [],
   "source": [
    "class EmbedderNeuronGroup(nn.Module):\n",
    "    def __init__(self, d_model, seed=22):\n",
    "        super().__init__()\n",
    "        #print(\"EmbedderNeuroneGroup\")\n",
    "        self.neuron_l1 = nn.Linear(200, d_model) #8\n",
    "        self.neuron_l2 = nn.Linear(72, d_model) #12\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.multiLinear(x)\n",
    "\n",
    "    def multiLinear(self, v):\n",
    "        #print(\"multi-linear method\",v.shape)\n",
    "\n",
    "        l = []\n",
    "\n",
    "        for ndx in range(8):\n",
    "            idx_start = ndx * 200\n",
    "            idx_end = idx_start + 200\n",
    "            l.append(self.neuron_l1(v[:,idx_start:idx_end]))\n",
    "\n",
    "        # l2\n",
    "        for ndx in range(12):\n",
    "            idx_start = 200*8 + ndx * 72\n",
    "            idx_end = idx_start + 72\n",
    "            l.append(self.neuron_l2(v[:,idx_start:idx_end]))\n",
    "        #print(len(l))\n",
    "        #print(len(l[0]))\n",
    "        final = torch.stack(l, dim=1)\n",
    "\n",
    "        # print(final.shape)\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2",
   "metadata": {
    "id": "fdbc54b7-041c-4dbc-a3cc-c22554a8c8f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f",
   "metadata": {
    "id": "56c1a547-55ed-45b9-9b9b-6a3c9a5d2f6f"
   },
   "outputs": [],
   "source": [
    "# max_seq_len=176,\n",
    "# N=4\n",
    "# heads=3\n",
    "# d_model=900\n",
    "# d_ff=900\n",
    "# neck=700\n",
    "# dropout=0.1\n",
    "# # Enc=EncoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff)\n",
    "# # vec1 = torch.rand(1,2464)\n",
    "# # res,scores=Enc(vec1)\n",
    "# # res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad",
   "metadata": {
    "id": "05d1616a-7a25-4af5-bc73-e64a0612d0ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278",
   "metadata": {
    "id": "a844bdf8-de0a-4fb1-8d6e-bbbcd841b278"
   },
   "outputs": [],
   "source": [
    "# vec2neck = nn.Linear(d_ff*2, neck)\n",
    "# print(res.shape)\n",
    "# out3=torch.cat([res,res], dim=2)\n",
    "# print(\"neck input:\",out3.shape)\n",
    "# sum_r=torch.sum(out3, dim=1, keepdim=False)\n",
    "# vec2=vec2neck(sum_r)\n",
    "# print(len(vec2))\n",
    "# tanh = nn.Tanh()\n",
    "# neck_t=tanh(vec2)\n",
    "# print(\"neck shape:\",neck_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac",
   "metadata": {
    "id": "5db4a2a5-8711-4948-8b8a-7e298d4502ac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4",
   "metadata": {
    "id": "4150e43a-f20a-4606-b1a8-5fb75ea2e1f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa74a80-dee8-4710-a221-a448b37758d1",
   "metadata": {
    "id": "efa74a80-dee8-4710-a221-a448b37758d1"
   },
   "outputs": [],
   "source": [
    "# Dec=DecoderNeuronGroup(d_model=d_model, N=N, heads=heads, max_seq_len=max_seq_len, dropout=dropout,d_ff=d_ff,neck=neck)\n",
    "# res,scores=Dec(neck_t)\n",
    "# res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf",
   "metadata": {
    "id": "da48474d-d348-4b5f-bdfb-3edabe5d46cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5",
   "metadata": {
    "id": "ddb5c635-1abd-40e5-a4c3-70ac38d69bf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d",
   "metadata": {
    "id": "2198b3a0-4243-4028-a1d1-c2992c56ab3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65",
   "metadata": {
    "id": "51fad956-1f6d-487c-a3a9-1003e7e55b65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8ef6a42-2b3e-4fc8-babe-2d6f6ff37500",
    "outputId": "7301efd4-e73d-46ce-baa8-b3b12a63c900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159516, 595620, 88560)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pair),len(train_pair),len(val_pair)#,len(test_tgt),len(train_tgt),len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649",
   "metadata": {
    "id": "5b6e843a-7f62-4bdb-bfe2-c55960b6b649"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619486cb-4a43-408f-976c-74c7d6a840d9",
   "metadata": {
    "id": "619486cb-4a43-408f-976c-74c7d6a840d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f35825-6623-41d4-9747-5e6c1d657c65",
    "outputId": "9429472d-98a4-47db-c47e-af78aadfba49"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(mod\u001b[39m.\u001b[39mnumParams())\n\u001b[1;32m      2\u001b[0m x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m,\u001b[39m2464\u001b[39m)\n\u001b[1;32m      3\u001b[0m x2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m,\u001b[39m2464\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(mod.numParams())\n",
    "x1 = torch.rand(1,2464)\n",
    "x2 = torch.rand(1,2464)\n",
    "mod=mod.to(device).to(torch.float32)\n",
    "\n",
    "#x1=x1.to(torch.float32)\n",
    "#x2=x2.to(torch.float32)\n",
    "x1=x1.to(device)\n",
    "x2=x2.to(device)\n",
    "mod=mod.to(device)\n",
    "out = mod(x1,x2)\n",
    "print(\"Output Shape: \", out[0].shape)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1e0eefd-9bb1-4f3e-b722-78f4108efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "class ClassSpecificImageFolder(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dropped_classes=[],\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        self.dropped_classes = dropped_classes\n",
    "        super(ClassSpecificImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                                       transform=transform,\n",
    "                                                       target_transform=target_transform,\n",
    "                                                       is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        classes = [c for c in classes if c not in self.dropped_classes]\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "#from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.0,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init module list\n",
    "        self.module_list = nn.ModuleList()\n",
    "        ### ASSUMES 28x28 image size\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(nn.Conv2d(channels_in, 8, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(nn.Conv2d(8, 6, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(nn.Conv2d(6, 4, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                # set bias to some small non-zero value\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "                or isinstance(layer, ORU)\n",
    "                or isinstance(layer, ERU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "def train(model, trainloader, optimizer, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.train()\n",
    "    #print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "        #List_mx.append(mx)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            if data is None:  # Skip None values\n",
    "                continue\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image\n",
    "            labels = labels\n",
    "            # forward pass\n",
    "            outputs = model(image.to(torch.float32))\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            #mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "            #List_mx.append(mx)\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "def create_frame(step,ax,data):\n",
    "    ax=ax.cla()\n",
    "    sns.heatmap(data[step][-1].cpu(),annot=True,cmap=\"cubehelix\",ax=ax,cbar=False)\n",
    "    plt.title('Epoch {} training {}'.format(step,exp)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c",
   "metadata": {
    "id": "b5cf2e31-6295-42f1-9d0e-284ad545f94c"
   },
   "outputs": [],
   "source": [
    "#L_activations=[\"gelu\",\"relu\",\"silu\",\"leakyrelu\",\"sigmoid\",\"tanh\"]\n",
    "#csv_files,L_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c657276f-7578-45a1-a58b-db8a21914d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4874)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2) in https://arxiv.org/pdf/2209.14733.pdf\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "class LWLN_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWLN_loss, self).__init__()\n",
    "    def forward(self, vec1,vec2):\n",
    "        loss = (torch.mean((vec1[:,0:208]-vec2[:,0:208])**2)/vec2[:,0:208].std() + \n",
    "                 torch.mean((vec1[:,208:1414]-vec2[:,208:1414])**2)/vec2[:,208:1414].std()+ \n",
    "                 torch.mean((vec1[:,1414:1514]-vec2[:,1414:1514])**2)/vec2[:,1414:1514].std()+\n",
    "                 torch.mean((vec1[:,1514:2254]-vec2[:,1514:2254])**2)/vec2[:,1514:2254].std()+\n",
    "                 torch.mean((vec1[:,2254:2464]-vec2[:,2254:2464])**2)/vec2[:,2254:2464].std())/(6)\n",
    "        \n",
    "        return loss\n",
    "LW=LWLN_loss()\n",
    "LW(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48684b12-575d-4354-84ed-04ce490df41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label task 1</th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy task1</th>\n",
       "      <th>label task 2</th>\n",
       "      <th>Accuracy task2</th>\n",
       "      <th>weight 0</th>\n",
       "      <th>weight 1</th>\n",
       "      <th>weight 2</th>\n",
       "      <th>weight 3</th>\n",
       "      <th>weight 4</th>\n",
       "      <th>...</th>\n",
       "      <th>bias 2462</th>\n",
       "      <th>bias 2463</th>\n",
       "      <th>Loader Set</th>\n",
       "      <th>Reconstructed Accuracy ID</th>\n",
       "      <th>Actual Accuracy</th>\n",
       "      <th>Reconstructed Accuracy OOD</th>\n",
       "      <th>Transformer Loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochCNN</th>\n",
       "      <th>ActivationCNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label task 1, index, Accuracy task1, label task 2, Accuracy task2, weight 0, weight 1, weight 2, weight 3, weight 4, weight 5, weight 6, weight 7, weight 8, weight 9, weight 10, weight 11, weight 12, weight 13, weight 14, weight 15, weight 16, weight 17, weight 18, weight 19, weight 20, weight 21, weight 22, weight 23, weight 24, weight 25, weight 26, weight 27, weight 28, weight 29, weight 30, weight 31, weight 32, weight 33, weight 34, weight 35, weight 36, weight 37, weight 38, weight 39, weight 40, weight 41, weight 42, weight 43, weight 44, weight 45, weight 46, weight 47, weight 48, weight 49, weight 50, weight 51, weight 52, weight 53, weight 54, weight 55, weight 56, weight 57, weight 58, weight 59, weight 60, weight 61, weight 62, weight 63, weight 64, weight 65, weight 66, weight 67, weight 68, weight 69, weight 70, weight 71, weight 72, weight 73, weight 74, weight 75, weight 76, weight 77, weight 78, weight 79, weight 80, weight 81, weight 82, weight 83, weight 84, weight 85, weight 86, weight 87, weight 88, weight 89, weight 90, weight 91, weight 92, weight 93, weight 94, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2477 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cols=[\"label task 1\",\"index\",\"Accuracy task1\",\\\n",
    "      \"label task 2\",\"Accuracy task2\"]+ \\\n",
    "[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+ \\\n",
    "[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+ \\\n",
    "[\"Loader Set\",\"Reconstructed Accuracy ID\",\"Actual Accuracy\",\"Reconstructed Accuracy OOD\",\"Transformer Loss\",\"lr\",'epochCNN','ActivationCNN'] \n",
    "\n",
    "print(len(Cols))\n",
    "predicted_Weights= pd.DataFrame(columns=Cols)\n",
    "\n",
    "# row=[\"\".format(task1),int(ind[0]),ACC[0],\"\".format(task2),ACC[1]]+vector_aux.to_list()+[\"train\",valid_epoch_acc0,ACC[2],valid_epoch_acc1,L_train[-1]]\n",
    "# predicted_Weights.append(row, ignore_index=True)\n",
    "predicted_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec127-29d7-4d8a-b935-5d0f1dbcb2e5",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd60539-fb7e-4145-a4cb-8183f9f31f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)\n",
    "def scheduler_to(sched, device):\n",
    "    for param in sched.__dict__.values():\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e960c79-58b9-4f1d-93df-cbccebb9a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-31 12:28:04.942861\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb7763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def loss_Contractive(W, x, recons_x, h, lam):\n",
    "    dh = h * (1 - h) \n",
    "\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    " \n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "\n",
    "    return contractive_loss.mul_(lam)\n",
    "\n",
    "vec1 = torch.rand(1,2464)\n",
    "vec2 = torch.rand(1,2464)\n",
    "#print(out[1].shape,W.shape)\n",
    "# for name, param in mod.named_parameters():\n",
    "#     if name == 'vec2neck.weight':\n",
    "#         W = param\n",
    "#         break\n",
    "# CL=loss_Contractive(W,vec1,vec2, out[1], 0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a86db2-b453-4c47-86b9-77ea21619679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    head=trial.suggest_int(\"heads\",3,4)\n",
    "    #d_model=trial.suggest_int(\"d_model\",200,1200)\n",
    "    neck=trial.suggest_int(\"neck\",400,700)\n",
    "    p=trial.suggest_float(\"dropout\",0,0.2)\n",
    "    mod = TransformerAE(max_seq_len=20,\n",
    "                        N=4,\n",
    "                        heads=head,\n",
    "                        d_model=1200,\n",
    "                        d_ff=1200,\n",
    "                        neck=neck,\n",
    "                        dropout=p\n",
    "                       )\n",
    "    print( \"model params: \",head,neck,p)\n",
    "    return mod,head,neck,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3901085-aa0a-415d-b9a0-a8f4f2d82488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off optuna log notes.\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(\n",
    "            \"Trial {} finished with best value: {} and parameters: {}. \".format(\n",
    "            frozen_trial.number,\n",
    "            frozen_trial.value,\n",
    "            frozen_trial.params,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
    "outputId": "02799af4-014c-4dab-ec46-33d719329174",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder droupout init 0.07368838248330072\n",
      "encoder droupout init 0.07368838248330072\n",
      "decoder droupout init 0.07368838248330072\n",
      "model params:  3 671 0.07368838248330072\n",
      "0.065639525865769 ReduceLROnPlateau 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/crns/Documents/GitHub/Federated-Continual-learning-/New/wandb/run-20240531_123133-j1mdwvza</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aymentlili/aymen-project/runs/j1mdwvza' target=\"_blank\">eternal-sun-28</a></strong> to <a href='https://wandb.ai/aymentlili/aymen-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aymentlili/aymen-project' target=\"_blank\">https://wandb.ai/aymentlili/aymen-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aymentlili/aymen-project/runs/j1mdwvza' target=\"_blank\">https://wandb.ai/aymentlili/aymen-project/runs/j1mdwvza</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9606/9606 [1:53:38<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:28<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:14<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:52:59<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:04<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:52:55<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:02<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:52:56<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:04<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:03<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:52:59<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:05<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:05<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:04<00:00,  1.42it/s]\n",
      "100%|██████████| 9606/9606 [1:53:14<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:28<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:31<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:30<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:28<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:28<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:32<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:29<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:26<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:12<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:21<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:22<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:30<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:26<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:27<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:28<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:30<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:27<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:27<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:18<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:35<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:29<00:00,  1.41it/s]\n",
      "100%|██████████| 9606/9606 [1:53:35<00:00,  1.41it/s]\n",
      "  1%|          | 89/9606 [01:03<1:52:15,  1.41it/s]wandb: Network error (SSLError), entering retry loop.\n",
      "100%|██████████| 9606/9606 [1:56:30<00:00,  1.37it/s]  \n",
      "100%|██████████| 9606/9606 [1:57:23<00:00,  1.36it/s]  \n",
      "100%|██████████| 9606/9606 [1:56:49<00:00,  1.37it/s]  \n",
      "100%|██████████| 9606/9606 [1:55:20<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:19<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:06<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:07<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:11<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:11<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:07<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:14<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:18<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:59<00:00,  1.38it/s]\n",
      "100%|██████████| 9606/9606 [1:59:03<00:00,  1.34it/s]  \n",
      "100%|██████████| 9606/9606 [1:55:32<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:55:22<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:54:33<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:35<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:38<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:33<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:38<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:36<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:43<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:35<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:55:12<00:00,  1.39it/s]\n",
      "100%|██████████| 9606/9606 [1:56:05<00:00,  1.38it/s]  \n",
      "100%|██████████| 9606/9606 [1:54:17<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:53:59<00:00,  1.40it/s]\n",
      "100%|██████████| 9606/9606 [1:54:56<00:00,  1.39it/s]\n",
      " 10%|▉         | 919/9606 [11:04<1:44:38,  1.38it/s]\n",
      "[W 2024-06-05 18:21:03,347] Trial 0 failed with parameters: {'heads': 3, 'neck': 671, 'dropout': 0.07368838248330072, 'Learning_rate': 0.065639525865769, 'scheduler': 'ReduceLROnPlateau', 'batch_size': 62} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5730/2048697243.py\", line 70, in objective\n",
      "    Dataset,EXP,ACC,U = cs_tr[i]\n",
      "  File \"/home/crns/Documents/GitHub/Federated-Continual-learning-/New/Double_input_transformer.py\", line 89, in __getitem__\n",
      "    rowk=self.df[(self.df[\"label\"]=='{}'.format(batch[i][1]))&(self.df[\"epoch\"]==int(self.D_epoch[str(batch[i][2])]))&(self.df[self.D_activ[str(batch[i][3])]]==float(1))]\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\", line 70, in new_method\n",
      "    return method(self, other)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\", line 40, in __eq__\n",
      "    return self._cmp_method(other, operator.eq)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\", line 5623, in _cmp_method\n",
      "    res_values = ops.comparison_op(lvalues, rvalues, op)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\", line 286, in comparison_op\n",
      "    res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=True)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\", line 163, in _na_arithmetic_op\n",
      "    result = func(left, right)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\", line 239, in evaluate\n",
      "    return _evaluate(op, op_str, a, b)  # type: ignore[misc]\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\", line 128, in _evaluate_numexpr\n",
      "    result = _evaluate_standard(op, op_str, a, b)\n",
      "  File \"/home/crns/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\", line 69, in _evaluate_standard\n",
      "    return op(a, b)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-05 18:21:03,389] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5730/2048697243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_tr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5730/2048697243.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEXP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcs_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Federated-Continual-learning-/New/Double_input_transformer.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mrowk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_activ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mL_Stream2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mind2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5622\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5623\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv \n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "results_path=\"./Contractive model/\"\n",
    "\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "\n",
    "storage = JournalStorage(JournalFileStorage(\"optuna-journal.log\"))\n",
    "def objective(trial):\n",
    "    track=0\n",
    "    step_size=0\n",
    "    mod,head,neck,p=define_model(trial)\n",
    "    \n",
    "    lr=trial.suggest_float(\"Learning_rate\",0.0001,0.1)\n",
    "    optimizer = Adam(mod.parameters(), lr=lr)\n",
    "    sched_name=trial.suggest_categorical(\"scheduler\",[\"CyclicLR\",\"ReduceLROnPlateau\"])\n",
    "    if sched_name==\"CyclicLR\" :\n",
    "        step_size=trial.suggest_int(\"step_size_up\",200,3400)\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.1, step_size_up=step_size, mode=\"triangular2\", cycle_momentum=False)\n",
    "    if sched_name==\"ReduceLROnPlateau\" :\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "    \n",
    "    \n",
    "    batch_size=trial.suggest_int(\"batch_size\",20,200)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    #LW=LWLN_loss()\n",
    "    \n",
    "    num_epochs=400\n",
    "    print(lr,sched_name,batch_size)\n",
    "    run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"aymen-project\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"head\": head,\n",
    "        \"neck\": neck,\n",
    "        \"p\": p,\n",
    "        \"sched_name\": sched_name,\n",
    "        \"step_size\": step_size,\n",
    "        \"batch_size\": batch_size\n",
    "    },\n",
    ")\n",
    "    \n",
    "    cs_tr=CustomDataset(train_pair,batch_size=batch_size)\n",
    "    nb_batches = len(cs_tr)//batch_size\n",
    "\n",
    "    optimizer_to(optimizer,device)\n",
    "    scheduler_to(scheduler,device)\n",
    "    mod.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time_epoch = time.time()\n",
    "        for i in tqdm(range(nb_batches)):\n",
    "            #start_time_batch = time.time()\n",
    "            loss_tr=torch.tensor(0.0, device=device)\n",
    "            if i%50==0:\n",
    "                for name, param in mod.named_parameters():\n",
    "                    if name == 'vec2neck.weight':\n",
    "                        W = param\n",
    "                        break\n",
    "            Dataset,EXP,ACC,U = cs_tr[i]\n",
    "            x1,x2,tg = Dataset[:,0,:], Dataset[:,1,:],Dataset[:,2,:]\n",
    "            try:\n",
    "                x1=x1.to(torch.float32)\n",
    "                x2=x2.to(torch.float32)\n",
    "                tg=tg.to(torch.float32)\n",
    "\n",
    "                x1=x1.to(device)\n",
    "                x2=x2.to(device)\n",
    "                tg=tg.to(device)\n",
    "                mod=mod.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = mod(x1,x2)\n",
    "\n",
    "                loss_tr = criterion(output[0],tg)+loss_Contractive(W,vec1,vec2, output[1], 0.005)\n",
    "                wandb.watch(model, loss_tr, log=\"all\", log_freq=100)\n",
    "            except Exception as e:\n",
    "                # Print the exception\n",
    "                print(\"An exception occurred:\", e)\n",
    "                traceback.print_exc()\n",
    "                # Continue with the loop\n",
    "                continue\n",
    "\n",
    "            #loss_tr=loss_tr.detach()\n",
    "            #loss_tr.requires_grad=True\n",
    "            loss_tr.backward()\n",
    "            optimizer.step()\n",
    "            if sched_name==\"ReduceLROnPlateau\" :\n",
    "                scheduler.step(loss_tr)\n",
    "            else:\n",
    "                 scheduler.step()\n",
    "\n",
    "            #end_time_batch = time.time()\n",
    "            #execution_time = end_time_batch - start_time_batch\n",
    "            #print(\"Batch Execution time:\", execution_time, \"seconds\")\n",
    "            torch.cuda.empty_cache()\n",
    "            loss_to_save = float(loss_tr.detach().cpu().item())\n",
    "            wandb.log({\"loss\":loss_to_save})\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "        if epoch%50==0:\n",
    "            track=+1\n",
    "            torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'Batch Loss':loss_tr.detach().cpu().item()},results_path+'AE epoch {} {}.pth'.format(epoch,track))\n",
    "    wandb.finish()\n",
    "    return loss_tr\n",
    "study= optuna.create_study(direction=\"minimize\",storage=storage)\n",
    "study.optimize(objective,n_trials=10,callbacks=[lambda study, trial: gc.collect()]+[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d206787-c1b6-41a6-abf0-05e4f2c702cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5730/4155904332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddb1dd-7ba0-4d3a-b94a-132b7c9ac4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d678-66e0-4fdc-b4b3-11f1c42fca65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f9ea2-757f-4c08-a838-968f9b27d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2949b-41d1-4cb9-90e5-ec389c2e6e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38362539-dd58-4e3c-925e-f313b21e4819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54092b-8cfd-4691-a8f9-caa1b00eb39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7993d-f994-485c-9169-827e94211812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbfa86-331e-4c39-92f4-e35133be58bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699aba2-6928-4425-b344-ad810f9fc144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4966281-ab38-4bac-aaef-98d1ff59e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df29ecd-9235-45f4-951a-ecfe9cc1a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch%30==0 or (epoch in [1,3,5,10]):\n",
    "        for vect in tqdm(range(len(x1))):\n",
    "            y_pred=torch.unsqueeze(output[0][vect], 0) \n",
    "            y =torch.unsqueeze(tg[vect], 0) \n",
    "            \n",
    "            selected_row = cs_tr.df.iloc[int(U[vect][0]), 11:17]  \n",
    "            columns_with_one = selected_row[selected_row == 1].index.tolist()\n",
    "            activ=columns_with_one\n",
    "            epochCNN=cs_tr.df.loc[int(U[vect][0])]['epoch']\n",
    "            \n",
    "            \n",
    "            checkpoint=OrderedDict()\n",
    "            vector_aux= output[0][vect].detach()\n",
    "            y_pred=vector_aux.cpu()\n",
    "\n",
    "            task1=[int(x) for x in EXP[vect][0]]\n",
    "            task2=[int(x) for x in EXP[vect][1]]\n",
    "            task3=sorted(task1+task2)\n",
    "\n",
    "\n",
    "            All=list(range(10))\n",
    "            L2=[k for k in All if k not in task3] #Classes to test on (In distribution)\n",
    "            L_others=[k for k in All if k not in task3] # Out of distribution classes\n",
    "\n",
    "            checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(y_pred[0:200]).reshape([8, 1, 5, 5]))\n",
    "            checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(y_pred[200:208]).reshape([8]))\n",
    "\n",
    "            checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(y_pred[208:1408]).reshape([6, 8, 5, 5]))\n",
    "            checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(y_pred[1408:1414]).reshape([6]))\n",
    "\n",
    "            checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(y_pred[1414:1510]).reshape([4, 6, 2, 2]))\n",
    "            checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(y_pred[1510:1514]).reshape([4]))\n",
    "\n",
    "            checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(y_pred[1514:2234]).reshape([20,36]))\n",
    "            checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(y_pred[2234:2254]).reshape([20]))\n",
    "\n",
    "            checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(y_pred[2254:2454]).reshape([10,20]))\n",
    "            checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(y_pred[2454:2464]).reshape([10]))\n",
    "\n",
    "            Brain = CNN(1,activ[0],0,\"kaiming_uniform\")\n",
    "\n",
    "            model=copy.deepcopy(Brain).to(torch.float32)\n",
    "            model.load_state_dict(checkpoint)\n",
    "\n",
    "            criterion_CNN0=CrossEntropyLoss()\n",
    "\n",
    "            test_IF0=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in L2],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "            Ts_DL0 = DataLoader(dataset=test_IF0, batch_size=400, num_workers=0, shuffle=True)\n",
    "            \n",
    "            _, valid_epoch_acc0,_= validate(model, Ts_DL0,  criterion_CNN0,10)\n",
    "            if len(task3)==10:\n",
    "                valid_epoch_acc1=valid_epoch_acc0\n",
    "                continue\n",
    "            else:\n",
    "                criterion_CNN1=CrossEntropyLoss()\n",
    "                test_IF1=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=[str(x) for x in task3],transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "                Ts_DL1 = DataLoader(dataset=test_IF1, batch_size=400, num_workers=0, shuffle=True)\n",
    "            \n",
    "            valid_epoch_loss0, valid_epoch_acc1,L_mx= validate(model, Ts_DL1,  criterion_CNN1,10)\n",
    "\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            \n",
    "            \n",
    "            vectstring=f\"{y_pred.tolist()}\".replace(\" \", \"\")[1:-1].split(',')\n",
    "            row_part=f\"{task1};{int(U[vect][0])};{float(ACC[vect][0])};{task2};{float(ACC[vect][1])}\".split(\";\")\n",
    "            row_part2=f\"train,{valid_epoch_acc0},{float(ACC[vect][2])},{valid_epoch_acc1},{float(loss_tr.detach().cpu())},{lr},{epochCNN},{activ[0]}\".split(\",\")\n",
    "            row=row_part+vectstring+row_part2\n",
    "            \n",
    "            temp_file = os.path.join(results_path,f'AE Tracking {track}.csv')\n",
    "        \n",
    "            if vect%150==0:\n",
    "                print(task3,len(Ts_DL0.dataset))\n",
    "                print(L2,len(Ts_DL1.dataset))\n",
    "                print(\"epoch\" ,epoch, \"\\t\", \"\\t batch: \",f\"/{len(Dataset)}\",f\"\\t Learning rate :\" ,f\"{lr:.8f}\")\n",
    "                temp_file = os.path.join(results_path, f'AE Tracking {track}.csv')\n",
    "                with open(temp_file, mode='a', newline='\\n') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(Cols)\n",
    "                \n",
    "            with open(temp_file, mode='a', newline='\\n') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(row)\n",
    "            if vect%150==0:\n",
    "                track += 1\n",
    "\n",
    "        csv_files = [file for file in os.listdir(results_path) if file.endswith(\".csv\")]\n",
    "        csv_files.sort(key=lambda x: int(x.split(\" \")[2][:-4]))\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(results_path, \"AE Tracking 0.csv\"),header=[0])\n",
    "        res= pd.DataFrame(columns=df.columns)\n",
    "        for file in csv_files:\n",
    "            df = pd.read_csv(os.path.join(results_path, file), header=[0])\n",
    "            res = res.append(df, ignore_index=True)\n",
    "        print(\"epoch\",epoch,'\\n','worst_CNN_ACC \\t',  float(min(res[[\"Reconstructed Accuracy ID\"]].values)),'\\n','best_CNN_ACC \\t',float(max(res[[\"Reconstructed Accuracy ID\"]].values)),'\\n','max_Transformer_loss \\t',float(max(res[[\"Transformer Loss\"]].values)),'\\n','min_CNN_ACC \\t',float(min(res[[\"Transformer Loss\"]].values)))\n",
    "                torch.save({'epoch':epoch,'model_state_dict': mod.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'Batch Loss':loss_tr.detach().cpu().item(),'last_batch_CNN_ACC':valid_epoch_acc0,'worst_CNN_ACC':  float(min(res[[\"Reconstructed Accuracy ID\"]].values)),'best_CNN_ACC':float(max(res[[\"Reconstructed Accuracy ID\"]].values)),'max_Transformer_loss':float(max(res[[\"Transformer Loss\"]].values)),'min_CNN_ACC':float(min(res[[\"Transformer Loss\"]].values))},results_path+'AE epoch {}.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616cff7-b29e-4984-9dc5-f8b13aec2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73672723-0e7f-42b2-8c86-1dad689519f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfa23f52-93fa-410f-918e-d9da64b9145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           EXP: 488.2 KiB\n",
      "                           ACC: 488.2 KiB\n",
      "                             U: 488.2 KiB\n",
      "                     Pairs_exp: 190.1 KiB\n",
      "                    train_pair: 133.4 KiB\n",
      "                     train_tgt: 133.4 KiB\n",
      "                     test_pair: 36.3 KiB\n",
      "                      test_tgt: 36.3 KiB\n",
      "                    vectstring: 20.1 KiB\n",
      "                      val_pair: 20.1 KiB\n"
     ]
    }
   ],
   "source": [
    "#https://discuss.pytorch.org/t/memory-management-using-pytorch-cuda-alloc-conf/157850\n",
    "#https://stackoverflow.com/questions/73747731/runtimeerror-cuda-out-of-memory-how-can-i-set-max-split-size-mb\n",
    "\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
