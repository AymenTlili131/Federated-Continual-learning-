{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77eb910c-dcef-4911-af76-79db919f0ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Collecting torch==1.11\n",
      "  Downloading torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:10\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/crns/anaconda3/lib/python3.9/site-packages (from torch==1.11) (4.9.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1\n",
      "    Uninstalling torch-1.9.1:\n",
      "      Successfully uninstalled torch-1.9.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.1 requires torch==1.9.1, but you have torch 1.11.0 which is incompatible.\n",
      "torchtext 0.10.1 requires torch==1.9.1, but you have torch 1.11.0 which is incompatible.\n",
      "torchdata 0.5.1 requires torch==1.13.1, but you have torch 1.11.0 which is incompatible.\n",
      "torchaudio 0.9.1 requires torch==1.9.1, but you have torch 1.11.0 which is incompatible.\n",
      "pytorch-lightning 2.1.2 requires torch>=1.12.0, but you have torch 1.11.0 which is incompatible.\n",
      "neurips-2022-generative-hyper-representations 0.0.post1.dev11+g7707bb6.d20230411 requires ray>=1.13.0, but you have ray 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install avalanche-lib==0.3.1\n",
    "#!pip install torcheval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67987ec9-75b3-44c6-b850-c5d1d4451b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.benchmarks.generators import dataset_benchmark\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation ,FFMpegWriter ,PillowWriter\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962115d-2eff-47cf-a980-13285f8443c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eadc6-44b5-40f0-b1ba-64ba8e6f4d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951af27-2afa-4e01-b81e-7b4b88752c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8323c49d-240a-4e46-98ec-c00e2e783a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9a283b-6c51-47f1-93e2-c4e79ea40478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_mnist = SplitMNIST(n_experiences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926a8e77-fdc8-4f4e-8bc6-7c70bc816d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in split_mnist.train_stream[0].dataset:\\n    print(i[0].shape)\\n    print(i[1])\\n    break\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in split_mnist.train_stream[0].dataset:\n",
    "    print(i[0].shape)\n",
    "    print(i[1])\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f92739-ad6c-4d5e-a3f1-6d74e19d8996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split_mnist.train_stream[0].dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cabfe5e-9a5d-4ed7-9343-e7cfe1b46328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3e3b5a0e20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.imshow(split_mnist.train_stream[0].dataset[0][0].numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4eecbbd-0b3e-4800-8e82-dc28bbc6e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(split_mnist.train_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b5f67-c020-4e1b-8e76-626d9e73039b",
   "metadata": {},
   "source": [
    "### Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617917ce-6b6c-4cf0-b2e8-4edcaa6f55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    if not(os.path.isdir(\".//data//SplitMnist//train//\")):\n",
    "        os.mkdir(\".//data//SplitMnist//train//\")\n",
    "    if not(os.path.isdir(\".//data//SplitMnist//train//{}\".format(k))):\n",
    "        os.mkdir(\".//data//SplitMnist//train//{}\".format(k))\n",
    "    if not(os.path.isdir(\".//data//SplitMnist//test//\")):\n",
    "        os.mkdir(\".//data//SplitMnist//test//\")\n",
    "    if not(os.path.isdir(\".//data//SplitMnist//test//{}\".format(k))):\n",
    "        os.mkdir(\".//data//SplitMnist//test//{}\".format(k))\n",
    "for i in tqdm(range(len(split_mnist.train_stream))):\n",
    "    for j in range(len(split_mnist.train_stream[i].dataset)):\n",
    "        save_image(split_mnist.train_stream[i].dataset[j][0], \".//data//SplitMnist//train//{}//{}.png\".format(split_mnist.train_stream[i].dataset[j][1],j))\n",
    "    #print(\"fold {}//{}//{}.png saved\".format(j,L_labels1[img_idx],test_index[img_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a4607-d214-42be-91f5-70abb19441fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(split_mnist.test_stream))):\n",
    "    for j in range(len(split_mnist.test_stream[i].dataset)):\n",
    "        save_image(split_mnist.test_stream[i].dataset[j][0], \".//data//SplitMnist//test//{}//{}.png\".format(split_mnist.test_stream[i].dataset[j][1],j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc29d06-1245-4330-bbe2-26ec015d3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "class ClassSpecificImageFolder(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            dropped_classes=[],\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        self.dropped_classes = dropped_classes\n",
    "        super(ClassSpecificImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                                       transform=transform,\n",
    "                                                       target_transform=target_transform,\n",
    "                                                       is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        classes = [c for c in classes if c not in self.dropped_classes]\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54b1ba-e0b1-4548-b226-d56b2f1a0bf2",
   "metadata": {},
   "source": [
    "# Single experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c365cf-2274-47d0-b722-20f8c6965f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListExperiences=list()\n",
    "\n",
    "All=list(range(10))\n",
    "for sample in range(2,9,1):\n",
    "    S=combinations(range(10), sample)\n",
    "    #All=list(range(10))\n",
    "    for i in S :\n",
    "        L1=list(i)\n",
    "        L2=[k for k in All if k not in L1] \n",
    "        ListExperiences.append(L1)\n",
    "len(ListExperiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0a696e-e72c-4c20-afc9-cda65871d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListExperiences.append([x for x in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8533bd-5beb-417f-870f-7ed2b6e996d3",
   "metadata": {},
   "source": [
    "# Pairs of experiences (with and without repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389f51b4-8d6b-4c29-ad36-93f9c5ede45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46872"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pairs_exp=list()\n",
    "\n",
    "All=list(range(10))\n",
    "for sample in range(2,9,1):\n",
    "    S=combinations(range(10), sample)\n",
    "    #All=list(range(10))\n",
    "    for i in S :\n",
    "        L1=list(i)\n",
    "        L2=[k for k in All if k not in L1] \n",
    "        for sample2 in range(2,9,1):\n",
    "            S2=combinations(L2, sample2)\n",
    "            for j in S2:\n",
    "                pair=[]\n",
    "                pair.append(L1)\n",
    "                sub=list(j)\n",
    "                pair.append(sub)\n",
    "                Pairs_exp.append(pair)\n",
    "len(Pairs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "324efcee-a06a-4286-9a1e-fd840629debc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23436"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pairs_exp=list()\n",
    "All=list(range(10))\n",
    "for sample in range(2,9,1):\n",
    "    S=combinations(range(10), sample)\n",
    "    #All=list(range(10))\n",
    "    for i in S :\n",
    "        L1=list(i)\n",
    "        L2=[k for k in All if k not in L1] \n",
    "        for sample2 in range(2,9,1):\n",
    "            S2=combinations(L2, sample2)\n",
    "            for j in S2:\n",
    "                pair=[]\n",
    "                pair.append(L1)\n",
    "                sub=list(j)\n",
    "                pair.append(sub)\n",
    "                pair.sort()\n",
    "                if pair not in Pairs_exp :\n",
    "                    Pairs_exp.append(pair)\n",
    "len(Pairs_exp)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11a07e-8d46-490b-b57c-9bdc6e1a565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairs_exp[0] ,Pairs_exp[10000],Pairs_exp[20000],Pairs_exp[30000],Pairs_exp[40000],Pairs_exp[46871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e287cc8e-5bc6-4c42-8dd3-b2198aa1a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], [1, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListExperiences[0] ,ListExperiences[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce5ffef-4c2e-46d2-b7ed-0e9c0fba16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_in,\n",
    "        nlin=\"leakyrelu\",\n",
    "        dropout=0.0,\n",
    "        init_type=\"uniform\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init module list\n",
    "        self.module_list = nn.ModuleList()\n",
    "        ### ASSUMES 28x28 image size\n",
    "        ## compose layer 1\n",
    "        self.module_list.append(nn.Conv2d(channels_in, 8, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        # apply dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 2\n",
    "        self.module_list.append(nn.Conv2d(8, 6, 5))\n",
    "        self.module_list.append(nn.MaxPool2d(2, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## compose layer 3\n",
    "        self.module_list.append(nn.Conv2d(6, 4, 2))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add flatten layer\n",
    "        self.module_list.append(nn.Flatten())\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(3 * 3 * 4, 20))\n",
    "        self.module_list.append(self.get_nonlin(nlin))\n",
    "        ## add dropout\n",
    "        if dropout > 0:\n",
    "            self.module_list.append(nn.Dropout(dropout))\n",
    "        ## add linear layer 1\n",
    "        self.module_list.append(nn.Linear(20, 10))\n",
    "\n",
    "        ### initialize weights with se methods\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        # print(\"initialze model\")\n",
    "        for m in self.module_list:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                if init_type == \"xavier_uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                if init_type == \"xavier_normal\":\n",
    "                    torch.nn.init.xavier_normal_(m.weight)\n",
    "                if init_type == \"uniform\":\n",
    "                    torch.nn.init.uniform_(m.weight)\n",
    "                if init_type == \"normal\":\n",
    "                    torch.nn.init.normal_(m.weight)\n",
    "                if init_type == \"kaiming_normal\":\n",
    "                    torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if init_type == \"kaiming_uniform\":\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                # set bias to some small non-zero value\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_nonlin(self, nlin):\n",
    "        # apply nonlinearity\n",
    "        if nlin == \"leakyrelu\":\n",
    "            return nn.LeakyReLU()\n",
    "        if nlin == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        if nlin == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        if nlin == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        if nlin == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        if nlin == \"gelu\":\n",
    "            return nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through module_list\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_activations(self, x):\n",
    "        # forward prop through module_list\n",
    "        activations = []\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "            if (\n",
    "                isinstance(layer, nn.Tanh)\n",
    "                or isinstance(layer, nn.Sigmoid)\n",
    "                or isinstance(layer, nn.ReLU)\n",
    "                or isinstance(layer, nn.LeakyReLU)\n",
    "                or isinstance(layer, nn.SiLU)\n",
    "                or isinstance(layer, nn.GELU)\n",
    "                or isinstance(layer, ORU)\n",
    "                or isinstance(layer, ERU)\n",
    "            ):\n",
    "                activations.append(x)\n",
    "        return x, activations\n",
    "def train(model, trainloader, optimizer, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.train()\n",
    "    #print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "        List_mx.append(mx)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion,nb_classes):\n",
    "    List_mx=[]\n",
    "    model.eval()\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            outputs = model(image)\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            mx=multiclass_confusion_matrix(preds ,labels,nb_classes,normalize=\"pred\")\n",
    "            List_mx.append(mx)\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc,List_mx\n",
    "def create_frame(step,ax,data):\n",
    "    ax=ax.cla()\n",
    "    sns.heatmap(data[step][-1].cpu(),annot=True,cmap=\"cubehelix\",ax=ax,cbar=False)\n",
    "    plt.title('Epoch {} training {}'.format(step,exp)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e2b73-792a-46fa-8c00-c6fb0c0cfe99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b82e4182-0ae4-40d0-a969-1686006a5ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "\n",
    "nput = torch.tensor([0, 0, 9, 0])\n",
    "target = torch.tensor([0, 1,9 , 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30f639-912b-48fa-9edb-235ebc716e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b0c44-03e9-4c2c-bde1-de956986d139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafd0ab0-f75a-48fb-935d-59c31643483b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdb51e4-2fb2-4801-98ee-f05949c20116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders_paths=[ \"./data/SplitMnist/train/{}\".format(x) for x in range(10)]\n",
    "test_loaders_paths=[ \"./data/SplitMnist/test/{}\".format(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80539d61-02e7-4285-9fc2-83f179ba04af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 40 0 gelu\n",
      "Training loss: 0.583, training acc: 80.940\n",
      "Validation loss: 0.213, validation acc 1: 93.510\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 2 of 40 0 gelu\n",
      "Training loss: 0.178, training acc: 94.613\n",
      "Validation loss: 0.144, validation acc 1: 95.542\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 3 of 40 0 gelu\n",
      "Training loss: 0.134, training acc: 95.890\n",
      "Validation loss: 0.120, validation acc 1: 96.295\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 4 of 40 0 gelu\n",
      "Training loss: 0.112, training acc: 96.433\n",
      "Validation loss: 0.111, validation acc 1: 96.485\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 5 of 40 0 gelu\n",
      "Training loss: 0.098, training acc: 96.930\n",
      "Validation loss: 0.085, validation acc 1: 97.348\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 6 of 40 0 gelu\n",
      "Training loss: 0.089, training acc: 97.142\n",
      "Validation loss: 0.083, validation acc 1: 97.408\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 7 of 40 0 gelu\n",
      "Training loss: 0.082, training acc: 97.432\n",
      "Validation loss: 0.085, validation acc 1: 97.290\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 8 of 40 0 gelu\n",
      "Training loss: 0.077, training acc: 97.598\n",
      "Validation loss: 0.070, validation acc 1: 97.768\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 9 of 40 0 gelu\n",
      "Training loss: 0.071, training acc: 97.725\n",
      "Validation loss: 0.065, validation acc 1: 97.970\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 10 of 40 0 gelu\n",
      "Training loss: 0.068, training acc: 97.827\n",
      "Validation loss: 0.061, validation acc 1: 98.092\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 11 of 40 0 gelu\n",
      "Training loss: 0.064, training acc: 98.012\n",
      "Validation loss: 0.055, validation acc 1: 98.267\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 12 of 40 0 gelu\n",
      "Training loss: 0.061, training acc: 98.083\n",
      "Validation loss: 0.058, validation acc 1: 98.147\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 13 of 40 0 gelu\n",
      "Training loss: 0.060, training acc: 98.107\n",
      "Validation loss: 0.060, validation acc 1: 98.053\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 14 of 40 0 gelu\n",
      "Training loss: 0.057, training acc: 98.190\n",
      "Validation loss: 0.051, validation acc 1: 98.448\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 15 of 40 0 gelu\n",
      "Training loss: 0.055, training acc: 98.260\n",
      "Validation loss: 0.047, validation acc 1: 98.573\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 16 of 40 0 gelu\n",
      "Training loss: 0.053, training acc: 98.337\n",
      "Validation loss: 0.049, validation acc 1: 98.397\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 17 of 40 0 gelu\n",
      "Training loss: 0.052, training acc: 98.322\n",
      "Validation loss: 0.054, validation acc 1: 98.210\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 18 of 40 0 gelu\n",
      "Training loss: 0.051, training acc: 98.353\n",
      "Validation loss: 0.047, validation acc 1: 98.500\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 19 of 40 0 gelu\n",
      "Training loss: 0.050, training acc: 98.455\n",
      "Validation loss: 0.042, validation acc 1: 98.740\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 20 of 40 0 gelu\n",
      "Training loss: 0.048, training acc: 98.477\n",
      "Validation loss: 0.043, validation acc 1: 98.658\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 21 of 40 0 gelu\n",
      "Training loss: 0.047, training acc: 98.475\n",
      "Validation loss: 0.041, validation acc 1: 98.685\n",
      "stagnation\n",
      "[INFO]: Epoch 22 of 40 0 gelu\n",
      "Training loss: 0.046, training acc: 98.517\n",
      "Validation loss: 0.043, validation acc 1: 98.585\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 23 of 40 0 gelu\n",
      "Training loss: 0.046, training acc: 98.560\n",
      "Validation loss: 0.048, validation acc 1: 98.440\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 24 of 40 0 gelu\n",
      "Training loss: 0.044, training acc: 98.557\n",
      "Validation loss: 0.048, validation acc 1: 98.407\n",
      "stagnation\n",
      "[INFO]: Epoch 25 of 40 0 gelu\n",
      "Training loss: 0.044, training acc: 98.588\n",
      "Validation loss: 0.041, validation acc 1: 98.695\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 26 of 40 0 gelu\n",
      "Training loss: 0.043, training acc: 98.657\n",
      "Validation loss: 0.047, validation acc 1: 98.452\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 27 of 40 0 gelu\n",
      "Training loss: 0.042, training acc: 98.622\n",
      "Validation loss: 0.044, validation acc 1: 98.592\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 28 of 40 0 gelu\n",
      "Training loss: 0.042, training acc: 98.602\n",
      "Validation loss: 0.041, validation acc 1: 98.653\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 29 of 40 0 gelu\n",
      "Training loss: 0.041, training acc: 98.707\n",
      "Validation loss: 0.039, validation acc 1: 98.718\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 30 of 40 0 gelu\n",
      "Training loss: 0.040, training acc: 98.668\n",
      "Validation loss: 0.035, validation acc 1: 98.857\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 31 of 40 0 gelu\n",
      "Training loss: 0.040, training acc: 98.738\n",
      "Validation loss: 0.039, validation acc 1: 98.710\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 32 of 40 0 gelu\n",
      "Training loss: 0.038, training acc: 98.775\n",
      "Validation loss: 0.034, validation acc 1: 98.935\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 33 of 40 0 gelu\n",
      "Training loss: 0.038, training acc: 98.762\n",
      "Validation loss: 0.037, validation acc 1: 98.772\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 34 of 40 0 gelu\n",
      "Training loss: 0.038, training acc: 98.788\n",
      "Validation loss: 0.034, validation acc 1: 98.893\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 35 of 40 0 gelu\n",
      "Training loss: 0.037, training acc: 98.782\n",
      "Validation loss: 0.039, validation acc 1: 98.643\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 36 of 40 0 gelu\n"
     ]
    }
   ],
   "source": [
    "#train_loaders_paths=[ \"./data/SplitMnist/train/{}\".format(x) for x in range(10)]\n",
    "#test_loaders_paths=[ \"./data/SplitMnist/test/{}\".format(x) for x in range(10)]\n",
    "\n",
    "\n",
    "torch.manual_seed(887)\n",
    "L_activations=[\"gelu\"]#,\"leakyrelu\",\"sigmoid\"]#,\"relu\",\"silu\",\"tanh\"]\n",
    "L_inits=[\"kaiming_uniform\"]\n",
    "\n",
    "\n",
    "\n",
    "All=list(range(10))\n",
    "patience=3\n",
    "Margin=0.05\n",
    "for i in range(len(L_activations)):\n",
    "    for t,exp in enumerate(ListExperiences):\n",
    "        L_train_acc=[]\n",
    "        L_train_loss=[]\n",
    "        L_test_acc_0=[]\n",
    "        L_test_loss_0=[]\n",
    "        \n",
    "        L2=[k for k in All if k not in exp] \n",
    "        train_IF=ClassSpecificImageFolder( root=\"./data/SplitMnist/train/\",dropped_classes=L2,transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "        T_DL = DataLoader(dataset=train_IF, batch_size=90, num_workers=0, shuffle=True)\n",
    "        test_IF=ClassSpecificImageFolder( root=\"./data/SplitMnist/test/\",dropped_classes=L2,transform=transforms.Compose([ transforms.ToTensor(),transforms.Grayscale(1)]))\n",
    "        Ts_DL = DataLoader(dataset=train_IF, batch_size=90, num_workers=0, shuffle=True)\n",
    "\n",
    "        model = CNN(1,L_activations[i],0,L_inits[0])\n",
    "        if not(os.path.isdir('./checkpoints/')):\n",
    "            os.mkdir('./checkpoints/')\n",
    "        if not(os.path.isdir('./checkpoints/{}/'.format(exp))):\n",
    "            os.mkdir('./checkpoints/{}/'.format(exp))\n",
    "        if not(os.path.isdir('./checkpoints/{}/{}'.format(exp,L_activations[i]))):\n",
    "            os.mkdir('./checkpoints/{}/{}'.format(exp,L_activations[i]))\n",
    "        if not(os.path.isdir('./checkpoints/{}/{}/metrics/'.format(exp,L_activations[i]))):\n",
    "            os.mkdir('./checkpoints/{}/{}/metrics/'.format(exp,L_activations[i]))\n",
    "\n",
    "\n",
    "        # lists to keep track of losses and accuracies\n",
    "        train_loss, valid_loss_0 = [], [] \n",
    "        train_acc, valid_acc_0 = [], []\n",
    "        train_confus,test_confus =[] , []\n",
    "        Brain=copy.deepcopy(model)\n",
    "        Brain=Brain.to(device)\n",
    "\n",
    "        optimizer = Adam(Brain.parameters(), lr=0.05)\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=0.1, step_size_up=1, mode=\"triangular2\", cycle_momentum=False)\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        valid_epoch_loss0, valid_epoch_acc0,L_mx_st = validate(Brain, Ts_DL,criterion,10)\n",
    "        valid_loss_0.append(valid_epoch_loss0)\n",
    "        valid_acc_0.append(valid_epoch_acc0)\n",
    "        test_confus.append(L_mx_st)\n",
    "        #print(f\"Validation loss: {valid_epoch_loss0:.3f}, validation acc 1: {valid_epoch_acc0:.3f}\")\n",
    "\n",
    "        #print('-'*50)\n",
    "        # start the training\n",
    "        stagnate=0\n",
    "        for epoch in range(41):\n",
    "            print(f\"[INFO]: Epoch {epoch+1} of 40\" , t ,L_activations[i])\n",
    "            train_epoch_loss, train_epoch_acc ,L_mx = train(Brain, T_DL, optimizer, criterion,10)\n",
    "            train_confus.append(L_mx)\n",
    "            train_loss.append(train_epoch_loss)\n",
    "            train_acc.append(train_epoch_acc)\n",
    "            valid_epoch_loss0, valid_epoch_acc0,L_mx= validate(Brain, Ts_DL,  criterion,10)\n",
    "            test_confus.append(L_mx)\n",
    "            valid_loss_0.append(valid_epoch_loss0)\n",
    "            valid_acc_0.append(valid_epoch_acc0)\n",
    "            print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "            print(f\"Validation loss: {valid_epoch_loss0:.3f}, validation acc 1: {valid_epoch_acc0:.3f}\")\n",
    "\n",
    "            if (valid_epoch_acc0 >60) and (epoch >= 9):\n",
    "                if epoch %5==1:\n",
    "                    torch.save({'epoch': aux,'model_state_dict': Brain.state_dict(),'optimizer_state_dict': optimizer.state_dict(),},'./checkpoints/{}/{}/checkpoint epoch {}.pth'.format(exp,L_activations[i],epoch))\n",
    "                if (abs(valid_epoch_acc0-valid_acc_0[-2])<=Margin)  :\n",
    "                    print(\"stagnation\")\n",
    "                    stagnate=stagnate+1\n",
    "                    if stagnate==patience :\n",
    "                        epoch=-1\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    stagnate=0\n",
    "                aux=epoch\n",
    "                if (epoch==-1) :\n",
    "                    aux=epoch\n",
    "                    break\n",
    "            print('-'*50)\n",
    "\n",
    "\n",
    "        #torch.save(Brain.state_dict(),'./checkpoints/{}/{}/{}/checkpoint.pth'.format(ListExperiences[exp_idx][:5],activ,init))\n",
    "        torch.save({'epoch': aux,'model_state_dict': Brain.state_dict(),'optimizer_state_dict': optimizer.state_dict(),},'./checkpoints/{}/{}/checkpoint epoch {}.pth'.format(exp,L_activations[i],epoch))\n",
    "        L_train_acc.append(train_acc)\n",
    "        L_train_loss.append(train_loss)\n",
    "        L_test_acc_0.append(valid_acc_0)\n",
    "        L_test_loss_0.append(valid_loss_0)\n",
    "\n",
    "        direct='./checkpoints/{}/{}/metrics/'.format(exp,L_activations[i])\n",
    "        M=np.array(L_test_acc_0) \n",
    "        np.save(direct+\"Test Accuracy IID.npy\", M)\n",
    "\n",
    "        H=np.array(L_test_loss_0)\n",
    "        np.save(direct+\"Test Loss IID.npy\",H)\n",
    "\n",
    "\n",
    "        N=np.array(L_train_acc)\n",
    "        np.save(direct+\"Train Acc.npy\",N)\n",
    "\n",
    "        O=np.array(L_train_loss)\n",
    "        np.save(direct+\"Train Loss.npy\",O)\n",
    "        \n",
    "        P=[train_confus[i][-1].cpu() for i in range(len(train_confus))]\n",
    "        P=torch.stack(P)\n",
    "        P=np.transpose(P, (1, 2, 0))\n",
    "        np.save(direct+\"multiclass train Confusion matrix raw.npy\",P)\n",
    "        \n",
    "        W=[test_confus[i][-1].cpu() for i in range(len(test_confus))]\n",
    "        W=torch.stack(W)\n",
    "        W=np.transpose(W, (1, 2, 0))\n",
    "        np.save(direct+\"multiclass test Confusion matrix raw.npy\",W)\n",
    "        \n",
    "        fig, ax = plt.subplots() \n",
    "        ax.cla()\n",
    "        animation = FuncAnimation(fig, create_frame, frames=len(train_confus), fargs=(ax,train_confus))\n",
    "        wr=PillowWriter(fps=1)\n",
    "        animation.save('./checkpoints/{}/{}/metrics/Training mcx.gif'.format(exp,L_activations[i]) , writer=wr)\n",
    "        fig, ax = plt.subplots() \n",
    "        ax.cla()\n",
    "        animation = FuncAnimation(fig, create_frame, frames=len(test_confus), fargs=(ax,test_confus))\n",
    "        wr=PillowWriter(fps=1)\n",
    "        animation.save('./checkpoints/{}/{}/metrics/Testing mcx.gif'.format(exp,L_activations[i]) , writer=wr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074274a-167a-4809-9002-d23cd7a0d77b",
   "metadata": {},
   "source": [
    "### Access weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a48cc-01ed-4fdf-8239-11054c91982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListModelvec=[]\n",
    "check=torch.load(f\".//checkpoints//{ListExperiences[exp][:5]}//{L_activations[activ]}//{L_inits[init]}//checkpoint.pth\",pickle_module=dill,map_location=device)\n",
    "model = CNN(1,activ,0,init)\n",
    "model=model.to(device)\n",
    "model.load_state_dict(check[\"model_state_dict\"])\n",
    "L_param=[]\n",
    "for param in model.parameters():\n",
    "    m = nn.Flatten(0,-1)\n",
    "    L_param.append(m(param))\n",
    "vec = torch.Tensor()\n",
    "vec=vec.to(device)\n",
    "for idx in L_param:\n",
    "    vec = torch.cat((vec, idx.view(-1)))\n",
    "print(vec.shape)\n",
    "ListModelvec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c2d8588-8388-4786-b6b6-99748f7ea7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.29166666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=np.load(f\".//checkpoints//{ListExperiences[0]}//silu//metrics//Test Accuracy IID.npy\")\n",
    "acc[0][11+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fada223-450e-4f78-bb18-a670a97b378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:49<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.241852 -0.157798  -0.060025   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.387815 -0.257078  -0.155628   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.173784   0.320989  -0.044591   0.182154  -0.153738  -0.072043  98.291667  \n",
      "1  -0.041424  -0.054431   0.054163   0.284974  -0.034241  -0.006681  97.951667  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:44<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.340546 -0.192325  -0.045288   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.445414 -0.282809  -0.161097   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.218639   0.359771  -0.039524   0.219914  -0.209009  -0.113632  98.328333  \n",
      "1  -0.070014  -0.063746   0.073051   0.317632  -0.008772  -0.040820  98.336667  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:38<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...    0.41161 -0.217371  -0.021828   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...    0.47596 -0.287845  -0.157885   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.263205   0.388223  -0.035607   0.261163  -0.259779  -0.149770  98.736667  \n",
      "1  -0.091544  -0.079008   0.095666   0.329233   0.013716  -0.061931  98.211667  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:30<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.482990 -0.243536  -0.003372   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.496811 -0.293571  -0.147234   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.301097   0.416964  -0.034564   0.295304  -0.309780  -0.171334  98.748333  \n",
      "1  -0.112757  -0.102765   0.115507   0.337539   0.037101  -0.084592  98.768333  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:23<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.544951 -0.281758   0.025728   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.515426 -0.307265  -0.141704   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.323952   0.448369  -0.027040   0.320681  -0.363458  -0.193887  98.948333  \n",
      "1  -0.129733  -0.123439   0.139197   0.349935   0.061104  -0.103264  98.990000  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:17<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.520209 -0.322867  -0.125558   \n",
      "1  [0, 4]  1  0  0  0  1  0  0  0  0  ...   0.321124  0.241839   0.243312   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.135941  -0.140599   0.151312   0.351459   0.082363  -0.116815  98.916667  \n",
      "1   0.018635   0.021350  -0.191974  -0.091528  -0.095988  -0.306271  99.018333  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [01:49<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
      "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.544951 -0.281758   0.025728   \n",
      "1  [0, 2]  1  0  1  0  0  0  0  0  0  ...   0.531318 -0.328890  -0.117285   \n",
      "\n",
      "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
      "0  -0.323952   0.448369  -0.027040   0.320681  -0.363458  -0.193887  98.948333  \n",
      "1  -0.138418  -0.157315   0.165869   0.359363   0.091049  -0.129053  98.960000  \n",
      "\n",
      "[2 rows x 2477 columns]\n"
     ]
    }
   ],
   "source": [
    "L_activations=[\"silu\"]#,\"leakyrelu\",\"sigmoid\"]#,\"relu\",\"gelu\",\"tanh\"]\n",
    "L_inits=[\"kaiming_uniform\"]\n",
    "\n",
    "Cols=[\"label\"]+[x for x in range(10)]+[\"Activation\"]+[\"weight {}\".format(x) for x in range(200)]+[\"bias {}\".format(x) for x in range(200,208)]+[\"weight {}\".format(x) for x in range(208,1408)]+[\"bias {}\".format(x) for x in range(1408,1414)]+[\"weight {}\".format(x) for x in range(1414,1510)]+[\"bias {}\".format(x) for x in range(1510,1514)]+[\"weight {}\".format(x) for x in range(1514,2234)]+[\"bias {}\".format(x) for x in range(2234,2254)]+[\"weight {}\".format(x) for x in range(2254,2454)]+[\"bias {}\".format(x) for x in range(2454,2464)]+[\"Accuracy\"]\n",
    "check_name=[' epoch 11',' epoch 16',' epoch 21',' epoch 26',' epoch 31',' epoch 36','']\n",
    "Weights= pd.DataFrame(columns=Cols)\n",
    "\n",
    "All=list(range(10))\n",
    "\n",
    "for name in check_name:\n",
    "    Weights= pd.DataFrame(columns=Cols)\n",
    "    for exp in tqdm(ListExperiences) :\n",
    "        try:\n",
    "            row=[]\n",
    "\n",
    "            row.append(exp)\n",
    "            for label in All:\n",
    "                if label in exp:\n",
    "                    row.append(1)\n",
    "                else:\n",
    "                    row.append(0)\n",
    "\n",
    "            row.append(\"silu\")\n",
    "\n",
    "            check=torch.load(f\".//checkpoints//{exp}//silu//checkpoint{name}.pth\",pickle_module=dill,map_location=device)\n",
    "            model = CNN(1,L_activations[0],0,L_inits[0])\n",
    "            model=model.to(device)\n",
    "            model.load_state_dict(check[\"model_state_dict\"])\n",
    "            L_param=[]\n",
    "            for param in model.parameters():\n",
    "                m = nn.Flatten(0,-1)\n",
    "                L_param.append(m(param))\n",
    "            vec = torch.Tensor()\n",
    "            vec=vec.to(device)\n",
    "            for idx in L_param:\n",
    "                vec = torch.cat((vec, idx.view(-1)))\n",
    "            vec=vec.detach().cpu().numpy()\n",
    "            row.extend(vec)\n",
    "\n",
    "            acc=np.load(f\".//checkpoints//{exp}//silu//metrics//Test Accuracy IID.npy\")\n",
    "            if name != '':\n",
    "                row.append(acc[0][int(name[-2:])+1])\n",
    "            else:\n",
    "                row.append(acc[0][-1])\n",
    "            Weights.loc[len(Weights)]=row\n",
    "        except:\n",
    "            continue\n",
    "    print(Weights.head(2))\n",
    "    Weights.to_csv(f\"Weights {L_activations[0]}{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefe55f-6eae-44e1-a545-afdad65ffe0e",
   "metadata": {},
   "source": [
    "## Create train , validation , test loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c4bada29-ee38-498c-ad9a-b2a5ba018ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>bias 2455</th>\n",
       "      <th>bias 2456</th>\n",
       "      <th>bias 2457</th>\n",
       "      <th>bias 2458</th>\n",
       "      <th>bias 2459</th>\n",
       "      <th>bias 2460</th>\n",
       "      <th>bias 2461</th>\n",
       "      <th>bias 2462</th>\n",
       "      <th>bias 2463</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241852</td>\n",
       "      <td>-0.157798</td>\n",
       "      <td>-0.060025</td>\n",
       "      <td>-0.173784</td>\n",
       "      <td>0.320989</td>\n",
       "      <td>-0.044591</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>-0.153738</td>\n",
       "      <td>-0.072043</td>\n",
       "      <td>98.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  0  1  2  3  4  5  6  7  8  ...  bias 2455 bias 2456  bias 2457  \\\n",
       "0  [0, 1]  1  1  0  0  0  0  0  0  0  ...   0.241852 -0.157798  -0.060025   \n",
       "\n",
       "   bias 2458  bias 2459  bias 2460  bias 2461  bias 2462  bias 2463   Accuracy  \n",
       "0  -0.173784   0.320989  -0.044591   0.182154  -0.153738  -0.072043  98.291667  \n",
       "\n",
       "[1 rows x 2477 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Weights silu epoch 11.csv\")\n",
    "\n",
    "param_columns=df.columns[12:-1]\n",
    "l=[0,1]\n",
    "df[df['label']=='{}'.format([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "884614fb-71eb-4d11-a935-c4a5b9494fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23436"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pairs_exp=list()\n",
    "All=list(range(10))\n",
    "for sample in range(2,9,1):\n",
    "    S=combinations(range(10), sample)\n",
    "    #All=list(range(10))\n",
    "    for i in S :\n",
    "        L1=list(i)\n",
    "        L2=[k for k in All if k not in L1] \n",
    "        for sample2 in range(2,9,1):\n",
    "            S2=combinations(L2, sample2)\n",
    "            for j in S2:\n",
    "                pair=[]\n",
    "                pair.append(L1)\n",
    "                sub=list(j)\n",
    "                pair.append(sub)\n",
    "                pair.sort()\n",
    "                if pair not in Pairs_exp :\n",
    "                    Pairs_exp.append(pair)\n",
    "len(Pairs_exp)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "07caf52b-8123-40fd-9113-83251863e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23436/23436 [00:00<00:00, 976959.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pair=[]\n",
    "train_tgt=[]\n",
    "\n",
    "val_pair=[]\n",
    "val_tgt=[]\n",
    "\n",
    "test_pair=[]\n",
    "test_tgt=[]\n",
    "for pair in tqdm(Pairs_exp):\n",
    "    if (len(pair[0])==5 and len(pair[1])==5) or(len(pair[0])==4 and len(pair[1])==4) or(len(pair[0])==3 and len(pair[1])==3) or (len(pair[0])==2 and len(pair[1])==2):\n",
    "        test_pair.append(pair)\n",
    "        tg=(pair[0]+pair[1]).sort()\n",
    "        test_tgt.append(tg)\n",
    "    elif (len(pair[0])==7 and len(pair[1])==2) or (len(pair[0])==2 and len(pair[1])==7) or (len(pair[0])==6 and len(pair[1])==3) or (len(pair[0])==3 and len(pair[1])==6) or (len(pair[0])==4 and len(pair[1])==5) or (len(pair[0])==5 and len(pair[1])==4):\n",
    "        val_pair.append(pair)\n",
    "        tg=(pair[0]+pair[1]).sort()\n",
    "        val_tgt.append(tg)\n",
    "    else :\n",
    "        train_pair.append(pair)\n",
    "        tg=(pair[0]+pair[1]).sort()\n",
    "        train_tgt.append(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "526c9bf6-9af4-4cef-b7fc-92226be8255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4431, 16545, 2460, 4431, 16545, 2460)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pair),len(train_pair),len(val_pair),len(test_tgt),len(train_tgt),len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e7bc8f85-6275-4b70-a4bc-d26b78c6eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1042, -0.6708, -0.3955,  ...,  0.1822, -0.1537, -0.0720]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(df[df['label']=='{}'.format([0,1])][param_columns].to_numpy().astype('float64') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6ddd4bd7-5c14-4ca5-9977-e808b42fcb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [2, 3, 4]]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "09649f5e-d70b-4dac-bcfe-a7be47eb8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_Stream1=[]\n",
    "L_Stream2=[]\n",
    "tgt=[]\n",
    "for c,pair in enumerate(train_pair):\n",
    "    L_Stream1.append(torch.from_numpy(df[df['label']=='{}'.format(pair[0])][param_columns].to_numpy().astype('float64')))\n",
    "    L_Stream2.append(torch.from_numpy(df[df['label']=='{}'.format(pair[1])][param_columns].to_numpy().astype('float64')))\n",
    "    tg=pair[0]+pair[1]\n",
    "    tg.sort()\n",
    "    tgt.append(torch.from_numpy(df[df['label']=='{}'.format(tg)][param_columns].to_numpy().astype('float64')))\n",
    "Stream1=torch.stack(L_Stream1)\n",
    "Stream2=torch.stack(L_Stream2)\n",
    "target=torch.stack(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "35d51e0f-abc8-46d6-a69b-7ff9c72592bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3074,  0.2168,  0.2783,  ..., -0.1724, -0.0076,  0.0278]],\n",
       "\n",
       "        [[-0.2350, -0.0342, -0.3572,  ...,  0.2821, -0.2164, -0.0975]],\n",
       "\n",
       "        [[ 0.3847,  0.1020, -0.1432,  ...,  0.0573, -0.1520, -0.0422]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1024, -0.6714, -0.3953,  ...,  0.1817, -0.1535, -0.0718]],\n",
       "\n",
       "        [[-0.1024, -0.6714, -0.3953,  ...,  0.1817, -0.1535, -0.0718]],\n",
       "\n",
       "        [[-0.1024, -0.6714, -0.3953,  ...,  0.1817, -0.1535, -0.0718]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "528288f7-d903-4c3f-af78-136599ed3ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16545, 2464]),\n",
       " torch.Size([16545, 2464]),\n",
       " torch.Size([16545, 2464]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stream1=torch.reshape(Stream1, (Stream1.shape[0], Stream1.shape[2]))\n",
    "Stream2=torch.reshape(Stream2, (Stream2.shape[0], Stream2.shape[2]))\n",
    "target=torch.reshape(target, (target.shape[0], target.shape[2]))\n",
    "Stream1.shape,Stream2.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a268ce95-235d-4221-92cd-c2eb743b51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_dataset = TensorDataset(Stream1,Stream2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "693d0076-cd0f-47ec-a23c-f10cfde045cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsab_cat_loader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d6113b58-7a3c-46f2-aa9d-33cd93694893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2464]) torch.Size([1, 1, 2464]) torch.Size([1, 0, 2464])\n"
     ]
    }
   ],
   "source": [
    "for x1,x2,tg in dsab_cat_loader:\n",
    "    print(x1.shape,x2.shape,tg.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d7907-a2dd-47f6-ab25-1d04e312ad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbbed9-d0ff-4f1e-ada5-6892f97f7594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5b20c-4959-4ded-944f-e8ad82965a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd03b68-2b5f-4ce9-8a6a-42eea002e24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901b045-1893-4cbf-bf49-6e12c4ea2e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fdca4c-7762-4267-a977-436e3ba5b1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510aa8f-03b6-4062-a7f9-41f0bcc1eb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41258b1c-2a5d-4215-b739-8396e044e86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b0277-cdce-427b-8f3f-646fc8afd36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8f158-aefe-456f-bc55-1fcfabed4e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737940f-6c50-4ec3-9c34-32b7fa0dfe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0110456-99c7-4c92-b5df-2e44664aea62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138e354-49a3-4aa1-bfb5-632c67df73a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ea51b-b3ea-41d6-97d7-92a7ef2b53d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c6f484-af6d-422c-970e-c9d19800ede0",
   "metadata": {},
   "source": [
    "## reconstruct Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630fb9b-bf05-43f9-95d7-323a211e4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "for class_order_idx in range(len(ListExperiences)):\n",
    "    for i in product(L_activations,L_inits):\n",
    "        checkpoint=OrderedDict()\n",
    "        vector_aux= copy.deepcopy(y)\n",
    "        vector_aux=vector_aux.cpu()\n",
    "        checkpoint[\"module_list.0.weight\"]=torch.tensor(np.array(vector_aux[l][0:200]).reshape([8, 1, 5, 5]))\n",
    "        checkpoint[\"module_list.0.bias\"]=torch.tensor(np.array(vector_aux[l][200:208]).reshape([8]))\n",
    "        checkpoint[\"module_list.3.weight\"]=torch.tensor(np.array(vector_aux[l][208:1408]).reshape([6, 8, 5, 5]))\n",
    "        checkpoint[\"module_list.3.bias\"]=torch.tensor(np.array(vector_aux[l][1408:1414]).reshape([6]))\n",
    "        checkpoint[\"module_list.6.weight\"]=torch.tensor(np.array(vector_aux[l][1414:1510]).reshape([4, 6, 2, 2]))\n",
    "        checkpoint[\"module_list.6.bias\"]=torch.tensor(np.array(vector_aux[l][1510:1514]).reshape([4]))\n",
    "        checkpoint[\"module_list.9.weight\"]=torch.tensor(np.array(vector_aux[l][1514:2234]).reshape([20,36]))\n",
    "        checkpoint[\"module_list.9.bias\"]=torch.tensor(np.array(vector_aux[l][2234:2254]).reshape([20]))\n",
    "        checkpoint[\"module_list.11.weight\"]=torch.tensor(np.array(vector_aux[l][2254:2454]).reshape([10,20]))\n",
    "        checkpoint[\"module_list.11.bias\"]=torch.tensor(np.array(vector_aux[l][2454:2464]).reshape([10]))\n",
    "        model = CNN(1,list(i)[0],0,list(i)[1]) ####\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        torch.save(model.state_dict(), './checkpoints/Cumulative/{}/{}/{}/1/Reconsturcted checkpoint.pth'.format(ListExperiences[class_order_idx][:5],list(i)[0],list(i)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ad9dc-d6f9-48ef-9b04-da0541e6d458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f8e7aae-ae9f-427c-b0de-c97dccf5a42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8770aa-e5e1-40a5-94bb-25d9adf77af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1f0d1-0159-4154-8ad9-c110697e971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30512354-7922-4443-bd1c-e7bab2a72ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf755c23-ef0c-48d6-9fbf-e8ed8862f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c386ba-8d07-4db9-b682-98c6949e37d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ec2f5-0222-48bc-8011-01542cd27baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d6e0b-b674-4c11-883c-b077e17b3d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca690d7-667d-44d6-8a25-1aba073df4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
